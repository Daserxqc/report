#!/usr/bin/env python3
"""
æ”¯æŒå®æ—¶SSEæ¨é€çš„MCPè°ƒåº¦å™¨
"""

import json
import asyncio
from typing import Dict, Any, AsyncGenerator
from datetime import datetime

# å¯¼å…¥ç°æœ‰çš„MCPå·¥å…·å‡½æ•°
from main import (
    analysis_mcp, query_generation_mcp, outline_writer_mcp, 
    summary_writer_mcp, content_writer_mcp, parallel_search,
    orchestrator_mcp, orchestrator_mcp_simple
)

# å¯¼å…¥åŸæœ¬agentçš„æ ¸å¿ƒé€»è¾‘
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from generate_news_report_enhanced import IntelligentReportAgent

class StreamingOrchestrator:
    """æ”¯æŒå®æ—¶SSEæ¨é€çš„MCPè°ƒåº¦å™¨"""
    
    def __init__(self):
        self.request_id = 1
        self.tool_name = ""
        # åˆå§‹åŒ–åŸæœ¬agentçš„æ ¸å¿ƒç»„ä»¶
        try:
            self.intelligent_agent = IntelligentReportAgent()
            print("âœ… IntelligentReportAgent åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ IntelligentReportAgent åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.intelligent_agent = None
    
    async def generate_industry_dynamic_report(self, request: Dict[str, Any]) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆè¡Œä¸šåŠ¨æ€æŠ¥å‘Š - å…¼å®¹MCPå·¥å…·è°ƒç”¨"""
        async for message in self.stream_industry_dynamic_report(request):
            yield message
    
    async def stream_industry_dynamic_report(self, request: Dict[str, Any]) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆè¡Œä¸šåŠ¨æ€æŠ¥å‘Š - é›†æˆåŸæœ¬agentçš„æ™ºèƒ½äº”æ­¥åˆ†ææ³•"""
        self.tool_name = "generate_industry_dynamic_report"
        
        # å‘é€å¼€å§‹æ¶ˆæ¯
        yield self._create_progress_message("started", "å¼€å§‹ç”Ÿæˆè¡Œä¸šåŠ¨æ€æŠ¥å‘Š", "æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½åˆ†æç³»ç»Ÿ...")
        await asyncio.sleep(0.1)
        
        try:
            industry = request.get("industry", "æœªæŒ‡å®šè¡Œä¸š")
            time_range = request.get("time_range", "recent")
            focus_areas = request.get("focus_areas", ["å¸‚åœºè¶‹åŠ¿", "æŠ€æœ¯åˆ›æ–°", "æ”¿ç­–å½±å“", "ç«äº‰æ ¼å±€"])
            days = request.get("days", 30)
            use_local_data = request.get("use_local_data", False)
            
            # å¦‚æœä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œè·³è¿‡ç½‘ç»œæœç´¢
            if use_local_data:
                yield self._create_progress_message("processing", "ä½¿ç”¨æœ¬åœ°æ•°æ®", "è·³è¿‡ç½‘ç»œæœç´¢ï¼Œä½¿ç”¨é¢„è®¾çš„æœ¬åœ°æ•°æ®...")
                await asyncio.sleep(0.1)
                
                # ä½¿ç”¨é¢„è®¾çš„æœ¬åœ°æ•°æ®
                local_data = self._get_local_data(industry)
                yield self._create_progress_message("completed", "æœ¬åœ°æ•°æ®åŠ è½½å®Œæˆ", f"åŠ è½½äº†{len(local_data)}æ¡æœ¬åœ°æ•°æ®")
                await asyncio.sleep(0.1)
                
                # ç›´æ¥è¿›å…¥å†…å®¹ç”Ÿæˆé˜¶æ®µ
                yield self._create_progress_message("processing", "ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", "åŸºäºæœ¬åœ°æ•°æ®ç”ŸæˆæŠ¥å‘Š...")
                await asyncio.sleep(0.1)
                
                # ç”ŸæˆæŠ¥å‘Šå†…å®¹
                report_content = await self._generate_report_from_local_data(local_data, industry)
                
                # å‘é€æœ€ç»ˆç»“æœ
                yield self._create_progress_message("completed", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ", "åŸºäºæœ¬åœ°æ•°æ®æˆåŠŸç”ŸæˆæŠ¥å‘Š")
                await asyncio.sleep(0.1)
                
                # å‘é€æœ€ç»ˆç»“æœ
                final_result = {
                    "type": "result",
                    "content": report_content,
                    "metadata": {
                        "industry": industry,
                        "data_source": "local",
                        "total_items": len(local_data)
                    }
                }
                yield f"data: {json.dumps(final_result, ensure_ascii=False)}\n\n"
                return
            
            # ========== ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆ ==========
            yield self._create_progress_message("processing", "æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆ", f"æ­£åœ¨åˆ†æ{industry}è¡Œä¸šéœ€æ±‚ï¼Œç”Ÿæˆå¤šç»´åº¦æœç´¢ç­–ç•¥...")
            await asyncio.sleep(0.1)
            
            # ä½¿ç”¨åŸæœ¬agentçš„æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆé€»è¾‘
            initial_data = await self._generate_initial_queries_enhanced(industry, days, focus_areas)
            total_count = initial_data.get('total_count', 0)
            if isinstance(total_count, int):
                count_str = str(total_count)
            else:
                count_str = str(len(total_count)) if hasattr(total_count, '__len__') else "0"
            yield self._create_progress_message("completed", "æŸ¥è¯¢ç­–ç•¥ç”Ÿæˆå®Œæˆ", f"ç”Ÿæˆäº†{count_str}æ¡åˆå§‹æ•°æ®")
            await asyncio.sleep(0.1)
            
            # ========== ç¬¬äºŒæ­¥ï¼šå¤šæ¸ é“ä¿¡æ¯æœé›† ==========
            yield self._create_progress_message("processing", "å¤šæ¸ é“ä¿¡æ¯æœé›†", "æ­£åœ¨æ•´åˆå¤šä¸ªæœç´¢å¼•æ“çš„ç»“æœ...")
            await asyncio.sleep(0.1)
            
            all_news_data = initial_data
            total_count = all_news_data.get('total_count', 0)
            if isinstance(total_count, int):
                count_str = str(total_count)
            else:
                count_str = str(len(total_count)) if hasattr(total_count, '__len__') else "0"
            yield self._create_progress_message("completed", "ä¿¡æ¯æœé›†å®Œæˆ", f"è·å¾—{count_str}æ¡ä¿¡æ¯")
            await asyncio.sleep(0.1)
            
            # ========== ç¬¬ä¸‰æ­¥ï¼šåæ€ä¸çŸ¥è¯†ç¼ºå£åˆ†æ ==========
            iteration_count = 0
            max_iterations = 3  # æœ€å¤š3è½®è¿­ä»£
            
            while iteration_count < max_iterations:
                iteration_count += 1
                yield self._create_progress_message("processing", f"åæ€åˆ†æ (ç¬¬{iteration_count}è½®)", "æ­£åœ¨åˆ†æä¿¡æ¯å®Œæ•´æ€§å’Œè´¨é‡...")
                await asyncio.sleep(0.1)
                
                gaps, is_sufficient = await self._reflect_on_information_gaps_enhanced(all_news_data, industry, days)
                
                if is_sufficient:
                    yield self._create_progress_message("completed", "ä¿¡æ¯å……åˆ†æ€§ç¡®è®¤", "ä¿¡æ¯æ”¶é›†å……åˆ†ï¼Œå‡†å¤‡ç”ŸæˆæŠ¥å‘Š")
                    await asyncio.sleep(0.1)
                    break
                
                if iteration_count < max_iterations:
                    yield self._create_progress_message("processing", f"è¡¥å……æœç´¢ (ç¬¬{iteration_count}è½®)", "æ­£åœ¨ç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢è¡¥å……ä¿¡æ¯ç¼ºå£...")
                    await asyncio.sleep(0.1)
                    
                    additional_data = await self._generate_targeted_queries_enhanced(gaps, industry, days)
                    if additional_data:
                        old_total = all_news_data.get('total_count', 0)
                        all_news_data = self._merge_data_enhanced(all_news_data, additional_data)
                        new_total = all_news_data.get('total_count', 0)
                        yield self._create_progress_message("completed", f"ç¬¬{iteration_count}è½®è¡¥å……å®Œæˆ", f"æ–°å¢{new_total - old_total}æ¡æ•°æ®ï¼Œæ€»é‡: {new_total}")
                        await asyncio.sleep(0.1)
                    else:
                        yield self._create_progress_message("completed", f"ç¬¬{iteration_count}è½®å®Œæˆ", "æœ¬è½®æœªè·å¾—æ–°æ•°æ®")
                        await asyncio.sleep(0.1)
                else:
                    yield self._create_progress_message("completed", "è¾¾åˆ°è¿­ä»£ä¸Šé™", "å·²å®Œæˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼€å§‹ç”ŸæˆæŠ¥å‘Š")
                    await asyncio.sleep(0.1)
            
            # ========== ç¬¬å››æ­¥ï¼šæ·±åº¦å†…å®¹åˆ†æ ==========
            yield self._create_progress_message("processing", "æ·±åº¦å†…å®¹åˆ†æ", "æ­£åœ¨å¯¹æ”¶é›†çš„ä¿¡æ¯è¿›è¡Œæ™ºèƒ½åˆ†æå’Œå»é‡...")
            await asyncio.sleep(0.1)
            
            # æ™ºèƒ½å»é‡å’Œæ—¶é—´è¿‡æ»¤
            processed_data = await self._process_collected_data_enhanced(all_news_data, industry, days)
            total_count = processed_data.get('total_count', 0)
            if isinstance(total_count, int):
                count_str = str(total_count)
            else:
                count_str = str(len(total_count)) if hasattr(total_count, '__len__') else "0"
            yield self._create_progress_message("completed", "å†…å®¹åˆ†æå®Œæˆ", f"å¤„ç†å®Œæˆï¼Œä¿ç•™{count_str}æ¡é«˜è´¨é‡ä¿¡æ¯")
            await asyncio.sleep(0.1)
            
            # ========== ç¬¬äº”æ­¥ï¼šç»¼åˆæŠ¥å‘Šç”Ÿæˆ ==========
            yield self._create_progress_message("processing", "ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", "æ­£åœ¨ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š...")
            await asyncio.sleep(0.1)
            
            # ç”Ÿæˆå„ä¸ªç« èŠ‚
            section_contents = {}
            
            # 1. é‡å¤§äº‹ä»¶åˆ†æ
            breaking_news = processed_data.get("breaking_news", [])
            print(f"ğŸ” [è°ƒè¯•] breaking_newsæ•°æ®: {len(breaking_news)}æ¡")
            if breaking_news and len(breaking_news) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆé‡å¤§äº‹ä»¶åˆ†æ", "æ­£åœ¨æ·±åº¦åˆ†æè¡Œä¸šé‡å¤§äº‹ä»¶...")
                await asyncio.sleep(0.1)
                try:
                    section_contents["é‡å¤§äº‹ä»¶"] = await self._process_breaking_news_enhanced(industry, breaking_news, days)
                    yield self._create_model_usage_message("dashscope", "qwen-max", 1500, 1000)
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "é‡å¤§äº‹ä»¶åˆ†æå®Œæˆ", "æ·±åº¦åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ é‡å¤§äº‹ä»¶åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "é‡å¤§äº‹ä»¶åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] breaking_newsä¸ºç©ºï¼Œè·³è¿‡é‡å¤§äº‹ä»¶åˆ†æ")
                yield self._create_progress_message("skipped", "é‡å¤§äº‹ä»¶åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— é‡å¤§äº‹ä»¶")
                await asyncio.sleep(0.1)
            
            # 2. æŠ€æœ¯åˆ›æ–°åˆ†æ
            innovation_news = processed_data.get("innovation_news", [])
            print(f"ğŸ” [è°ƒè¯•] innovation_newsæ•°æ®: {len(innovation_news)}æ¡")
            print(f"ğŸ” [è°ƒè¯•] innovation_newså†…å®¹: {innovation_news[:2] if innovation_news else 'æ— æ•°æ®'}")
            if innovation_news and len(innovation_news) > 0:
                yield self._create_progress_message("processing", "ç”ŸæˆæŠ€æœ¯åˆ›æ–°åˆ†æ", "æ­£åœ¨åˆ†ææŠ€æœ¯åˆ›æ–°å’Œçªç ´...")
                await asyncio.sleep(0.1)
                try:
                    section_contents["æŠ€æœ¯åˆ›æ–°"] = await self._process_innovation_news_enhanced(industry, innovation_news)
                    yield self._create_model_usage_message("dashscope", "qwen-max", 1200, 800)
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "æŠ€æœ¯åˆ›æ–°åˆ†æå®Œæˆ", "æŠ€æœ¯åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ æŠ€æœ¯åˆ›æ–°åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "æŠ€æœ¯åˆ›æ–°åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] innovation_newsä¸ºç©ºï¼Œè·³è¿‡æŠ€æœ¯åˆ›æ–°åˆ†æ")
                yield self._create_progress_message("skipped", "æŠ€æœ¯åˆ›æ–°åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— æŠ€æœ¯åˆ›æ–°ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 3. æŠ•èµ„åŠ¨æ€åˆ†æ
            investment_news = processed_data.get("investment_news", [])
            print(f"ğŸ” [è°ƒè¯•] investment_newsæ•°æ®: {len(investment_news)}æ¡")
            if investment_news and len(investment_news) > 0:
                yield self._create_progress_message("processing", "ç”ŸæˆæŠ•èµ„åŠ¨æ€åˆ†æ", "æ­£åœ¨åˆ†ææŠ•èµ„å’Œå¸‚åœºåŠ¨å‘...")
                await asyncio.sleep(0.1)
                try:
                    section_contents["æŠ•èµ„åŠ¨æ€"] = await self._process_investment_news_enhanced(industry, investment_news)
                    yield self._create_model_usage_message("dashscope", "qwen-max", 1300, 900)
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "æŠ•èµ„åŠ¨æ€åˆ†æå®Œæˆ", "æŠ•èµ„åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ æŠ•èµ„åŠ¨æ€åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "æŠ•èµ„åŠ¨æ€åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] investment_newsä¸ºç©ºï¼Œè·³è¿‡æŠ•èµ„åŠ¨æ€åˆ†æ")
                yield self._create_progress_message("skipped", "æŠ•èµ„åŠ¨æ€åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— æŠ•èµ„åŠ¨æ€ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 4. æ”¿ç­–ç›‘ç®¡åˆ†æ
            policy_news = processed_data.get("policy_news", [])
            print(f"ğŸ” [è°ƒè¯•] policy_newsæ•°æ®: {len(policy_news)}æ¡")
            if policy_news and len(policy_news) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆæ”¿ç­–ç›‘ç®¡åˆ†æ", "æ­£åœ¨åˆ†ææ”¿ç­–å’Œç›‘ç®¡åŠ¨æ€...")
                await asyncio.sleep(0.1)
                try:
                    section_contents["æ”¿ç­–ç›‘ç®¡"] = await self._process_policy_news_enhanced(industry, policy_news)
                    yield self._create_model_usage_message("dashscope", "qwen-max", 1100, 700)
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "æ”¿ç­–ç›‘ç®¡åˆ†æå®Œæˆ", "æ”¿ç­–åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ æ”¿ç­–ç›‘ç®¡åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "æ”¿ç­–ç›‘ç®¡åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] policy_newsä¸ºç©ºï¼Œè·³è¿‡æ”¿ç­–ç›‘ç®¡åˆ†æ")
                yield self._create_progress_message("skipped", "æ”¿ç­–ç›‘ç®¡åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— æ”¿ç­–ç›‘ç®¡ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 5. è¡Œä¸šè¶‹åŠ¿åˆ†æ
            trend_news = processed_data.get("trend_news", [])
            print(f"ğŸ” [è°ƒè¯•] trend_newsæ•°æ®: {len(trend_news)}æ¡")
            if trend_news and len(trend_news) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆè¡Œä¸šè¶‹åŠ¿åˆ†æ", "æ­£åœ¨åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿...")
                await asyncio.sleep(0.1)
                try:
                    section_contents["è¡Œä¸šè¶‹åŠ¿"] = await self._process_industry_trends_enhanced(industry, trend_news, days)
                    yield self._create_model_usage_message("dashscope", "qwen-max", 1400, 1000)
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "è¡Œä¸šè¶‹åŠ¿åˆ†æå®Œæˆ", "è¶‹åŠ¿åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ è¡Œä¸šè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "è¡Œä¸šè¶‹åŠ¿åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] trend_newsä¸ºç©ºï¼Œè·³è¿‡è¡Œä¸šè¶‹åŠ¿åˆ†æ")
                yield self._create_progress_message("skipped", "è¡Œä¸šè¶‹åŠ¿åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— è¡Œä¸šè¶‹åŠ¿ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 6. è§‚ç‚¹å¯¹æ¯”åˆ†æ
            perspective_analysis = processed_data.get("perspective_analysis", [])
            print(f"ğŸ” [è°ƒè¯•] perspective_analysisæ•°æ®: {len(perspective_analysis)}æ¡")
            if perspective_analysis and len(perspective_analysis) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆè§‚ç‚¹å¯¹æ¯”åˆ†æ", "æ­£åœ¨åˆ†æä¸åŒè§‚ç‚¹å’Œäº‰è®®...")
                await asyncio.sleep(0.1)
                try:
                    section_contents["è§‚ç‚¹å¯¹æ¯”"] = await self._process_perspective_analysis_enhanced(industry, perspective_analysis)
                    yield self._create_model_usage_message("dashscope", "qwen-max", 1200, 800)
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "è§‚ç‚¹å¯¹æ¯”åˆ†æå®Œæˆ", "è§‚ç‚¹åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ è§‚ç‚¹å¯¹æ¯”åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "è§‚ç‚¹å¯¹æ¯”åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] perspective_analysisä¸ºç©ºï¼Œè·³è¿‡è§‚ç‚¹å¯¹æ¯”åˆ†æ")
                yield self._create_progress_message("skipped", "è§‚ç‚¹å¯¹æ¯”åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— è§‚ç‚¹å¯¹æ¯”ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 7. ç”Ÿæˆæ™ºèƒ½æ€»ç»“
            yield self._create_progress_message("processing", "ç”Ÿæˆæ™ºèƒ½æ€»ç»“", "æ­£åœ¨ç”ŸæˆAIæ™ºèƒ½åˆ†ææ€»ç»“...")
            await asyncio.sleep(0.1)
            intelligent_summary = await self._generate_intelligent_summary_enhanced(industry, processed_data, days)
            yield self._create_model_usage_message("dashscope", "qwen-max", 1000, 800)
            await asyncio.sleep(0.1)
            yield self._create_progress_message("completed", "æ™ºèƒ½æ€»ç»“å®Œæˆ", "AIåˆ†ææ€»ç»“å·²ç”Ÿæˆ")
            await asyncio.sleep(0.1)
            
            # 8. ç»„è£…æœ€ç»ˆæŠ¥å‘Š
            yield self._create_progress_message("processing", "ç»„è£…æœ€ç»ˆæŠ¥å‘Š", "æ­£åœ¨æ•´åˆæ‰€æœ‰åˆ†æå†…å®¹...")
            await asyncio.sleep(0.1)
            
            final_report = self._assemble_enhanced_report(industry, intelligent_summary, section_contents, processed_data, days)
            yield self._create_progress_message("completed", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ", f"æˆåŠŸç”ŸæˆåŒ…å«{len(section_contents)}ä¸ªæ·±åº¦åˆ†æç« èŠ‚çš„æ™ºèƒ½æŠ¥å‘Š")
            await asyncio.sleep(0.1)
            
            # å‘é€æœ€ç»ˆç»“æœ
            yield self._create_final_result(final_report)
            
        except Exception as e:
            yield self._create_error_message(str(e))
    
    def _create_progress_message(self, status: str, message: str, content: str) -> str:
        """åˆ›å»ºè¿›åº¦æ›´æ–°æ¶ˆæ¯"""
        progress_message = {
            "method": "notifications/message",
            "params": {
                "level": "info",
                "data": {
                    "msg": {
                        "status": status,
                        "message": message,
                        "details": {
                            "id": self.request_id,
                            "name": self.tool_name,
                            "content": content
                        }
                    },
                    "extra": None
                }
            },
            "jsonrpc": "2.0"
        }
        return f"data: {json.dumps(progress_message, ensure_ascii=False)}\n\n"
    
    def _create_model_usage_message(self, provider: str, model: str, input_tokens: int, output_tokens: int) -> str:
        """åˆ›å»ºæ¨¡å‹ç”¨é‡æ¶ˆæ¯"""
        usage_message = {
            "jsonrpc": "2.0",
            "method": "notifications/message",
            "params": {
                "data": {
                    "msg": {
                        "type": "model_usage",
                        "data": {
                            "model_provider": provider,
                            "model_name": model,
                            "input_tokens": input_tokens,
                            "output_tokens": output_tokens
                        }
                    }
                }
            }
        }
        return f"data: {json.dumps(usage_message, ensure_ascii=False)}\n\n"
    
    def _create_final_result(self, content: str) -> str:
        """åˆ›å»ºæœ€ç»ˆç»“æœæ¶ˆæ¯"""
        final_response = {
            "jsonrpc": "2.0",
            "id": self.request_id,
            "result": {
                "content": content,
                "tool": self.tool_name
            }
        }
        return f"data: {json.dumps(final_response, ensure_ascii=False)}\n\n"
    
    # ========== åŸæœ¬agentçš„æ ¸å¿ƒæ–¹æ³•é›†æˆ ==========
    
    async def _generate_initial_queries_enhanced(self, industry: str, days: int, focus_areas: list) -> Dict[str, Any]:
        """ä½¿ç”¨åŸæœ¬agentçš„æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆé€»è¾‘"""
        try:
            if self.intelligent_agent is None:
                print("âŒ IntelligentReportAgent æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å¤‡ç”¨æŸ¥è¯¢")
                return {
                    "breaking_news": [],
                    "innovation_news": [],
                    "investment_news": [],
                    "policy_news": [],
                    "trend_news": [],
                    "company_news": [],
                    "total_count": 0
                }
            # ä½¿ç”¨åŸæœ¬agentçš„å¤šæ¸ é“æ•´åˆæœç´¢
            return self.intelligent_agent._parse_query_strategy("", industry, days, focus_areas)
        except Exception as e:
            print(f"æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {str(e)}")
            # é™çº§åˆ°åŸºç¡€æœç´¢
            if self.intelligent_agent:
                return self.intelligent_agent._get_fallback_queries(industry, days, focus_areas)
            else:
                return {
                    "breaking_news": [],
                    "innovation_news": [],
                    "investment_news": [],
                    "policy_news": [],
                    "trend_news": [],
                    "company_news": [],
                    "total_count": 0
                }
    
    async def _reflect_on_information_gaps_enhanced(self, collected_data: Dict[str, Any], industry: str, days: int) -> tuple:
        """ä½¿ç”¨åŸæœ¬agentçš„åæ€ä¸çŸ¥è¯†ç¼ºå£åˆ†æ"""
        try:
            return self.intelligent_agent.reflect_on_information_gaps(collected_data, industry, days)
        except Exception as e:
            print(f"åæ€åˆ†æå¤±è´¥: {str(e)}")
            return [], True  # å‡ºé”™æ—¶å‡è®¾ä¿¡æ¯å……åˆ†
    
    async def _generate_targeted_queries_enhanced(self, gaps: list, industry: str, days: int) -> Dict[str, Any]:
        """ä½¿ç”¨åŸæœ¬agentçš„é’ˆå¯¹æ€§æŸ¥è¯¢ç”Ÿæˆ"""
        try:
            return self.intelligent_agent.generate_targeted_queries(gaps, industry, days)
        except Exception as e:
            print(f"é’ˆå¯¹æ€§æŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self.intelligent_agent._fallback_targeted_search(industry, days)
    
    def _merge_data_enhanced(self, existing_data: Dict[str, Any], new_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨åŸæœ¬agentçš„æ•°æ®åˆå¹¶é€»è¾‘"""
        try:
            return self.intelligent_agent._merge_data(existing_data, new_data)
        except Exception as e:
            print(f"æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            return existing_data
    
    async def _process_collected_data_enhanced(self, all_news_data: Dict[str, Any], industry: str, days: int) -> Dict[str, Any]:
        """ä½¿ç”¨åŸæœ¬agentçš„æ™ºèƒ½å»é‡å’Œæ—¶é—´è¿‡æ»¤"""
        try:
            processed_data = all_news_data.copy()
            
            # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œæ™ºèƒ½å»é‡
            for category in ["breaking_news", "innovation_news", "investment_news", "policy_news", "trend_news", "perspective_analysis"]:
                if processed_data.get(category):
                    processed_data[category] = self.intelligent_agent._deduplicate_by_content(
                        processed_data[category], category
                    )
            
            # é‡æ–°è®¡ç®—æ€»æ•°
            processed_data["total_count"] = sum(
                len(processed_data[key]) for key in processed_data.keys() 
                if key != "total_count" and isinstance(processed_data[key], list)
            )
            
            return processed_data
        except Exception as e:
            print(f"æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
            return all_news_data
    
    async def _process_breaking_news_enhanced(self, industry: str, breaking_news: list, days: int) -> str:
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆé‡å¤§äº‹ä»¶åˆ†æ"""
        try:
            if not breaking_news:
                return f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶\n\nğŸ“Š **åˆ†æè¯´æ˜**: åœ¨å½“å‰æ—¶é—´çª—å£å†…ï¼Œæš‚æœªå‘ç°{industry}è¡Œä¸šçš„é‡å¤§çªå‘äº‹ä»¶ã€‚\n\n"
            
            print(f"ğŸ” [æ·±åº¦åˆ†æ] æ­£åœ¨åˆ†æ{len(breaking_news)}æ¡é‡å¤§äº‹ä»¶...")
            
            # æ„å»ºæ–°é—»æ•°æ®
            news_data = []
            for item in breaking_news[:5]:  # åªå–å‰5æ¡
                news_data.append({
                    "title": item.get('title', 'æ— æ ‡é¢˜'),
                    "content": item.get('content', 'æ— å†…å®¹')[:500],
                    "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                    "url": item.get('url', '#')
                })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”Ÿæˆé‡å¤§äº‹ä»¶åˆ†æ...")
                content = content_writer_mcp(
                    section_title="è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ",
                    content_data=news_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="è¡Œä¸šåˆ†æå¸ˆ"
                )
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                import traceback
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                traceback.print_exc()
                content = f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶\n\nåŸºäºæ”¶é›†çš„{len(breaking_news)}æ¡é‡å¤§äº‹ä»¶ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
            
            # æ·»åŠ ä¿¡æ¯æ¥æº
            print(f"ğŸ” [è°ƒè¯•] å¼€å§‹æ·»åŠ ä¿¡æ¯æ¥æºï¼Œbreaking_newsæ•°é‡: {len(breaking_news)}")
            sources = []
            for item in breaking_news:
                if item.get('url', '#') != '#':
                    sources.append(f"- [{item.get('title', 'æœªçŸ¥æ ‡é¢˜')}]({item.get('url')}) - {item.get('source', 'æœªçŸ¥æ¥æº')}")
            
            print(f"ğŸ” [è°ƒè¯•] æ”¶é›†åˆ°{len(sources)}ä¸ªä¿¡æ¯æ¥æº")
            if sources:
                content += "\n\n**ä¿¡æ¯æ¥æº:**\n" + "\n".join(sources)
                print(f"ğŸ” [è°ƒè¯•] ä¿¡æ¯æ¥æºæ·»åŠ å®Œæˆï¼Œæœ€ç»ˆå†…å®¹é•¿åº¦: {len(content)}")
            
            final_result = f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ\n\n{content}\n\n"
            print(f"ğŸ” [è°ƒè¯•] å‡†å¤‡è¿”å›æœ€ç»ˆç»“æœï¼Œé•¿åº¦: {len(final_result)}")
            return final_result
            
        except Exception as e:
            print(f"é‡å¤§äº‹ä»¶åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶\n\né‡å¤§äº‹ä»¶åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n"
    
    async def _process_innovation_news_enhanced(self, industry: str, innovation_news: list) -> str:
        """ä½¿ç”¨MCPå·¥å…·ç”ŸæˆæŠ€æœ¯åˆ›æ–°åˆ†æ"""
        try:
            print(f"ğŸ” [è°ƒè¯•] _process_innovation_news_enhancedå¼€å§‹ï¼Œæ•°æ®: {len(innovation_news)}æ¡")
            if not innovation_news:
                print(f"ğŸ” [è°ƒè¯•] innovation_newsä¸ºç©ºï¼Œè¿”å›é»˜è®¤å†…å®¹")
                return f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šæŠ€æœ¯åˆ›æ–°æ´»åŠ¨ç›¸å¯¹å¹³é™ã€‚\n\n"
            
            print(f"ğŸ§ª [æŠ€æœ¯åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(innovation_news)}é¡¹æŠ€æœ¯åˆ›æ–°...")
            print(f"ğŸ” [è°ƒè¯•] å‰2æ¡æ•°æ®: {innovation_news[:2]}")
            
            # æ„å»ºæŠ€æœ¯æ•°æ®
            tech_data = []
            for item in innovation_news[:5]:  # åªå–å‰5æ¡
                tech_data.append({
                    "title": item.get('title', 'æ— æ ‡é¢˜'),
                    "content": item.get('content', 'æ— å†…å®¹')[:500],
                    "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                    "url": item.get('url', '#')
                })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”ŸæˆæŠ€æœ¯åˆ›æ–°åˆ†æ...")
                content = await asyncio.to_thread(
                    content_writer_mcp,
                    section_title="æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“æ·±åº¦è§£æ",
                    content_data=tech_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="æŠ€æœ¯ä¸“å®¶"
                )
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“\n\nåŸºäºæ”¶é›†çš„{len(innovation_news)}æ¡æŠ€æœ¯åˆ›æ–°ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
            
            return f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“æ·±åº¦è§£æ\n\n{content}\n\n"
            
        except Exception as e:
            print(f"æŠ€æœ¯åˆ›æ–°åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“\n\næŠ€æœ¯åˆ›æ–°åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n"
    
    async def _process_investment_news_enhanced(self, industry: str, investment_news: list) -> str:
        """ä½¿ç”¨MCPå·¥å…·ç”ŸæˆæŠ•èµ„åŠ¨æ€åˆ†æ"""
        try:
            if not investment_news:
                return f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šæŠ•èµ„æ´»åŠ¨ç›¸å¯¹å¹³é™ã€‚\n\n"
            
            print(f"ğŸ’° [æŠ•èµ„åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(investment_news)}é¡¹æŠ•èµ„åŠ¨æ€...")
            
            # æ„å»ºæŠ•èµ„æ•°æ®
            investment_data = []
            for item in investment_news[:5]:  # åªå–å‰5æ¡
                investment_data.append({
                    "title": item.get('title', 'æ— æ ‡é¢˜'),
                    "content": item.get('content', 'æ— å†…å®¹')[:500],
                    "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                    "url": item.get('url', '#')
                })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”ŸæˆæŠ•èµ„åŠ¨æ€åˆ†æ...")
                content = await asyncio.to_thread(
                    content_writer_mcp,
                    section_title="æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘æ·±åº¦è§£æ",
                    content_data=investment_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="æŠ•èµ„åˆ†æå¸ˆ"
                )
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘\n\nåŸºäºæ”¶é›†çš„{len(investment_news)}æ¡æŠ•èµ„åŠ¨æ€ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
            
            return f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘æ·±åº¦è§£æ\n\n{content}\n\n"
            
        except Exception as e:
            print(f"æŠ•èµ„åŠ¨æ€åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘\n\næŠ•èµ„åŠ¨æ€åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n"
    
    async def _process_policy_news_enhanced(self, industry: str, policy_news: list) -> str:
        """ä½¿ç”¨åŸæœ¬agentçš„æ”¿ç­–ç›‘ç®¡åˆ†æé€»è¾‘"""
        try:
            return self.intelligent_agent._process_policy_news_enhanced(industry, policy_news)
        except Exception as e:
            print(f"æ”¿ç­–ç›‘ç®¡åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ“œ æ”¿ç­–ä¸ç›‘ç®¡åŠ¨æ€\n\næ”¿ç­–ç›‘ç®¡åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n"
    
    async def _process_industry_trends_enhanced(self, industry: str, trend_news: list, days: int) -> str:
        """ä½¿ç”¨åŸæœ¬agentçš„è¡Œä¸šè¶‹åŠ¿åˆ†æé€»è¾‘"""
        try:
            return self.intelligent_agent._process_industry_trends_enhanced(industry, trend_news, days)
        except Exception as e:
            print(f"è¡Œä¸šè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿æ·±åº¦åˆ†æ\n\nè¡Œä¸šè¶‹åŠ¿åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n"
    
    async def _process_perspective_analysis_enhanced(self, industry: str, perspective_data: list) -> str:
        """ä½¿ç”¨åŸæœ¬agentçš„è§‚ç‚¹å¯¹æ¯”åˆ†æé€»è¾‘"""
        try:
            return self.intelligent_agent._process_perspective_analysis_enhanced(industry, perspective_data)
        except Exception as e:
            print(f"è§‚ç‚¹å¯¹æ¯”åˆ†æå¤±è´¥: {str(e)}")
            return f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\nè§‚ç‚¹å¯¹æ¯”åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n"
    
    async def _generate_intelligent_summary_enhanced(self, industry: str, processed_data: Dict[str, Any], days: int) -> str:
        """ä½¿ç”¨åŸæœ¬agentçš„æ™ºèƒ½æ€»ç»“ç”Ÿæˆé€»è¾‘"""
        try:
            return self.intelligent_agent._generate_intelligent_summary(industry, processed_data, days)
        except Exception as e:
            print(f"æ™ºèƒ½æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"## ğŸ§  AIæ™ºèƒ½åˆ†ææ€»ç»“\n\n{industry}è¡Œä¸šæ­£å¤„äºåŠ¨æ€å‘å±•é˜¶æ®µï¼ŒAIåˆ†ææ˜¾ç¤ºå¤šä¸ªç»´åº¦éƒ½æœ‰é‡è¦å˜åŒ–å€¼å¾—å…³æ³¨ã€‚\n\n"
    
    def _assemble_enhanced_report(self, industry: str, intelligent_summary: str, section_contents: Dict[str, str], processed_data: Dict[str, Any], days: int) -> str:
        """ç»„è£…å¢å¼ºç‰ˆæŠ¥å‘Šï¼Œé›†æˆåŸæœ¬agentçš„æ ¼å¼"""
        try:
            # ä½¿ç”¨åŸæœ¬agentçš„æŠ¥å‘Šç»„è£…é€»è¾‘
            date_str = datetime.now().strftime('%Y-%m-%d')
            
            # æ„å»ºæŠ¥å‘Šå¤´éƒ¨
            content = f"# {industry}è¡Œä¸šæ™ºèƒ½åˆ†ææŠ¥å‘Š\n\n"
            content += f"*æœ¬æŠ¥å‘Šç”±AIæ™ºèƒ½ä»£ç†ç”Ÿæˆï¼Œå…·å¤‡æ·±åº¦æ€è€ƒå’Œåæ€èƒ½åŠ›*\n\n"
            content += f"æŠ¥å‘Šæ—¥æœŸ: {date_str}\n\n"
            
            # æ·»åŠ æŠ¥å‘Šæ¦‚è¿°
            content += f"""## ğŸ“‹ æŠ¥å‘Šæ¦‚è¿°

æœ¬æŠ¥å‘Šé‡‡ç”¨AIæ™ºèƒ½ä»£ç†çš„äº”æ­¥åˆ†ææ³•ï¼Œå¯¹{industry}è¡Œä¸šè¿›è¡Œå…¨æ–¹ä½æ·±åº¦è§£æã€‚é€šè¿‡æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆã€
å¤šç»´ä¿¡æ¯æœé›†ã€åæ€å¼ç¼ºå£åˆ†æã€è¿­ä»£ä¼˜åŒ–æœç´¢å’Œç»¼åˆæŠ¥å‘Šç”Ÿæˆï¼Œç¡®ä¿ä¿¡æ¯çš„å…¨é¢æ€§å’Œåˆ†æçš„æ·±åº¦ã€‚

**æŠ¥å‘Šç‰¹è‰²ï¼š**
- ğŸ§  æ·±åº¦æ€è€ƒï¼šæ¨¡æ‹Ÿä¸“å®¶çº§åˆ†æå¸ˆçš„æ€ç»´è¿‡ç¨‹
- ğŸ”„ å¤šè½®è¿­ä»£ï¼šé€šè¿‡åæ€æœºåˆ¶ç¡®ä¿ä¿¡æ¯å……åˆ†æ€§
- ğŸ¯ é’ˆå¯¹æ€§å¼ºï¼šæ ¹æ®è¯†åˆ«çš„çŸ¥è¯†ç¼ºå£è¿›è¡Œè¡¥å……æœç´¢
- ğŸ“Š æ•°æ®ä¸°å¯Œï¼šæ•´åˆå¤šæºä¿¡æ¯ï¼Œæä¾›å…¨é¢è§†è§’
- ğŸ”® å‰ç»æ€§å¼ºï¼šä¸ä»…åˆ†æç°çŠ¶ï¼Œæ›´é¢„æµ‹æœªæ¥è¶‹åŠ¿

---

"""
            
            # æ·»åŠ å„ä¸ªç« èŠ‚
            for section_name, section_content in section_contents.items():
                content += section_content + "\n"
            
            # æ·»åŠ æ™ºèƒ½æ€»ç»“
            content += intelligent_summary + "\n"
            
            # æ·»åŠ å‚è€ƒèµ„æ–™
            content += self.intelligent_agent._generate_references(processed_data)
            
            return content
        except Exception as e:
            print(f"æŠ¥å‘Šç»„è£…å¤±è´¥: {str(e)}")
            return f"# {industry}è¡Œä¸šåˆ†ææŠ¥å‘Š\n\næŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    
    def _create_error_message(self, error: str) -> str:
        """åˆ›å»ºé”™è¯¯æ¶ˆæ¯"""
        error_response = {
            "jsonrpc": "2.0",
            "id": self.request_id,
            "error": {
                "code": -32603,
                "message": "Internal error",
                "data": {
                    "type": "report_generation_failed",
                    "message": error
                }
            }
        }
        return f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n"
    
    def _extract_topic_from_task(self, task: str) -> str:
        """ä»ä»»åŠ¡æè¿°ä¸­æå–ä¸»é¢˜"""
        stop_words = ["ç”Ÿæˆ", "åˆ†æ", "æŠ¥å‘Š", "ç ”ç©¶", "å†™", "åˆ›å»º", "åˆ¶ä½œ", "è¡Œä¸š", "åŠ¨æ€", "æ–°é—»"]
        words = task.split()
        topic_words = [word for word in words if word not in stop_words]
        return " ".join(topic_words[:3]) if topic_words else "è¡Œä¸šåˆ†æ"
    
    def _assemble_report(self, topic: str, executive_summary: str, section_contents: Dict[str, str]) -> str:
        """ç»„è£…æœ€ç»ˆæŠ¥å‘Š"""
        report = f"# {topic}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š\n\n"
        report += f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        report += "## ğŸ” æ‰§è¡Œæ‘˜è¦\n\n"
        report += executive_summary + "\n\n"
        
        for section_title, content in section_contents.items():
            report += f"## {section_title}\n\n"
            report += content + "\n\n"
        
        report += "---\n\n*æœ¬æŠ¥å‘Šç”±MCPæ™ºèƒ½è°ƒåº¦å™¨ç”Ÿæˆï¼Œæ•´åˆäº†æ„å›¾è¯†åˆ«ã€å¤§çº²ç”Ÿæˆã€å†…å®¹æ£€ç´¢ã€è´¨é‡è¯„ä¼°ç­‰å¤šä¸ªMCPå·¥å…·*"
        return report
    
    def _get_local_data(self, industry: str) -> list:
        """è·å–æœ¬åœ°é¢„è®¾æ•°æ®"""
        # æ–°èƒ½æºæ±½è½¦è¡Œä¸šçš„æœ¬åœ°æ•°æ®
        if "æ–°èƒ½æº" in industry or "æ±½è½¦" in industry:
            return [
                {
                    "title": "ç‰¹æ–¯æ‹‰2025å¹´Q3äº¤ä»˜é‡åˆ›æ–°é«˜",
                    "content": "ç‰¹æ–¯æ‹‰å…¬å¸ƒ2025å¹´ç¬¬ä¸‰å­£åº¦å…¨çƒäº¤ä»˜é‡è¾¾åˆ°45.2ä¸‡è¾†ï¼ŒåŒæ¯”å¢é•¿23%ï¼Œåˆ›å†å²æ–°é«˜ã€‚",
                    "source": "ç‰¹æ–¯æ‹‰å®˜æ–¹",
                    "url": "https://example.com/tesla-q3-2025",
                    "category": "breaking_news",
                    "date": "2025-01-05"
                },
                {
                    "title": "æ¯”äºšè¿ªå›ºæ€ç”µæ± æŠ€æœ¯çªç ´",
                    "content": "æ¯”äºšè¿ªå®£å¸ƒåœ¨å›ºæ€ç”µæ± æŠ€æœ¯æ–¹é¢å–å¾—é‡å¤§çªç ´ï¼Œèƒ½é‡å¯†åº¦æå‡40%ï¼Œé¢„è®¡2026å¹´é‡äº§ã€‚",
                    "source": "æ¯”äºšè¿ªå®˜æ–¹",
                    "url": "https://example.com/byd-solid-battery",
                    "category": "innovation_news",
                    "date": "2025-01-04"
                },
                {
                    "title": "è”šæ¥è·å¾—50äº¿å…ƒæˆ˜ç•¥æŠ•èµ„",
                    "content": "è”šæ¥æ±½è½¦å®£å¸ƒè·å¾—æ¥è‡ªæŸå¤§å‹æŠ•èµ„æœºæ„çš„50äº¿å…ƒæˆ˜ç•¥æŠ•èµ„ï¼Œå°†ç”¨äºæŠ€æœ¯ç ”å‘å’Œå¸‚åœºæ‰©å¼ ã€‚",
                    "source": "è”šæ¥å®˜æ–¹",
                    "url": "https://example.com/nio-investment",
                    "category": "investment_news",
                    "date": "2025-01-03"
                },
                {
                    "title": "å›½å®¶å‘æ”¹å§”å‘å¸ƒæ–°èƒ½æºæ±½è½¦æ–°æ”¿ç­–",
                    "content": "å›½å®¶å‘æ”¹å§”å‘å¸ƒã€Šå…³äºè¿›ä¸€æ­¥ä¿ƒè¿›æ–°èƒ½æºæ±½è½¦äº§ä¸šå‘å±•çš„æŒ‡å¯¼æ„è§ã€‹ï¼Œæå‡ºå¤šé¡¹æ”¯æŒæªæ–½ã€‚",
                    "source": "å›½å®¶å‘æ”¹å§”",
                    "url": "https://example.com/ndrc-policy",
                    "category": "policy_news",
                    "date": "2025-01-02"
                },
                {
                    "title": "2025å¹´æ–°èƒ½æºæ±½è½¦å¸‚åœºè¶‹åŠ¿åˆ†æ",
                    "content": "æ ¹æ®æœ€æ–°å¸‚åœºè°ƒç ”ï¼Œ2025å¹´æ–°èƒ½æºæ±½è½¦å¸‚åœºé¢„è®¡å°†ä¿æŒ30%ä»¥ä¸Šçš„å¢é•¿ç‡ï¼Œæ¸—é€ç‡æœ‰æœ›çªç ´50%ã€‚",
                    "source": "å¸‚åœºç ”ç©¶æœºæ„",
                    "url": "https://example.com/market-trend",
                    "category": "trend_news",
                    "date": "2025-01-01"
                }
            ]
        else:
            # å…¶ä»–è¡Œä¸šçš„é€šç”¨æ•°æ®
            return [
                {
                    "title": f"{industry}è¡Œä¸šæœ€æ–°åŠ¨æ€",
                    "content": f"è¿™æ˜¯{industry}è¡Œä¸šçš„æœ€æ–°åŠ¨æ€ä¿¡æ¯ï¼ŒåŸºäºæœ¬åœ°æ•°æ®ç”Ÿæˆã€‚",
                    "source": "æœ¬åœ°æ•°æ®æº",
                    "url": "https://example.com/local-data",
                    "category": "breaking_news",
                    "date": "2025-01-05"
                }
            ]
    
    async def _generate_report_from_local_data(self, local_data: list, industry: str) -> str:
        """åŸºäºæœ¬åœ°æ•°æ®ç”ŸæˆæŠ¥å‘Š"""
        try:
            # æŒ‰ç±»åˆ«åˆ†ç»„æ•°æ®
            categories = {}
            for item in local_data:
                category = item.get('category', 'other')
                if category not in categories:
                    categories[category] = []
                categories[category].append(item)
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report = f"# {industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š\n\n"
            report += f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            report += f"**æ•°æ®æ¥æº**: æœ¬åœ°æ•°æ®\n"
            report += f"**æ•°æ®æ¡æ•°**: {len(local_data)}\n\n"
            
            # æŒ‰ç±»åˆ«ç”Ÿæˆå†…å®¹
            for category, items in categories.items():
                if category == "breaking_news":
                    report += "## ğŸš¨ é‡å¤§äº‹ä»¶\n\n"
                elif category == "innovation_news":
                    report += "## ğŸ’¡ æŠ€æœ¯åˆ›æ–°\n\n"
                elif category == "investment_news":
                    report += "## ğŸ’° æŠ•èµ„åŠ¨æ€\n\n"
                elif category == "policy_news":
                    report += "## ğŸ“‹ æ”¿ç­–æ³•è§„\n\n"
                elif category == "trend_news":
                    report += "## ğŸ“ˆ å¸‚åœºè¶‹åŠ¿\n\n"
                else:
                    report += f"## ğŸ“Š {category}\n\n"
                
                for item in items:
                    report += f"### {item['title']}\n\n"
                    report += f"{item['content']}\n\n"
                    if item.get('url') and item['url'] != 'https://example.com/local-data':
                        report += f"**æ¥æº**: [{item['source']}]({item['url']})\n\n"
                    else:
                        report += f"**æ¥æº**: {item['source']}\n\n"
            
            return report
            
        except Exception as e:
            print(f"æœ¬åœ°æ•°æ®æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"# {industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š\n\nåŸºäºæœ¬åœ°æ•°æ®ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
