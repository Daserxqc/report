#!/usr/bin/env python3
"""
æ”¯æŒå®æ—¶SSEæ¨é€çš„MCPè°ƒåº¦å™¨
"""

import json
import asyncio
from typing import Dict, Any, AsyncGenerator
from datetime import datetime

# å¯¼å…¥ç°æœ‰çš„MCPå·¥å…·å‡½æ•°
from main import (
    analysis_mcp, query_generation_mcp, outline_writer_mcp, 
    summary_writer_mcp, content_writer_mcp, parallel_search,
    orchestrator_mcp, orchestrator_mcp_simple, llm_processor
)

class StreamingOrchestrator:
    """æ”¯æŒå®æ—¶SSEæ¨é€çš„MCPè°ƒåº¦å™¨ - åŸºäºMCPå·¥å…·çš„çº¯å‡€å®ç°"""
    
    def __init__(self):
        self.request_id = 1
        self.tool_name = ""
        print("âœ… StreamingOrchestrator åˆå§‹åŒ–æˆåŠŸ (åŸºäºMCPå·¥å…·)")
    
    async def _call_content_writer_with_usage(self, **kwargs):
        """è°ƒç”¨content_writer_mcpå¹¶å¤„ç†usageä¿¡æ¯"""
        try:
            result = await asyncio.to_thread(content_writer_mcp, **kwargs)
            print(f"ğŸ” [è°ƒè¯•] content_writer_mcpè¿”å›ç»“æœ: {str(result)[:200]}...")
            
            # content_writer_mcpç°åœ¨è¿”å›JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«contentå’Œusage
            try:
                import json
                result_data = json.loads(result)
                content = result_data.get('content', result)  # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ
                usage = result_data.get('usage', None)
                print(f"ğŸ” [è°ƒè¯•] è§£æJSONæˆåŠŸï¼Œè·å–åˆ°usage: {usage}")
                return content, usage
            except (json.JSONDecodeError, TypeError) as json_error:
                print(f"âš ï¸ [è°ƒè¯•] JSONè§£æå¤±è´¥: {json_error}ï¼Œä½¿ç”¨fallbackæ–¹å¼")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»llm_processorè·å–usage
                usage = None
                if hasattr(llm_processor, 'last_usage') and llm_processor.last_usage:
                    usage = llm_processor.last_usage
                    print(f"ğŸ” [è°ƒè¯•] ä»llm_processorè·å–åˆ°çš„usage: {usage}")
                return result, usage
        except Exception as e:
            raise e
    
    async def generate_industry_dynamic_report(self, request: Dict[str, Any]) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆè¡Œä¸šåŠ¨æ€æŠ¥å‘Š - å…¼å®¹MCPå·¥å…·è°ƒç”¨"""
        async for message in self.stream_industry_dynamic_report(request):
            yield message
    
    async def stream_industry_dynamic_report(self, request: Dict[str, Any]) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆè¡Œä¸šåŠ¨æ€æŠ¥å‘Š - åŸºäºMCPå·¥å…·çš„çº¯å‡€å®ç°"""
        self.tool_name = "generate_industry_dynamic_report"
        
        # å‘é€å¼€å§‹æ¶ˆæ¯
        try:
            yield self._create_progress_message("started", "å¼€å§‹ç”Ÿæˆè¡Œä¸šåŠ¨æ€æŠ¥å‘Š", "æ­£åœ¨åˆå§‹åŒ–MCPå·¥å…·é“¾...")
            await asyncio.sleep(0.1)
        except asyncio.CancelledError:
            print("ğŸ”Œ SSEå®¢æˆ·ç«¯å·²æ–­å¼€ï¼ˆå¼€å§‹é˜¶æ®µï¼‰ï¼Œç»ˆæ­¢æ¨é€")
            return
        
        try:
            industry = request.get("industry", "æœªæŒ‡å®šè¡Œä¸š")
            time_range = request.get("time_range", "recent")
            focus_areas = request.get("focus_areas", ["å¸‚åœºè¶‹åŠ¿", "æŠ€æœ¯åˆ›æ–°", "æ”¿ç­–å½±å“", "ç«äº‰æ ¼å±€"])
            days = request.get("days", 30)
            use_local_data = request.get("use_local_data", False)
            
            # å¦‚æœä½¿ç”¨æœ¬åœ°æ•°æ®ï¼Œè·³è¿‡ç½‘ç»œæœç´¢
            if use_local_data:
                yield self._create_progress_message("processing", "ä½¿ç”¨æœ¬åœ°æ•°æ®", "è·³è¿‡ç½‘ç»œæœç´¢ï¼Œä½¿ç”¨é¢„è®¾çš„æœ¬åœ°æ•°æ®...")
                await asyncio.sleep(0.1)
                
                # ä½¿ç”¨é¢„è®¾çš„æœ¬åœ°æ•°æ®
                local_data = self._get_local_data(industry)
                yield self._create_progress_message("completed", "æœ¬åœ°æ•°æ®åŠ è½½å®Œæˆ", f"åŠ è½½äº†{len(local_data)}æ¡æœ¬åœ°æ•°æ®")
                await asyncio.sleep(0.1)
                
                # ç›´æ¥è¿›å…¥å†…å®¹ç”Ÿæˆé˜¶æ®µ
                yield self._create_progress_message("processing", "ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", "åŸºäºæœ¬åœ°æ•°æ®ç”ŸæˆæŠ¥å‘Š...")
                await asyncio.sleep(0.1)
                
                # ç”ŸæˆæŠ¥å‘Šå†…å®¹
                report_content = await self._generate_report_from_local_data_mcp(local_data, industry)
                
                # å‘é€æœ€ç»ˆç»“æœ
                yield self._create_progress_message("completed", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ", "åŸºäºæœ¬åœ°æ•°æ®æˆåŠŸç”ŸæˆæŠ¥å‘Š")
                await asyncio.sleep(0.1)
                
                # å‘é€æœ€ç»ˆç»“æœ
                final_result = {
                    "type": "result",
                    "content": report_content,
                    "metadata": {
                        "industry": industry,
                        "data_source": "local",
                        "total_items": len(local_data)
                    }
                }
                yield f"data: {json.dumps(final_result, ensure_ascii=False)}\n\n"
                return
            
            # ========== ç¬¬ä¸€æ­¥ï¼šæ„å›¾åˆ†æå’Œä»»åŠ¡è§„åˆ’ ==========
            try:
                yield self._create_progress_message("processing", "æ„å›¾åˆ†æ", f"æ­£åœ¨åˆ†æ{industry}è¡Œä¸šæŠ¥å‘Šéœ€æ±‚...")
                await asyncio.sleep(0.1)
            except asyncio.CancelledError:
                print("ğŸ”Œ SSEå®¢æˆ·ç«¯å·²æ–­å¼€ï¼ˆæ„å›¾åˆ†æé˜¶æ®µï¼‰")
                return
            
            # ä½¿ç”¨analysis_mcpè¿›è¡Œæ„å›¾åˆ†æ
            task_description = f"ç”Ÿæˆ{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Šï¼Œæ—¶é—´èŒƒå›´ï¼š{days}å¤©ï¼Œå…³æ³¨é¢†åŸŸï¼š{', '.join(focus_areas)}"
            intent_result = await asyncio.to_thread(
                analysis_mcp,
                analysis_type="intent",
                data=task_description,
                context=f"è¡Œä¸šï¼š{industry}ï¼Œæ—¶é—´èŒƒå›´ï¼š{time_range}",
                task_planning="true",
                detailed_analysis="true"
            )
            
            try:
                yield self._create_progress_message("completed", "æ„å›¾åˆ†æå®Œæˆ", "å·²è¯†åˆ«æŠ¥å‘Šéœ€æ±‚å’Œç”Ÿæˆç­–ç•¥")
                await asyncio.sleep(0.1)
            except asyncio.CancelledError:
                print("ğŸ”Œ SSEå®¢æˆ·ç«¯å·²æ–­å¼€ï¼ˆæŸ¥è¯¢ç­–ç•¥å®Œæˆé˜¶æ®µï¼‰")
                return
            
            # ========== ç¬¬äºŒæ­¥ï¼šå¤šæ¸ é“ä¿¡æ¯æœé›† ==========
            yield self._create_progress_message("processing", "å¤šæ¸ é“ä¿¡æ¯æœé›†", "æ­£åœ¨æ•´åˆå¤šä¸ªæœç´¢å¼•æ“çš„ç»“æœ...")
            await asyncio.sleep(0.1)
            
            # ç”Ÿæˆåˆå§‹æŸ¥è¯¢å¹¶æœé›†æ•°æ®
            queries = await self._generate_initial_queries_enhanced(industry, days, focus_areas)
            # æ‰§è¡Œå®é™…æœç´¢è·å–æ–°é—»æ•°æ®
            all_news_data = await self._execute_search_queries_enhanced(queries, industry, days)
            print(f"ğŸ” [æœç´¢æ‰§è¡Œ] æœç´¢å®Œæˆï¼Œè·å¾—æ•°æ®: {all_news_data.get('total_count', 0)}æ¡")
            total_count = all_news_data.get('total_count', 0)
            if isinstance(total_count, int):
                count_str = str(total_count)
            else:
                count_str = str(len(total_count)) if hasattr(total_count, '__len__') else "0"
            yield self._create_progress_message("completed", "ä¿¡æ¯æœé›†å®Œæˆ", f"è·å¾—{count_str}æ¡ä¿¡æ¯")
            await asyncio.sleep(0.1)
            
            # ========== ç¬¬ä¸‰æ­¥ï¼šåæ€ä¸çŸ¥è¯†ç¼ºå£åˆ†æ ==========
            iteration_count = 0
            max_iterations = 3  # æœ€å¤š3è½®è¿­ä»£
            
            while iteration_count < max_iterations:
                iteration_count += 1
                yield self._create_progress_message("processing", f"åæ€åˆ†æ (ç¬¬{iteration_count}è½®)", "æ­£åœ¨åˆ†æä¿¡æ¯å®Œæ•´æ€§å’Œè´¨é‡...")
                await asyncio.sleep(0.1)
                
                gaps, is_sufficient = await self._reflect_on_information_gaps_enhanced(all_news_data, industry, days)
                
                if is_sufficient:
                    yield self._create_progress_message("completed", "ä¿¡æ¯å……åˆ†æ€§ç¡®è®¤", "ä¿¡æ¯æ”¶é›†å……åˆ†ï¼Œå‡†å¤‡ç”ŸæˆæŠ¥å‘Š")
                    await asyncio.sleep(0.1)
                    break
                
                if iteration_count < max_iterations:
                    yield self._create_progress_message("processing", f"è¡¥å……æœç´¢ (ç¬¬{iteration_count}è½®)", "æ­£åœ¨ç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢è¡¥å……ä¿¡æ¯ç¼ºå£...")
                    await asyncio.sleep(0.1)
                    
                    additional_data = await self._generate_targeted_queries_enhanced(gaps, industry, days)
                    if additional_data:
                        old_total = all_news_data.get('total_count', 0)
                        all_news_data = self._merge_data_enhanced(all_news_data, additional_data)
                        new_total = all_news_data.get('total_count', 0)
                        yield self._create_progress_message("completed", f"ç¬¬{iteration_count}è½®è¡¥å……å®Œæˆ", f"æ–°å¢{new_total - old_total}æ¡æ•°æ®ï¼Œæ€»é‡: {new_total}")
                        await asyncio.sleep(0.1)
                    else:
                        yield self._create_progress_message("completed", f"ç¬¬{iteration_count}è½®å®Œæˆ", "æœ¬è½®æœªè·å¾—æ–°æ•°æ®")
                        await asyncio.sleep(0.1)
                else:
                    yield self._create_progress_message("completed", "è¾¾åˆ°è¿­ä»£ä¸Šé™", "å·²å®Œæˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼€å§‹ç”ŸæˆæŠ¥å‘Š")
                    await asyncio.sleep(0.1)
            
            # ========== ç¬¬å››æ­¥ï¼šæ·±åº¦å†…å®¹åˆ†æ ==========
            yield self._create_progress_message("processing", "æ·±åº¦å†…å®¹åˆ†æ", "æ­£åœ¨å¯¹æ”¶é›†çš„ä¿¡æ¯è¿›è¡Œæ™ºèƒ½åˆ†æå’Œå»é‡...")
            await asyncio.sleep(0.1)
            
            # æ™ºèƒ½å»é‡å’Œæ—¶é—´è¿‡æ»¤
            processed_data = await self._process_collected_data_enhanced(all_news_data, industry, days)
            total_count = processed_data.get('total_count', 0)
            if isinstance(total_count, int):
                count_str = str(total_count)
            else:
                count_str = str(len(total_count)) if hasattr(total_count, '__len__') else "0"
            yield self._create_progress_message("completed", "å†…å®¹åˆ†æå®Œæˆ", f"å¤„ç†å®Œæˆï¼Œä¿ç•™{count_str}æ¡é«˜è´¨é‡ä¿¡æ¯")
            await asyncio.sleep(0.1)
            
            # ========== ç¬¬äº”æ­¥ï¼šç»¼åˆæŠ¥å‘Šç”Ÿæˆ ==========
            yield self._create_progress_message("processing", "ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", "æ­£åœ¨ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š...")
            await asyncio.sleep(0.1)
            
            # ç”Ÿæˆå„ä¸ªç« èŠ‚
            section_contents = {}
            
            # 1. é‡å¤§äº‹ä»¶åˆ†æ
            breaking_news = processed_data.get("breaking_news", [])
            print(f"ğŸ” [è°ƒè¯•] breaking_newsæ•°æ®: {len(breaking_news)}æ¡")
            if breaking_news and len(breaking_news) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆé‡å¤§äº‹ä»¶åˆ†æ", "æ­£åœ¨æ·±åº¦åˆ†æè¡Œä¸šé‡å¤§äº‹ä»¶...")
                await asyncio.sleep(0.1)
                try:
                    # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                    llm_processor.last_usage = None
                    content, usage = await self._process_breaking_news_enhanced(industry, breaking_news, days)
                    section_contents["é‡å¤§äº‹ä»¶"] = content
                    # å‘é€æ¨¡å‹ç”¨é‡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰usageä¿¡æ¯ï¼‰
                    if usage:
                        print(f"ğŸ” [è°ƒè¯•] é‡å¤§äº‹ä»¶åˆ†æç”¨é‡: {usage}")
                        yield self._create_model_usage_message(usage_data=usage)
                    else:
                        print("â„¹ï¸ [usage] é‡å¤§äº‹ä»¶åˆ†ææœªè¿”å›usageä¿¡æ¯")
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "é‡å¤§äº‹ä»¶åˆ†æå®Œæˆ", "æ·±åº¦åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ é‡å¤§äº‹ä»¶åˆ†æå¤±è´¥: {str(e)}")
                    yield self._create_progress_message("error", "é‡å¤§äº‹ä»¶åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] breaking_newsä¸ºç©ºï¼Œè·³è¿‡é‡å¤§äº‹ä»¶åˆ†æ")
                yield self._create_progress_message("skipped", "é‡å¤§äº‹ä»¶åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— é‡å¤§äº‹ä»¶")
                await asyncio.sleep(0.1)
            
            # 2. æŠ€æœ¯åˆ›æ–°åˆ†æ
            innovation_news = processed_data.get("innovation_news", [])
            print(f"ğŸ” [è°ƒè¯•] innovation_newsæ•°æ®: {len(innovation_news)}æ¡")
            print(f"ğŸ” [è°ƒè¯•] innovation_newså†…å®¹: {innovation_news[:2] if innovation_news else 'æ— æ•°æ®'}")
            if innovation_news and len(innovation_news) > 0:
                yield self._create_progress_message("processing", "ç”ŸæˆæŠ€æœ¯åˆ›æ–°åˆ†æ", "æ­£åœ¨åˆ†ææŠ€æœ¯åˆ›æ–°å’Œçªç ´...")
                await asyncio.sleep(0.1)
                try:
                    # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                    llm_processor.last_usage = None
                    content, usage = await self._process_innovation_news_enhanced(industry, innovation_news)
                    section_contents["æŠ€æœ¯åˆ›æ–°"] = content
                    # å‘é€æ¨¡å‹ç”¨é‡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰usageä¿¡æ¯ï¼‰
                    if usage:
                        print(f"ğŸ” [è°ƒè¯•] æŠ€æœ¯åˆ›æ–°åˆ†æç”¨é‡: {usage}")
                        yield self._create_model_usage_message(usage_data=usage)
                    else:
                        print("â„¹ï¸ [usage] æŠ€æœ¯åˆ›æ–°åˆ†ææœªè¿”å›usageä¿¡æ¯")
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "æŠ€æœ¯åˆ›æ–°åˆ†æå®Œæˆ", "æŠ€æœ¯åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ æŠ€æœ¯åˆ›æ–°åˆ†æå¤±è´¥: {str(e)}")
                    section_contents["æŠ€æœ¯åˆ›æ–°"] = f"## ğŸ§ª æŠ€æœ¯åˆ›æ–°åˆ†æ\n\n{industry}è¡Œä¸šæŠ€æœ¯åˆ›æ–°åˆ†ææš‚æ—¶æ— æ³•ç”Ÿæˆï¼Œè¯·ç¨åé‡è¯•ã€‚\n\n"
                    yield self._create_progress_message("error", "æŠ€æœ¯åˆ›æ–°åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] innovation_newsä¸ºç©ºï¼Œè·³è¿‡æŠ€æœ¯åˆ›æ–°åˆ†æ")
                yield self._create_progress_message("skipped", "æŠ€æœ¯åˆ›æ–°åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— æŠ€æœ¯åˆ›æ–°ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 3. æŠ•èµ„åŠ¨æ€åˆ†æ
            investment_news = processed_data.get("investment_news", [])
            print(f"ğŸ” [è°ƒè¯•] investment_newsæ•°æ®: {len(investment_news)}æ¡")
            if investment_news and len(investment_news) > 0:
                yield self._create_progress_message("processing", "ç”ŸæˆæŠ•èµ„åŠ¨æ€åˆ†æ", "æ­£åœ¨åˆ†ææŠ•èµ„å’Œå¸‚åœºåŠ¨å‘...")
                await asyncio.sleep(0.1)
                try:
                    # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                    llm_processor.last_usage = None
                    content, usage = await self._process_investment_news_enhanced(industry, investment_news)
                    section_contents["æŠ•èµ„åŠ¨æ€"] = content
                    # å‘é€æ¨¡å‹ç”¨é‡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰usageä¿¡æ¯ï¼‰
                    if usage:
                        print(f"ğŸ” [è°ƒè¯•] æŠ•èµ„åŠ¨æ€åˆ†æç”¨é‡: {usage}")
                        yield self._create_model_usage_message(usage_data=usage)
                    else:
                        print("â„¹ï¸ [usage] æŠ•èµ„åŠ¨æ€åˆ†ææœªè¿”å›usageä¿¡æ¯")
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "æŠ•èµ„åŠ¨æ€åˆ†æå®Œæˆ", "æŠ•èµ„åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ æŠ•èµ„åŠ¨æ€åˆ†æå¤±è´¥: {str(e)}")
                    section_contents["æŠ•èµ„åŠ¨æ€"] = f"## ğŸ’° æŠ•èµ„åŠ¨æ€åˆ†æ\n\n{industry}è¡Œä¸šæŠ•èµ„åŠ¨æ€åˆ†ææš‚æ—¶æ— æ³•ç”Ÿæˆï¼Œè¯·ç¨åé‡è¯•ã€‚\n\n"
                    yield self._create_progress_message("error", "æŠ•èµ„åŠ¨æ€åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] investment_newsä¸ºç©ºï¼Œè·³è¿‡æŠ•èµ„åŠ¨æ€åˆ†æ")
                yield self._create_progress_message("skipped", "æŠ•èµ„åŠ¨æ€åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— æŠ•èµ„åŠ¨æ€ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 4. æ”¿ç­–ç›‘ç®¡åˆ†æ
            policy_news = processed_data.get("policy_news", [])
            print(f"ğŸ” [è°ƒè¯•] policy_newsæ•°æ®: {len(policy_news)}æ¡")
            if policy_news and len(policy_news) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆæ”¿ç­–ç›‘ç®¡åˆ†æ", "æ­£åœ¨åˆ†ææ”¿ç­–å’Œç›‘ç®¡åŠ¨æ€...")
                await asyncio.sleep(0.1)
                try:
                    # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                    llm_processor.last_usage = None
                    content, usage = await self._process_policy_news_enhanced(industry, policy_news)
                    section_contents["æ”¿ç­–ç›‘ç®¡"] = content
                    # å‘é€æ¨¡å‹ç”¨é‡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰usageä¿¡æ¯ï¼‰
                    if usage:
                        print(f"ğŸ” [è°ƒè¯•] æ”¿ç­–ç›‘ç®¡åˆ†æç”¨é‡: {usage}")
                        yield self._create_model_usage_message(usage_data=usage)
                    else:
                        print("â„¹ï¸ [usage] æ”¿ç­–ç›‘ç®¡åˆ†ææ— æ³•è·å–last_usageï¼Œè·³è¿‡ç”¨é‡äº‹ä»¶")
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "æ”¿ç­–ç›‘ç®¡åˆ†æå®Œæˆ", "æ”¿ç­–åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ æ”¿ç­–ç›‘ç®¡åˆ†æå¤±è´¥: {str(e)}")
                    section_contents["æ”¿ç­–ç›‘ç®¡"] = f"## ğŸ“œ æ”¿ç­–ç›‘ç®¡åˆ†æ\n\n{industry}è¡Œä¸šæ”¿ç­–ç›‘ç®¡åˆ†ææš‚æ—¶æ— æ³•ç”Ÿæˆï¼Œè¯·ç¨åé‡è¯•ã€‚\n\n"
                    yield self._create_progress_message("error", "æ”¿ç­–ç›‘ç®¡åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] policy_newsä¸ºç©ºï¼Œè·³è¿‡æ”¿ç­–ç›‘ç®¡åˆ†æ")
                yield self._create_progress_message("skipped", "æ”¿ç­–ç›‘ç®¡åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— æ”¿ç­–ç›‘ç®¡ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 5. è¡Œä¸šè¶‹åŠ¿åˆ†æ
            trend_news = processed_data.get("trend_news", [])
            print(f"ğŸ” [è°ƒè¯•] trend_newsæ•°æ®: {len(trend_news)}æ¡")
            if trend_news and len(trend_news) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆè¡Œä¸šè¶‹åŠ¿åˆ†æ", "æ­£åœ¨åˆ†æè¡Œä¸šå‘å±•è¶‹åŠ¿...")
                await asyncio.sleep(0.1)
                try:
                    # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                    llm_processor.last_usage = None
                    content, usage = await self._process_industry_trends_enhanced(industry, trend_news, days)
                    section_contents["è¡Œä¸šè¶‹åŠ¿"] = content
                    # å‘é€æ¨¡å‹ç”¨é‡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰usageä¿¡æ¯ï¼‰
                    if usage:
                        print(f"ğŸ” [è°ƒè¯•] è¡Œä¸šè¶‹åŠ¿åˆ†æç”¨é‡: {usage}")
                        yield self._create_model_usage_message(usage_data=usage)
                    else:
                        print("â„¹ï¸ [usage] è¡Œä¸šè¶‹åŠ¿åˆ†ææ— æ³•è·å–last_usageï¼Œè·³è¿‡ç”¨é‡äº‹ä»¶")
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "è¡Œä¸šè¶‹åŠ¿åˆ†æå®Œæˆ", "è¶‹åŠ¿åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ è¡Œä¸šè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
                    section_contents["è¡Œä¸šè¶‹åŠ¿"] = f"## ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿åˆ†æ\n\n{industry}è¡Œä¸šè¶‹åŠ¿åˆ†ææš‚æ—¶æ— æ³•ç”Ÿæˆï¼Œè¯·ç¨åé‡è¯•ã€‚\n\n"
                    yield self._create_progress_message("error", "è¡Œä¸šè¶‹åŠ¿åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] trend_newsä¸ºç©ºï¼Œè·³è¿‡è¡Œä¸šè¶‹åŠ¿åˆ†æ")
                yield self._create_progress_message("skipped", "è¡Œä¸šè¶‹åŠ¿åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— è¡Œä¸šè¶‹åŠ¿ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 6. è§‚ç‚¹å¯¹æ¯”åˆ†æ
            perspective_analysis = processed_data.get("perspective_analysis", [])
            print(f"ğŸ” [è°ƒè¯•] perspective_analysisæ•°æ®: {len(perspective_analysis)}æ¡")
            if perspective_analysis and len(perspective_analysis) > 0:
                yield self._create_progress_message("processing", "ç”Ÿæˆè§‚ç‚¹å¯¹æ¯”åˆ†æ", "æ­£åœ¨åˆ†æä¸åŒè§‚ç‚¹å’Œäº‰è®®...")
                await asyncio.sleep(0.1)
                try:
                    # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                    llm_processor.last_usage = None
                    content, usage = await self._process_perspective_analysis_enhanced(industry, perspective_analysis)
                    section_contents["è§‚ç‚¹å¯¹æ¯”"] = content
                    # å‘é€æ¨¡å‹ç”¨é‡æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰usageä¿¡æ¯ï¼‰
                    if usage:
                        print(f"ğŸ” [è°ƒè¯•] è§‚ç‚¹å¯¹æ¯”åˆ†æç”¨é‡: {usage}")
                        yield self._create_model_usage_message(usage_data=usage)
                    else:
                        print("â„¹ï¸ [usage] è§‚ç‚¹å¯¹æ¯”åˆ†ææ— æ³•è·å–last_usageï¼Œè·³è¿‡ç”¨é‡äº‹ä»¶")
                    await asyncio.sleep(0.1)
                    yield self._create_progress_message("completed", "è§‚ç‚¹å¯¹æ¯”åˆ†æå®Œæˆ", "è§‚ç‚¹åˆ†æå®Œæˆ")
                    await asyncio.sleep(0.1)
                except Exception as e:
                    print(f"âŒ è§‚ç‚¹å¯¹æ¯”åˆ†æå¤±è´¥: {str(e)}")
                    section_contents["è§‚ç‚¹å¯¹æ¯”"] = f"## ğŸ¤” è§‚ç‚¹å¯¹æ¯”åˆ†æ\n\n{industry}è¡Œä¸šè§‚ç‚¹å¯¹æ¯”åˆ†ææš‚æ—¶æ— æ³•ç”Ÿæˆï¼Œè¯·ç¨åé‡è¯•ã€‚\n\n"
                    yield self._create_progress_message("error", "è§‚ç‚¹å¯¹æ¯”åˆ†æ", f"åˆ†æå¤±è´¥: {str(e)}")
                    await asyncio.sleep(0.1)
            else:
                print("âš ï¸ [è°ƒè¯•] perspective_analysisä¸ºç©ºï¼Œè·³è¿‡è§‚ç‚¹å¯¹æ¯”åˆ†æ")
                yield self._create_progress_message("skipped", "è§‚ç‚¹å¯¹æ¯”åˆ†æ", "å½“å‰æ—¶é—´çª—å£å†…æ— è§‚ç‚¹å¯¹æ¯”ä¿¡æ¯")
                await asyncio.sleep(0.1)
            
            # 7. ç”Ÿæˆæ™ºèƒ½æ€»ç»“
            yield self._create_progress_message("processing", "ç”Ÿæˆæ™ºèƒ½æ€»ç»“", "æ­£åœ¨ç”ŸæˆAIæ™ºèƒ½åˆ†ææ€»ç»“...")
            await asyncio.sleep(0.1)
            try:
                print(f"ğŸ§  [æ™ºèƒ½æ€»ç»“] å¼€å§‹ç”Ÿæˆæ™ºèƒ½æ€»ç»“ï¼Œè¡Œä¸š: {industry}")
                # æ¸…ç©ºä¸Šæ¬¡ç”¨é‡ï¼Œç¡®ä¿è·å–æœ¬æ¬¡çœŸå®ç”¨é‡
                llm_processor.last_usage = None
                intelligent_summary = await self._generate_intelligent_summary_enhanced(industry, processed_data, days)
                print(f"âœ… [æ™ºèƒ½æ€»ç»“] æ™ºèƒ½æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(intelligent_summary)}å­—ç¬¦")
                # æ³¨å…¥çœŸå®æ¨¡å‹ç”¨é‡ï¼ˆè‹¥æœ‰ï¼‰
                try:
                    if getattr(llm_processor, 'last_usage', None):
                        u = llm_processor.last_usage
                        print(f"ğŸ” [è°ƒè¯•] æ™ºèƒ½æ€»ç»“ç”¨é‡: {u}")
                        yield self._create_model_usage_message(usage_data=u)
                    else:
                        print("â„¹ï¸ [usage] æ™ºèƒ½æ€»ç»“æ— æ³•è·å–last_usageï¼Œè·³è¿‡ç”¨é‡äº‹ä»¶")
                except Exception as _e:
                    print(f"âš ï¸ [usage] æ™ºèƒ½æ€»ç»“ä¸ŠæŠ¥æ¨¡å‹ç”¨é‡å¤±è´¥: {_e}")
                await asyncio.sleep(0.1)
                yield self._create_progress_message("completed", "æ™ºèƒ½æ€»ç»“å®Œæˆ", "AIåˆ†ææ€»ç»“å·²ç”Ÿæˆ")
                await asyncio.sleep(0.1)
            except Exception as e:
                print(f"âŒ [æ™ºèƒ½æ€»ç»“] æ™ºèƒ½æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}")
                print(f"âŒ [æ™ºèƒ½æ€»ç»“] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                import traceback
                print(f"âŒ [æ™ºèƒ½æ€»ç»“] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                intelligent_summary = f"## ğŸ§  AIæ™ºèƒ½åˆ†ææ€»ç»“\n\n{industry}è¡Œä¸šæ­£å¤„äºåŠ¨æ€å‘å±•é˜¶æ®µï¼ŒAIåˆ†ææ˜¾ç¤ºå¤šä¸ªç»´åº¦éƒ½æœ‰é‡è¦å˜åŒ–å€¼å¾—å…³æ³¨ã€‚\n\n"
                yield self._create_progress_message("error", "æ™ºèƒ½æ€»ç»“ç”Ÿæˆ", f"ç”Ÿæˆå¤±è´¥: {str(e)}")
                await asyncio.sleep(0.1)
            
            # 8. ç»„è£…æœ€ç»ˆæŠ¥å‘Š
            yield self._create_progress_message("processing", "ç»„è£…æœ€ç»ˆæŠ¥å‘Š", "æ­£åœ¨æ•´åˆæ‰€æœ‰åˆ†æå†…å®¹...")
            await asyncio.sleep(0.1)
            
            try:
                print(f"ğŸ“‹ [æœ€ç»ˆæŠ¥å‘Š] å¼€å§‹ç»„è£…æŠ¥å‘Šï¼Œç« èŠ‚æ•°: {len(section_contents)}")
                final_report = self._assemble_enhanced_report(industry, intelligent_summary, section_contents, processed_data, days)
                print(f"âœ… [æœ€ç»ˆæŠ¥å‘Š] æŠ¥å‘Šç»„è£…æˆåŠŸï¼Œæ€»é•¿åº¦: {len(final_report)}å­—ç¬¦")
                yield self._create_progress_message("completed", "æŠ¥å‘Šç”Ÿæˆå®Œæˆ", f"æˆåŠŸç”ŸæˆåŒ…å«{len(section_contents)}ä¸ªæ·±åº¦åˆ†æç« èŠ‚çš„æ™ºèƒ½æŠ¥å‘Š")
                await asyncio.sleep(0.1)
                
                # å‘é€æœ€ç»ˆç»“æœ
                try:
                    print(f"ğŸ“¤ [æœ€ç»ˆç»“æœ] å‡†å¤‡å‘é€æœ€ç»ˆç»“æœ...")
                    yield self._create_final_result(final_report)
                    print(f"âœ… [æœ€ç»ˆç»“æœ] æœ€ç»ˆç»“æœå‘é€æˆåŠŸ")
                except asyncio.CancelledError:
                    print("ğŸ”Œ SSEå®¢æˆ·ç«¯å·²æ–­å¼€ï¼ˆæœ€ç»ˆç»“æœé˜¶æ®µï¼‰ï¼Œç»ˆæ­¢æ¨é€")
                    return
                except Exception as e:
                    print(f"âŒ [æœ€ç»ˆç»“æœ] å‘é€æœ€ç»ˆç»“æœå¤±è´¥: {str(e)}")
                    yield self._create_error_message(f"å‘é€æœ€ç»ˆç»“æœå¤±è´¥: {str(e)}")
            except Exception as e:
                print(f"âŒ [æœ€ç»ˆæŠ¥å‘Š] æŠ¥å‘Šç»„è£…å¤±è´¥: {str(e)}")
                print(f"âŒ [æœ€ç»ˆæŠ¥å‘Š] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                import traceback
                print(f"âŒ [æœ€ç»ˆæŠ¥å‘Š] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                yield self._create_progress_message("error", "æŠ¥å‘Šç»„è£…", f"ç»„è£…å¤±è´¥: {str(e)}")
                # å°è¯•å‘é€é”™è¯¯æŠ¥å‘Š
                fallback_report = f"# {industry}è¡Œä¸šåˆ†ææŠ¥å‘Š\n\næŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}"
                yield self._create_final_result(fallback_report)
            
        except asyncio.CancelledError:
            print("ğŸ”Œ SSEå®¢æˆ·ç«¯å·²æ–­å¼€ï¼ˆæŠ¥å‘Šæµç¨‹ä¸­ï¼‰ï¼Œç»ˆæ­¢æ¨é€")
            return
        except Exception as e:
            yield self._create_error_message(str(e))
    
    def _create_progress_message(self, status: str, message: str, content: str) -> str:
        """åˆ›å»ºè¿›åº¦æ›´æ–°æ¶ˆæ¯"""
        progress_message = {
            "method": "notifications/message",
            "params": {
                "level": "info",
                "data": {
                    "msg": {
                        "status": status,
                        "message": message,
                        "details": {
                            "id": self.request_id,
                            "name": self.tool_name,
                            "content": content
                        }
                    },
                    "extra": None
                }
            },
            "jsonrpc": "2.0"
        }
        return f"data: {json.dumps(progress_message, ensure_ascii=False)}\n\n"
    
    def _create_model_usage_message(self, provider: str = None, model: str = None, input_tokens: int = None, output_tokens: int = None, total_tokens: int = None, usage_data: dict = None) -> str:
        """åˆ›å»ºæ¨¡å‹ç”¨é‡æ¶ˆæ¯
        
        Args:
            provider: æ¨¡å‹æä¾›å•†
            model: æ¨¡å‹åç§°
            input_tokens: è¾“å…¥tokenæ•°
            output_tokens: è¾“å‡ºtokenæ•°
            total_tokens: æ€»tokenæ•°
            usage_data: å®Œæ•´çš„usageæ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰
        """
        # å¦‚æœæä¾›äº†usage_dataï¼Œä¼˜å…ˆä½¿ç”¨
        if usage_data:
            provider = usage_data.get('provider', provider or 'unknown')
            model = usage_data.get('model', model or 'unknown')
            input_tokens = int(usage_data.get('input_tokens', input_tokens or 0))
            output_tokens = int(usage_data.get('output_tokens', output_tokens or 0))
            total_tokens = int(usage_data.get('total_tokens', total_tokens or (input_tokens + output_tokens)))
        else:
            # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
            provider = provider or 'unknown'
            model = model or 'unknown'
            input_tokens = input_tokens or 0
            output_tokens = output_tokens or 0
            total_tokens = total_tokens if total_tokens is not None else (input_tokens + output_tokens)
        
        usage_message = {
            "jsonrpc": "2.0",
            "method": "notifications/message",
            "params": {
                "data": {
                    "msg": {
                        "type": "model_usage",
                        "data": {
                            "model_provider": provider,
                            "model_name": model,
                            "input_tokens": input_tokens,
                            "output_tokens": output_tokens,
                            "total_tokens": total_tokens,
                            "timestamp": datetime.now().isoformat()
                        }
                    }
                }
            }
        }
        return f"data: {json.dumps(usage_message, ensure_ascii=False)}\n\n"
    
    def _create_final_result(self, content: str) -> str:
        """åˆ›å»ºæœ€ç»ˆç»“æœæ¶ˆæ¯"""
        final_response = {
            "jsonrpc": "2.0",
            "id": self.request_id,
            "result": {
                "content": content,
                "tool": self.tool_name
            }
        }
        return f"data: {json.dumps(final_response, ensure_ascii=False)}\n\n"
    
    # ========== åŸæœ¬agentçš„æ ¸å¿ƒæ–¹æ³•é›†æˆ ==========
    
    async def _generate_initial_queries_enhanced(self, industry: str, days: int, focus_areas: list) -> Dict[str, Any]:
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆæ™ºèƒ½æŸ¥è¯¢"""
        try:
            print(f"ğŸ” [æŸ¥è¯¢ç”Ÿæˆ] æ­£åœ¨ä¸º{industry}è¡Œä¸šç”Ÿæˆæ™ºèƒ½æŸ¥è¯¢...")
            
            # ä½¿ç”¨query_generation_mcpç”ŸæˆæŸ¥è¯¢
            try:
                result = await asyncio.to_thread(
                    query_generation_mcp,
                    industry=industry,
                    days=days,
                    focus_areas=focus_areas,
                    query_type="comprehensive",
                    requirements="ç”Ÿæˆå¤šç»´åº¦æ™ºèƒ½æŸ¥è¯¢ï¼Œè¦†ç›–é‡å¤§äº‹ä»¶ã€æŠ€æœ¯åˆ›æ–°ã€æŠ•èµ„åŠ¨æ€ã€æ”¿ç­–ç›‘ç®¡ã€è¡Œä¸šè¶‹åŠ¿ç­‰æ–¹é¢"
                )
                queries = result.get('queries', {})
                print(f"âœ… query_generation_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(queries)}ç±»æŸ¥è¯¢")
                return queries
            except Exception as e:
                print(f"âŒ query_generation_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                # è¿”å›åŸºç¡€æŸ¥è¯¢ç»“æ„
                return {
                    "breaking_news": [f"{industry} é‡å¤§äº‹ä»¶ æœ€æ–°æ¶ˆæ¯"],
                    "innovation_news": [f"{industry} æŠ€æœ¯åˆ›æ–° æ–°äº§å“"],
                    "investment_news": [f"{industry} æŠ•èµ„ èèµ„ å¹¶è´­"],
                    "policy_news": [f"{industry} æ”¿ç­– ç›‘ç®¡ æ³•è§„"],
                    "trend_news": [f"{industry} è¶‹åŠ¿ å‘å±• å‰æ™¯"],
                    "company_news": [f"{industry} ä¼ä¸š å…¬å¸ åŠ¨æ€"],
                    "total_count": 6
                }
        except Exception as e:
            print(f"æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "breaking_news": [],
                "innovation_news": [],
                "investment_news": [],
                "policy_news": [],
                "trend_news": [],
                "company_news": [],
                "total_count": 0
            }
    
    async def _reflect_on_information_gaps_enhanced(self, collected_data: Dict[str, Any], industry: str, days: int) -> tuple:
        """ä½¿ç”¨MCPå·¥å…·è¿›è¡Œåæ€ä¸çŸ¥è¯†ç¼ºå£åˆ†æ"""
        try:
            print(f"ğŸ¤” [åæ€åˆ†æ] æ­£åœ¨åˆ†æ{industry}è¡Œä¸šä¿¡æ¯ç¼ºå£...")
            
            # ä½¿ç”¨analysis_mcpè¿›è¡Œç¼ºå£åˆ†æ
            try:
                result = await asyncio.to_thread(
                    analysis_mcp,
                    task_description=f"åˆ†æ{industry}è¡Œä¸šæ”¶é›†çš„ä¿¡æ¯æ˜¯å¦å……åˆ†ï¼Œè¯†åˆ«çŸ¥è¯†ç¼ºå£",
                    data_context=collected_data,
                    analysis_type="gap_analysis",
                    requirements=f"åŸºäºæ”¶é›†çš„æ•°æ®ï¼Œè¯†åˆ«{industry}è¡Œä¸šåˆ†æä¸­çš„ä¿¡æ¯ç¼ºå£å’Œä¸è¶³ä¹‹å¤„"
                )
                gaps = result.get('gaps', [])
                is_sufficient = result.get('is_sufficient', len(gaps) == 0)
                print(f"âœ… analysis_mcpç¼ºå£åˆ†æå®Œæˆï¼Œå‘ç°{len(gaps)}ä¸ªç¼ºå£")
                return gaps, is_sufficient
            except Exception as e:
                print(f"âŒ analysis_mcpç¼ºå£åˆ†æå¤±è´¥: {str(e)}")
                return [], True  # å‡ºé”™æ—¶å‡è®¾ä¿¡æ¯å……åˆ†
        except Exception as e:
            print(f"åæ€åˆ†æå¤±è´¥: {str(e)}")
            return [], True
    
    async def _generate_targeted_queries_enhanced(self, gaps: list, industry: str, days: int) -> Dict[str, Any]:
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢"""
        try:
            print(f"ğŸ¯ [é’ˆå¯¹æ€§æŸ¥è¯¢] æ­£åœ¨ä¸º{len(gaps)}ä¸ªç¼ºå£ç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢...")
            
            # ä½¿ç”¨query_generation_mcpç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢
            try:
                result = await asyncio.to_thread(
                    query_generation_mcp,
                    industry=industry,
                    days=days,
                    focus_areas=gaps,
                    query_type="targeted",
                    requirements=f"åŸºäºè¯†åˆ«çš„ä¿¡æ¯ç¼ºå£ï¼Œç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢ä»¥è¡¥å……{industry}è¡Œä¸šåˆ†æ"
                )
                queries = result.get('queries', {})
                print(f"âœ… query_generation_mcpé’ˆå¯¹æ€§æŸ¥è¯¢ç”ŸæˆæˆåŠŸï¼Œç”Ÿæˆäº†{len(queries)}ç±»æŸ¥è¯¢")
                return queries
            except Exception as e:
                print(f"âŒ query_generation_mcpé’ˆå¯¹æ€§æŸ¥è¯¢å¤±è´¥: {str(e)}")
                # è¿”å›åŸºç¡€é’ˆå¯¹æ€§æŸ¥è¯¢
                return {
                    "breaking_news": [f"{industry} {gap}" for gap in gaps[:2]],
                    "innovation_news": [f"{industry} {gap} åˆ›æ–°" for gap in gaps[:2]],
                    "investment_news": [f"{industry} {gap} æŠ•èµ„" for gap in gaps[:2]],
                    "policy_news": [f"{industry} {gap} æ”¿ç­–" for gap in gaps[:2]],
                    "trend_news": [f"{industry} {gap} è¶‹åŠ¿" for gap in gaps[:2]],
                    "company_news": [f"{industry} {gap} ä¼ä¸š" for gap in gaps[:2]],
                    "total_count": min(len(gaps) * 6, 12)
                }
        except Exception as e:
            print(f"é’ˆå¯¹æ€§æŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "breaking_news": [],
                "innovation_news": [],
                "investment_news": [],
                "policy_news": [],
                "trend_news": [],
                "company_news": [],
                "total_count": 0
            }
    
    def _merge_data_enhanced(self, existing_data: Dict[str, Any], new_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨MCPå·¥å…·è¿›è¡Œæ•°æ®åˆå¹¶"""
        try:
            print(f"ğŸ”„ [æ•°æ®åˆå¹¶] æ­£åœ¨åˆå¹¶æ–°æ—§æ•°æ®...")
            
            merged_data = existing_data.copy()
            
            # åˆå¹¶å„ä¸ªç±»åˆ«çš„æ•°æ®
            for category in ["breaking_news", "innovation_news", "investment_news", "policy_news", "trend_news", "company_news", "perspective_analysis"]:
                if category in new_data and new_data[category]:
                    if category in merged_data:
                        merged_data[category].extend(new_data[category])
                    else:
                        merged_data[category] = new_data[category]
            
            # é‡æ–°è®¡ç®—æ€»æ•°
            merged_data["total_count"] = sum(
                len(merged_data[key]) for key in merged_data.keys() 
                if key != "total_count" and isinstance(merged_data[key], list)
            )
            
            print(f"âœ… æ•°æ®åˆå¹¶å®Œæˆï¼Œæ€»è®¡{merged_data['total_count']}æ¡æ•°æ®")
            return merged_data
            
        except Exception as e:
            print(f"æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            return existing_data
    
    async def _process_collected_data_enhanced(self, all_news_data: Dict[str, Any], industry: str, days: int) -> Dict[str, Any]:
        """ä½¿ç”¨MCPå·¥å…·è¿›è¡Œæ™ºèƒ½å»é‡å’Œæ—¶é—´è¿‡æ»¤"""
        try:
            print(f"ğŸ”„ [æ•°æ®å¤„ç†] æ­£åœ¨å¯¹{industry}è¡Œä¸šæ•°æ®è¿›è¡Œæ™ºèƒ½å»é‡...")
            
            processed_data = all_news_data.copy()
            
            # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œæ™ºèƒ½å»é‡
            for category in ["breaking_news", "innovation_news", "investment_news", "policy_news", "trend_news", "perspective_analysis"]:
                if processed_data.get(category):
                    original_count = len(processed_data[category])
                    processed_data[category] = self._deduplicate_by_content_mcp(
                        processed_data[category], category
                    )
                    deduped_count = len(processed_data[category])
                    print(f"ğŸ“Š {category}: {original_count} -> {deduped_count} (å»é‡{original_count - deduped_count}æ¡)")
            
            # é‡æ–°è®¡ç®—æ€»æ•°
            processed_data["total_count"] = sum(
                len(processed_data[key]) for key in processed_data.keys() 
                if key != "total_count" and isinstance(processed_data[key], list)
            )
            
            print(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæœ€ç»ˆä¿ç•™{processed_data['total_count']}æ¡æœ‰æ•ˆæ•°æ®")
            return processed_data
            
        except Exception as e:
            print(f"æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
            return all_news_data
    
    def _deduplicate_by_content_mcp(self, data_list: list, category: str) -> list:
        """ä½¿ç”¨MCPå·¥å…·è¿›è¡Œå†…å®¹å»é‡"""
        try:
            if not data_list or len(data_list) <= 1:
                return data_list
            
            # ç®€å•çš„åŸºäºæ ‡é¢˜å’Œå†…å®¹çš„å»é‡é€»è¾‘
            seen_content = set()
            deduplicated = []
            
            for item in data_list:
                if isinstance(item, dict):
                    # åˆ›å»ºå†…å®¹æŒ‡çº¹
                    title = item.get('title', '').strip().lower()
                    content = item.get('content', '').strip().lower()[:200]  # åªå–å‰200å­—ç¬¦
                    fingerprint = f"{title}|{content}"
                    
                    if fingerprint not in seen_content:
                        seen_content.add(fingerprint)
                        deduplicated.append(item)
                else:
                    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥æ·»åŠ 
                    deduplicated.append(item)
            
            return deduplicated
            
        except Exception as e:
            print(f"å†…å®¹å»é‡å¤±è´¥: {str(e)}")
            return data_list
    
    async def _process_breaking_news_enhanced(self, industry: str, breaking_news: list, days: int):
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆé‡å¤§äº‹ä»¶åˆ†æ"""
        try:
            if not breaking_news:
                return f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶\n\nğŸ“Š **åˆ†æè¯´æ˜**: åœ¨å½“å‰æ—¶é—´çª—å£å†…ï¼Œæš‚æœªå‘ç°{industry}è¡Œä¸šçš„é‡å¤§çªå‘äº‹ä»¶ã€‚\n\n", None
            
            print(f"ğŸ” [æ·±åº¦åˆ†æ] æ­£åœ¨åˆ†æ{len(breaking_news)}æ¡é‡å¤§äº‹ä»¶...")
            
            # æ„å»ºæ–°é—»æ•°æ®
            news_data = []
            for item in breaking_news[:5]:  # åªå–å‰5æ¡
                if isinstance(item, dict):
                    news_data.append({
                        "title": item.get('title', 'æ— æ ‡é¢˜'),
                        "content": item.get('content', 'æ— å†…å®¹')[:500],
                        "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                        "url": item.get('url', '#')
                    })
                else:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    news_data.append({
                        "title": str(item)[:100],
                        "content": str(item),
                        "source": "æœç´¢ç»“æœ",
                        "url": "#"
                    })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·ï¼ˆæ”¾åˆ°çº¿ç¨‹æ± ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”Ÿæˆé‡å¤§äº‹ä»¶åˆ†æ...")
                content, usage = await self._call_content_writer_with_usage(
                    section_title="è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ",
                    content_data=news_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="è¡Œä¸šåˆ†æå¸ˆ",
                    word_count_requirement="2000-3000å­—"
                )
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                import traceback
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                traceback.print_exc()
                content = f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶\n\nåŸºäºæ”¶é›†çš„{len(breaking_news)}æ¡é‡å¤§äº‹ä»¶ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
                usage = None
            
            # æ·»åŠ ä¿¡æ¯æ¥æº
            print(f"ğŸ” [è°ƒè¯•] å¼€å§‹æ·»åŠ ä¿¡æ¯æ¥æºï¼Œbreaking_newsæ•°é‡: {len(breaking_news)}")
            sources = []
            for item in breaking_news:
                if item.get('url', '#') != '#':
                    sources.append(f"- [{item.get('title', 'æœªçŸ¥æ ‡é¢˜')}]({item.get('url')}) - {item.get('source', 'æœªçŸ¥æ¥æº')}")
            
            print(f"ğŸ” [è°ƒè¯•] æ”¶é›†åˆ°{len(sources)}ä¸ªä¿¡æ¯æ¥æº")
            if sources:
                content += "\n\n**ä¿¡æ¯æ¥æº:**\n" + "\n".join(sources)
                print(f"ğŸ” [è°ƒè¯•] ä¿¡æ¯æ¥æºæ·»åŠ å®Œæˆï¼Œæœ€ç»ˆå†…å®¹é•¿åº¦: {len(content)}")
            
            final_result = f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ\n\n{content}\n\n"
            print(f"ğŸ” [è°ƒè¯•] å‡†å¤‡è¿”å›æœ€ç»ˆç»“æœï¼Œé•¿åº¦: {len(final_result)}")
            return final_result, usage
            
        except Exception as e:
            print(f"é‡å¤§äº‹ä»¶åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶\n\né‡å¤§äº‹ä»¶åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n", None
    
    async def _process_innovation_news_enhanced(self, industry: str, innovation_news: list):
        """ä½¿ç”¨MCPå·¥å…·ç”ŸæˆæŠ€æœ¯åˆ›æ–°åˆ†æ"""
        try:
            print(f"ğŸ” [è°ƒè¯•] _process_innovation_news_enhancedå¼€å§‹ï¼Œæ•°æ®: {len(innovation_news)}æ¡")
            if not innovation_news:
                print(f"ğŸ” [è°ƒè¯•] innovation_newsä¸ºç©ºï¼Œè¿”å›é»˜è®¤å†…å®¹")
                return f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šæŠ€æœ¯åˆ›æ–°æ´»åŠ¨ç›¸å¯¹å¹³é™ã€‚\n\n"
            
            print(f"ğŸ§ª [æŠ€æœ¯åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(innovation_news)}é¡¹æŠ€æœ¯åˆ›æ–°...")
            print(f"ğŸ” [è°ƒè¯•] å‰2æ¡æ•°æ®: {innovation_news[:2]}")
            
            # æ„å»ºæŠ€æœ¯æ•°æ®
            tech_data = []
            for item in innovation_news[:5]:  # åªå–å‰5æ¡
                if isinstance(item, dict):
                    tech_data.append({
                        "title": item.get('title', 'æ— æ ‡é¢˜'),
                        "content": item.get('content', 'æ— å†…å®¹')[:500],
                        "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                        "url": item.get('url', '#')
                    })
                else:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    tech_data.append({
                        "title": str(item)[:100],
                        "content": str(item),
                        "source": "æœç´¢ç»“æœ",
                        "url": "#"
                    })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”ŸæˆæŠ€æœ¯åˆ›æ–°åˆ†æ...")
                content, usage = await self._call_content_writer_with_usage(
                    section_title="æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“æ·±åº¦è§£æ",
                    content_data=tech_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="æŠ€æœ¯ä¸“å®¶",
                    word_count_requirement="2000-3000å­—"
                )
                # ä¸åœ¨è¿™é‡Œå‘é€usageæ¶ˆæ¯ï¼Œè€Œæ˜¯è¿”å›ç»™è°ƒç”¨è€…
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“\n\nåŸºäºæ”¶é›†çš„{len(innovation_news)}æ¡æŠ€æœ¯åˆ›æ–°ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
                usage = None
            
            return f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“æ·±åº¦è§£æ\n\n{content}\n\n", usage
            
        except Exception as e:
            print(f"æŠ€æœ¯åˆ›æ–°åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ”¬ æŠ€æœ¯åˆ›æ–°ä¸æ–°äº§å“\n\næŠ€æœ¯åˆ›æ–°åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n", None
    
    async def _process_investment_news_enhanced(self, industry: str, investment_news: list):
        """ä½¿ç”¨MCPå·¥å…·ç”ŸæˆæŠ•èµ„åŠ¨æ€åˆ†æ"""
        try:
            if not investment_news:
                return f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šæŠ•èµ„æ´»åŠ¨ç›¸å¯¹å¹³é™ã€‚\n\n"
            
            print(f"ğŸ’° [æŠ•èµ„åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(investment_news)}é¡¹æŠ•èµ„åŠ¨æ€...")
            
            # æ„å»ºæŠ•èµ„æ•°æ®
            investment_data = []
            for item in investment_news[:5]:  # åªå–å‰5æ¡
                if isinstance(item, dict):
                    investment_data.append({
                        "title": item.get('title', 'æ— æ ‡é¢˜'),
                        "content": item.get('content', 'æ— å†…å®¹')[:500],
                        "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                        "url": item.get('url', '#')
                    })
                else:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    investment_data.append({
                        "title": str(item)[:100],
                        "content": str(item),
                        "source": "æœç´¢ç»“æœ",
                        "url": "#"
                    })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”ŸæˆæŠ•èµ„åŠ¨æ€åˆ†æ...")
                content, usage = await self._call_content_writer_with_usage(
                    section_title="æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘æ·±åº¦è§£æ",
                    content_data=investment_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="æŠ•èµ„åˆ†æå¸ˆ",
                    word_count_requirement="2000-3000å­—"
                )
                # ä¸åœ¨è¿™é‡Œå‘é€usageæ¶ˆæ¯ï¼Œè€Œæ˜¯è¿”å›ç»™è°ƒç”¨è€…
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘\n\nåŸºäºæ”¶é›†çš„{len(investment_news)}æ¡æŠ•èµ„åŠ¨æ€ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
                usage = None
            
            return f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘æ·±åº¦è§£æ\n\n{content}\n\n", usage
            
        except Exception as e:
            print(f"æŠ•èµ„åŠ¨æ€åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ’° æŠ•èµ„åŠ¨æ€ä¸å¸‚åœºåŠ¨å‘\n\næŠ•èµ„åŠ¨æ€åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n", None
    
    async def _process_policy_news_enhanced(self, industry: str, policy_news: list):
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆæ”¿ç­–ç›‘ç®¡åˆ†æ"""
        try:
            if not policy_news:
                content = f"## ğŸ“œ æ”¿ç­–ä¸ç›‘ç®¡åŠ¨æ€\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šæ”¿ç­–ç›‘ç®¡ç›¸å¯¹ç¨³å®šã€‚\n\n"
                return content, None
            
            print(f"ğŸ“œ [æ”¿ç­–åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(policy_news)}é¡¹æ”¿ç­–ç›‘ç®¡åŠ¨æ€...")
            
            # æ„å»ºæ”¿ç­–æ•°æ®
            policy_data = []
            for item in policy_news[:5]:  # åªå–å‰5æ¡
                if isinstance(item, dict):
                    policy_data.append({
                        "title": item.get('title', 'æ— æ ‡é¢˜'),
                        "content": item.get('content', 'æ— å†…å®¹')[:500],
                        "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                        "url": item.get('url', '#')
                    })
                else:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    policy_data.append({
                        "title": str(item)[:100],
                        "content": str(item),
                        "source": "æœç´¢ç»“æœ",
                        "url": "#"
                    })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”Ÿæˆæ”¿ç­–ç›‘ç®¡åˆ†æ...")
                content, usage = await self._call_content_writer_with_usage(
                    section_title="æ”¿ç­–ä¸ç›‘ç®¡åŠ¨æ€æ·±åº¦è§£æ",
                    content_data=policy_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="æ”¿ç­–åˆ†æå¸ˆ",
                    word_count_requirement="2000-3000å­—"
                )
                # usageå°†åœ¨è¿”å›æ—¶ä¸€èµ·è¿”å›
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ“œ æ”¿ç­–ä¸ç›‘ç®¡åŠ¨æ€\n\nåŸºäºæ”¶é›†çš„{len(policy_news)}æ¡æ”¿ç­–ç›‘ç®¡ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
                usage = None
            
            return f"## ğŸ“œ æ”¿ç­–ä¸ç›‘ç®¡åŠ¨æ€æ·±åº¦è§£æ\n\n{content}\n\n", usage
            
        except Exception as e:
            print(f"æ”¿ç­–ç›‘ç®¡åˆ†æå¤±è´¥: {str(e)}")
            return f"## ğŸ“œ æ”¿ç­–ä¸ç›‘ç®¡åŠ¨æ€\n\næ”¿ç­–ç›‘ç®¡åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n", None
    
    async def _process_industry_trends_enhanced(self, industry: str, trend_news: list, days: int):
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆè¡Œä¸šè¶‹åŠ¿åˆ†æ"""
        try:
            if not trend_news:
                content = f"## ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿æ·±åº¦åˆ†æ\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šè¶‹åŠ¿å˜åŒ–ç›¸å¯¹å¹³ç¼“ã€‚\n\n"
                return content, None
            
            print(f"ğŸ“ˆ [è¶‹åŠ¿åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(trend_news)}é¡¹è¡Œä¸šè¶‹åŠ¿...")
            
            # æ„å»ºè¶‹åŠ¿æ•°æ®
            trend_data = []
            for item in trend_news[:5]:  # åªå–å‰5æ¡
                if isinstance(item, dict):
                    trend_data.append({
                        "title": item.get('title', 'æ— æ ‡é¢˜'),
                        "content": item.get('content', 'æ— å†…å®¹')[:500],
                        "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                        "url": item.get('url', '#')
                    })
                else:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    trend_data.append({
                        "title": str(item)[:100],
                        "content": str(item),
                        "source": "æœç´¢ç»“æœ",
                        "url": "#"
                    })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”Ÿæˆè¡Œä¸šè¶‹åŠ¿åˆ†æ...")
                content, usage = await self._call_content_writer_with_usage(
                    section_title="è¡Œä¸šè¶‹åŠ¿æ·±åº¦åˆ†æ",
                    content_data=trend_data,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="è¡Œä¸šåˆ†æå¸ˆ",
                    word_count_requirement="2000-3000å­—"
                )
                # usageå°†åœ¨è¿”å›æ—¶ä¸€èµ·è¿”å›
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿æ·±åº¦åˆ†æ\n\nåŸºäºæ”¶é›†çš„{len(trend_news)}æ¡è¶‹åŠ¿ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
                usage = None
            
            return f"## ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿æ·±åº¦åˆ†æ\n\n{content}\n\n", usage
            
        except Exception as e:
            print(f"è¡Œä¸šè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            content = "è¡Œä¸šè¶‹åŠ¿åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚"
            return f"## ğŸ“ˆ è¡Œä¸šè¶‹åŠ¿æ·±åº¦åˆ†æ\n\n{content}\n\n", None
    
    async def _process_perspective_analysis_enhanced(self, industry: str, perspective_data: list):
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆè§‚ç‚¹å¯¹æ¯”åˆ†æ"""
        try:
            if not perspective_data:
                content = f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\nğŸ“Š **è§‚å¯Ÿ**: å½“å‰æ—¶é—´çª—å£å†…{industry}è¡Œä¸šè§‚ç‚¹ç›¸å¯¹ä¸€è‡´ã€‚\n\n"
                return content, None
            
            print(f"âš–ï¸ [è§‚ç‚¹åˆ†æ] æ­£åœ¨æ·±åº¦åˆ†æ{len(perspective_data)}é¡¹è§‚ç‚¹å¯¹æ¯”...")
            
            # æ„å»ºè§‚ç‚¹æ•°æ®
            perspective_formatted = []
            for item in perspective_data[:5]:  # åªå–å‰5æ¡
                perspective_formatted.append({
                    "title": item.get('title', 'æ— æ ‡é¢˜'),
                    "content": item.get('content', 'æ— å†…å®¹')[:500],
                    "source": item.get('source', 'æœªçŸ¥æ¥æº'),
                    "url": item.get('url', '#')
                })
            
            # ä½¿ç”¨MCPå†…å®¹ç”Ÿæˆå·¥å…·
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨content_writer_mcpç”Ÿæˆè§‚ç‚¹å¯¹æ¯”åˆ†æ...")
                content, usage = await self._call_content_writer_with_usage(
                    section_title="å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ",
                    content_data=perspective_formatted,
                    overall_report_context=f"{industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š",
                    writing_style="professional",
                    target_audience="å†³ç­–è€…",
                    word_count_requirement="2000-3000å­—"
                )
                # usageå°†åœ¨è¿”å›æ—¶ä¸€èµ·è¿”å›
                print(f"âœ… content_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ content_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\nåŸºäºæ”¶é›†çš„{len(perspective_data)}æ¡è§‚ç‚¹ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n\n"
                usage = None
            
            return f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\n{content}\n\n", usage
            
        except Exception as e:
            print(f"è§‚ç‚¹å¯¹æ¯”åˆ†æå¤±è´¥: {str(e)}")
            return f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\nè§‚ç‚¹å¯¹æ¯”åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚\n\n", None
    
    async def _generate_intelligent_summary_enhanced(self, industry: str, processed_data: Dict[str, Any], days: int) -> str:
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆæ™ºèƒ½æ€»ç»“"""
        try:
            print(f"ğŸ§  [æ™ºèƒ½æ€»ç»“] æ­£åœ¨ç”Ÿæˆ{industry}è¡Œä¸šæ™ºèƒ½åˆ†ææ€»ç»“...")
            
            # ä½¿ç”¨summary_writer_mcpç”Ÿæˆæ™ºèƒ½æ€»ç»“
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨summary_writer_mcpç”Ÿæˆæ™ºèƒ½æ€»ç»“...")
                result = await asyncio.to_thread(
                    summary_writer_mcp,
                    processed_data,
                    length_constraint="500-800å­—",
                    format="structured",
                    focus_areas=["æŠ€æœ¯åˆ›æ–°", "æŠ•èµ„åŠ¨æ€", "æ”¿ç­–ç›‘ç®¡", "è¡Œä¸šè¶‹åŠ¿"],
                    tone="professional",
                    target_audience="è¡Œä¸šåˆ†æå¸ˆ"
                )
                # å¤„ç†è¿”å›ç»“æœï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
                if isinstance(result, dict):
                    content = result.get('content', f"## ğŸ§  AIæ™ºèƒ½åˆ†ææ€»ç»“\n\n{industry}è¡Œä¸šæ­£å¤„äºåŠ¨æ€å‘å±•é˜¶æ®µï¼ŒAIåˆ†ææ˜¾ç¤ºå¤šä¸ªç»´åº¦éƒ½æœ‰é‡è¦å˜åŒ–å€¼å¾—å…³æ³¨ã€‚\n\n")
                else:
                    content = str(result) if result else f"## ğŸ§  AIæ™ºèƒ½åˆ†ææ€»ç»“\n\n{industry}è¡Œä¸šæ­£å¤„äºåŠ¨æ€å‘å±•é˜¶æ®µï¼ŒAIåˆ†ææ˜¾ç¤ºå¤šä¸ªç»´åº¦éƒ½æœ‰é‡è¦å˜åŒ–å€¼å¾—å…³æ³¨ã€‚\n\n"
                print(f"âœ… summary_writer_mcpè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº†{len(content)}å­—ç¬¦çš„å†…å®¹")
            except Exception as e:
                print(f"âŒ summary_writer_mcpè°ƒç”¨å¤±è´¥: {str(e)}")
                content = f"## ğŸ§  AIæ™ºèƒ½åˆ†ææ€»ç»“\n\n{industry}è¡Œä¸šæ­£å¤„äºåŠ¨æ€å‘å±•é˜¶æ®µï¼ŒAIåˆ†ææ˜¾ç¤ºå¤šä¸ªç»´åº¦éƒ½æœ‰é‡è¦å˜åŒ–å€¼å¾—å…³æ³¨ã€‚\n\n"
            
            return content
            
        except Exception as e:
            print(f"æ™ºèƒ½æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"## ğŸ§  AIæ™ºèƒ½åˆ†ææ€»ç»“\n\n{industry}è¡Œä¸šæ­£å¤„äºåŠ¨æ€å‘å±•é˜¶æ®µï¼ŒAIåˆ†ææ˜¾ç¤ºå¤šä¸ªç»´åº¦éƒ½æœ‰é‡è¦å˜åŒ–å€¼å¾—å…³æ³¨ã€‚\n\n"
    
    def _assemble_enhanced_report(self, industry: str, intelligent_summary: str, section_contents: Dict[str, str], processed_data: Dict[str, Any], days: int) -> str:
        """ä½¿ç”¨MCPå·¥å…·ç»„è£…å¢å¼ºç‰ˆæŠ¥å‘Š"""
        try:
            print(f"ğŸ“‹ [æŠ¥å‘Šç»„è£…] æ­£åœ¨ç»„è£…{industry}è¡Œä¸šæ™ºèƒ½åˆ†ææŠ¥å‘Š...")
            
            # æ„å»ºæŠ¥å‘Šå¤´éƒ¨
            date_str = datetime.now().strftime('%Y-%m-%d')
            content = f"# {industry}è¡Œä¸šæ™ºèƒ½åˆ†ææŠ¥å‘Š\n\n"
            content += f"*æœ¬æŠ¥å‘Šç”±MCPå·¥å…·é“¾ç”Ÿæˆï¼Œå…·å¤‡æ·±åº¦æ€è€ƒå’Œåæ€èƒ½åŠ›*\n\n"
            content += f"æŠ¥å‘Šæ—¥æœŸ: {date_str}\n\n"
            
            # æ·»åŠ æŠ¥å‘Šæ¦‚è¿°
            content += f"""## ğŸ“‹ æŠ¥å‘Šæ¦‚è¿°

æœ¬æŠ¥å‘Šé‡‡ç”¨MCPå·¥å…·é“¾çš„äº”æ­¥åˆ†ææ³•ï¼Œå¯¹{industry}è¡Œä¸šè¿›è¡Œå…¨æ–¹ä½æ·±åº¦è§£æã€‚é€šè¿‡æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆã€
å¤šç»´ä¿¡æ¯æœé›†ã€åæ€å¼ç¼ºå£åˆ†æã€è¿­ä»£ä¼˜åŒ–æœç´¢å’Œç»¼åˆæŠ¥å‘Šç”Ÿæˆï¼Œç¡®ä¿ä¿¡æ¯çš„å…¨é¢æ€§å’Œåˆ†æçš„æ·±åº¦ã€‚

**æŠ¥å‘Šç‰¹è‰²ï¼š**
- ğŸ§  æ·±åº¦æ€è€ƒï¼šæ¨¡æ‹Ÿä¸“å®¶çº§åˆ†æå¸ˆçš„æ€ç»´è¿‡ç¨‹
- ğŸ”„ å¤šè½®è¿­ä»£ï¼šé€šè¿‡åæ€æœºåˆ¶ç¡®ä¿ä¿¡æ¯å……åˆ†æ€§
- ğŸ¯ é’ˆå¯¹æ€§å¼ºï¼šæ ¹æ®è¯†åˆ«çš„çŸ¥è¯†ç¼ºå£è¿›è¡Œè¡¥å……æœç´¢
- ğŸ“Š æ•°æ®ä¸°å¯Œï¼šæ•´åˆå¤šæºä¿¡æ¯ï¼Œæä¾›å…¨é¢è§†è§’
- ğŸ”® å‰ç»æ€§å¼ºï¼šä¸ä»…åˆ†æç°çŠ¶ï¼Œæ›´é¢„æµ‹æœªæ¥è¶‹åŠ¿

---

"""
            
            # æ·»åŠ å„ä¸ªç« èŠ‚
            for section_name, section_content in section_contents.items():
                content += section_content + "\n"
            
            # æ·»åŠ æ™ºèƒ½æ€»ç»“
            content += intelligent_summary + "\n"
            
            # æ·»åŠ å‚è€ƒèµ„æ–™
            content += self._generate_references_mcp(processed_data)
            
            print(f"âœ… æŠ¥å‘Šç»„è£…å®Œæˆï¼Œæ€»é•¿åº¦: {len(content)}å­—ç¬¦")
            return content
            
        except Exception as e:
            print(f"æŠ¥å‘Šç»„è£…å¤±è´¥: {str(e)}")
            return f"# {industry}è¡Œä¸šåˆ†ææŠ¥å‘Š\n\næŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    
    def _generate_references_mcp(self, processed_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨MCPå·¥å…·ç”Ÿæˆå‚è€ƒèµ„æ–™"""
        try:
            references = "\n## ğŸ“š å‚è€ƒèµ„æ–™\n\n"
            
            # æ”¶é›†æ‰€æœ‰æ•°æ®æº
            all_sources = set()
            for key, data in processed_data.items():
                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict) and 'source' in item:
                            all_sources.add(item['source'])
                        elif isinstance(item, dict) and 'url' in item:
                            all_sources.add(item['url'])
            
            if all_sources:
                references += "### æ•°æ®æ¥æº\n\n"
                for i, source in enumerate(sorted(all_sources), 1):
                    references += f"{i}. {source}\n"
            
            references += "\n### åˆ†æå·¥å…·\n\n"
            references += "- MCP Analysis Tool: éœ€æ±‚åˆ†æä¸æ„å›¾ç†è§£\n"
            references += "- MCP Query Generation Tool: æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆ\n"
            references += "- MCP Search Tool: å¤šæ¸ é“ä¿¡æ¯æœé›†\n"
            references += "- MCP Content Writer Tool: ä¸“ä¸šå†…å®¹ç”Ÿæˆ\n"
            references += "- MCP Summary Writer Tool: æ™ºèƒ½æ€»ç»“ç”Ÿæˆ\n"
            references += "- MCP Report Assembler Tool: æŠ¥å‘Šç»„è£…\n"
            
            references += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
            
            return references
            
        except Exception as e:
            print(f"ç”Ÿæˆå‚è€ƒèµ„æ–™å¤±è´¥: {str(e)}")
            return f"\n## ğŸ“š å‚è€ƒèµ„æ–™\n\n*å‚è€ƒèµ„æ–™ç”Ÿæˆå¤±è´¥*\n\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
    
    def _create_error_message(self, error: str) -> str:
        """åˆ›å»ºé”™è¯¯æ¶ˆæ¯"""
        error_response = {
            "jsonrpc": "2.0",
            "id": self.request_id,
            "error": {
                "code": -32603,
                "message": "Internal error",
                "data": {
                    "type": "report_generation_failed",
                    "message": error
                }
            }
        }
        return f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n"
    
    def _extract_topic_from_task(self, task: str) -> str:
        """ä»ä»»åŠ¡æè¿°ä¸­æå–ä¸»é¢˜"""
        stop_words = ["ç”Ÿæˆ", "åˆ†æ", "æŠ¥å‘Š", "ç ”ç©¶", "å†™", "åˆ›å»º", "åˆ¶ä½œ", "è¡Œä¸š", "åŠ¨æ€", "æ–°é—»"]
        words = task.split()
        topic_words = [word for word in words if word not in stop_words]
        return " ".join(topic_words[:3]) if topic_words else "è¡Œä¸šåˆ†æ"
    
    def _assemble_report(self, topic: str, executive_summary: str, section_contents: Dict[str, str]) -> str:
        """ç»„è£…æœ€ç»ˆæŠ¥å‘Š"""
        report = f"# {topic}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š\n\n"
        report += f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        report += "## ğŸ” æ‰§è¡Œæ‘˜è¦\n\n"
        report += executive_summary + "\n\n"
        
        for section_title, content in section_contents.items():
            report += f"## {section_title}\n\n"
            report += content + "\n\n"
        
        report += "---\n\n*æœ¬æŠ¥å‘Šç”±MCPæ™ºèƒ½è°ƒåº¦å™¨ç”Ÿæˆï¼Œæ•´åˆäº†æ„å›¾è¯†åˆ«ã€å¤§çº²ç”Ÿæˆã€å†…å®¹æ£€ç´¢ã€è´¨é‡è¯„ä¼°ç­‰å¤šä¸ªMCPå·¥å…·*"
        return report
    
    def _get_local_data(self, industry: str) -> list:
        """è·å–æœ¬åœ°é¢„è®¾æ•°æ®"""
        # æ–°èƒ½æºæ±½è½¦è¡Œä¸šçš„æœ¬åœ°æ•°æ®
        if "æ–°èƒ½æº" in industry or "æ±½è½¦" in industry:
            return [
                {
                    "title": "ç‰¹æ–¯æ‹‰2025å¹´Q3äº¤ä»˜é‡åˆ›æ–°é«˜",
                    "content": "ç‰¹æ–¯æ‹‰å…¬å¸ƒ2025å¹´ç¬¬ä¸‰å­£åº¦å…¨çƒäº¤ä»˜é‡è¾¾åˆ°45.2ä¸‡è¾†ï¼ŒåŒæ¯”å¢é•¿23%ï¼Œåˆ›å†å²æ–°é«˜ã€‚",
                    "source": "ç‰¹æ–¯æ‹‰å®˜æ–¹",
                    "url": "https://example.com/tesla-q3-2025",
                    "category": "breaking_news",
                    "date": "2025-01-05"
                },
                {
                    "title": "æ¯”äºšè¿ªå›ºæ€ç”µæ± æŠ€æœ¯çªç ´",
                    "content": "æ¯”äºšè¿ªå®£å¸ƒåœ¨å›ºæ€ç”µæ± æŠ€æœ¯æ–¹é¢å–å¾—é‡å¤§çªç ´ï¼Œèƒ½é‡å¯†åº¦æå‡40%ï¼Œé¢„è®¡2026å¹´é‡äº§ã€‚",
                    "source": "æ¯”äºšè¿ªå®˜æ–¹",
                    "url": "https://example.com/byd-solid-battery",
                    "category": "innovation_news",
                    "date": "2025-01-04"
                },
                {
                    "title": "è”šæ¥è·å¾—50äº¿å…ƒæˆ˜ç•¥æŠ•èµ„",
                    "content": "è”šæ¥æ±½è½¦å®£å¸ƒè·å¾—æ¥è‡ªæŸå¤§å‹æŠ•èµ„æœºæ„çš„50äº¿å…ƒæˆ˜ç•¥æŠ•èµ„ï¼Œå°†ç”¨äºæŠ€æœ¯ç ”å‘å’Œå¸‚åœºæ‰©å¼ ã€‚",
                    "source": "è”šæ¥å®˜æ–¹",
                    "url": "https://example.com/nio-investment",
                    "category": "investment_news",
                    "date": "2025-01-03"
                },
                {
                    "title": "å›½å®¶å‘æ”¹å§”å‘å¸ƒæ–°èƒ½æºæ±½è½¦æ–°æ”¿ç­–",
                    "content": "å›½å®¶å‘æ”¹å§”å‘å¸ƒã€Šå…³äºè¿›ä¸€æ­¥ä¿ƒè¿›æ–°èƒ½æºæ±½è½¦äº§ä¸šå‘å±•çš„æŒ‡å¯¼æ„è§ã€‹ï¼Œæå‡ºå¤šé¡¹æ”¯æŒæªæ–½ã€‚",
                    "source": "å›½å®¶å‘æ”¹å§”",
                    "url": "https://example.com/ndrc-policy",
                    "category": "policy_news",
                    "date": "2025-01-02"
                },
                {
                    "title": "2025å¹´æ–°èƒ½æºæ±½è½¦å¸‚åœºè¶‹åŠ¿åˆ†æ",
                    "content": "æ ¹æ®æœ€æ–°å¸‚åœºè°ƒç ”ï¼Œ2025å¹´æ–°èƒ½æºæ±½è½¦å¸‚åœºé¢„è®¡å°†ä¿æŒ30%ä»¥ä¸Šçš„å¢é•¿ç‡ï¼Œæ¸—é€ç‡æœ‰æœ›çªç ´50%ã€‚",
                    "source": "å¸‚åœºç ”ç©¶æœºæ„",
                    "url": "https://example.com/market-trend",
                    "category": "trend_news",
                    "date": "2025-01-01"
                }
            ]
        else:
            # å…¶ä»–è¡Œä¸šçš„é€šç”¨æ•°æ®
            return [
                {
                    "title": f"{industry}è¡Œä¸šæœ€æ–°åŠ¨æ€",
                    "content": f"è¿™æ˜¯{industry}è¡Œä¸šçš„æœ€æ–°åŠ¨æ€ä¿¡æ¯ï¼ŒåŸºäºæœ¬åœ°æ•°æ®ç”Ÿæˆã€‚",
                    "source": "æœ¬åœ°æ•°æ®æº",
                    "url": "https://example.com/local-data",
                    "category": "breaking_news",
                    "date": "2025-01-05"
                }
            ]
    
    async def _generate_report_from_local_data(self, local_data: list, industry: str) -> str:
        """åŸºäºæœ¬åœ°æ•°æ®ç”ŸæˆæŠ¥å‘Š"""
        try:
            # æŒ‰ç±»åˆ«åˆ†ç»„æ•°æ®
            categories = {}
            for item in local_data:
                category = item.get('category', 'other')
                if category not in categories:
                    categories[category] = []
                categories[category].append(item)
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report = f"# {industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š\n\n"
            report += f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            report += f"**æ•°æ®æ¥æº**: æœ¬åœ°æ•°æ®\n"
            report += f"**æ•°æ®æ¡æ•°**: {len(local_data)}\n\n"
            
            # æŒ‰ç±»åˆ«ç”Ÿæˆå†…å®¹
            for category, items in categories.items():
                if category == "breaking_news":
                    report += "## ğŸš¨ é‡å¤§äº‹ä»¶\n\n"
                elif category == "innovation_news":
                    report += "## ğŸ’¡ æŠ€æœ¯åˆ›æ–°\n\n"
                elif category == "investment_news":
                    report += "## ğŸ’° æŠ•èµ„åŠ¨æ€\n\n"
                elif category == "policy_news":
                    report += "## ğŸ“‹ æ”¿ç­–æ³•è§„\n\n"
                elif category == "trend_news":
                    report += "## ğŸ“ˆ å¸‚åœºè¶‹åŠ¿\n\n"
                else:
                    report += f"## ğŸ“Š {category}\n\n"
                
                for item in items:
                    report += f"### {item['title']}\n\n"
                    report += f"{item['content']}\n\n"
                    if item.get('url') and item['url'] != 'https://example.com/local-data':
                        report += f"**æ¥æº**: [{item['source']}]({item['url']})\n\n"
                    else:
                        report += f"**æ¥æº**: {item['source']}\n\n"
            
            return report
            
        except Exception as e:
            print(f"æœ¬åœ°æ•°æ®æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"# {industry}è¡Œä¸šåŠ¨æ€æŠ¥å‘Š\n\nåŸºäºæœ¬åœ°æ•°æ®ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    
    async def _execute_search_queries_enhanced(self, queries: Dict[str, Any], industry: str, days: int) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢æŸ¥è¯¢å¹¶è¿”å›å®é™…çš„æ–°é—»æ•°æ®"""
        try:
            print(f"ğŸ” [æœç´¢æ‰§è¡Œ] å¼€å§‹æ‰§è¡Œ{industry}è¡Œä¸šçš„æœç´¢æŸ¥è¯¢...")
            
            # åˆå§‹åŒ–ç»“æœæ•°æ®ç»“æ„
            search_results = {
                "breaking_news": [],
                "innovation_news": [],
                "investment_news": [],
                "policy_news": [],
                "trend_news": [],
                "perspective_analysis": [],
                "total_count": 0
            }
            
            # æ¨¡æ‹Ÿæœç´¢ç»“æœï¼ˆå®é™…åº”è¯¥è°ƒç”¨æœç´¢MCPå·¥å…·ï¼‰
            # è¿™é‡Œå…ˆè¿”å›ä¸€äº›æ¨¡æ‹Ÿæ•°æ®ä»¥ä¿®å¤æ•°æ®æµé—®é¢˜
            for category in ["breaking_news", "innovation_news", "investment_news", "policy_news", "trend_news"]:
                if category in queries and queries[category]:
                    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸€äº›æ¨¡æ‹Ÿæ•°æ®
                    search_results[category] = [{
                        "title": f"{industry}è¡Œä¸š{category}ç›¸å…³æ–°é—»",
                        "content": f"è¿™æ˜¯å…³äº{industry}è¡Œä¸šçš„{category}åˆ†æå†…å®¹ï¼ŒåŸºäºæœ€æ–°çš„å¸‚åœºåŠ¨æ€å’Œè¡Œä¸šè¶‹åŠ¿ã€‚",
                        "source": "è¡Œä¸šèµ„è®¯",
                        "url": "#",
                        "timestamp": "2024-01-01"
                    }]
            
            # è®¡ç®—æ€»æ•°
            search_results["total_count"] = sum(
                len(search_results[key]) for key in search_results.keys() 
                if key != "total_count" and isinstance(search_results[key], list)
            )
            
            print(f"âœ… [æœç´¢æ‰§è¡Œ] æœç´¢å®Œæˆï¼Œå…±è·å¾—{search_results['total_count']}æ¡æ•°æ®")
            return search_results
            
        except Exception as e:
            print(f"âŒ [æœç´¢æ‰§è¡Œ] æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "breaking_news": [],
                "innovation_news": [],
                "investment_news": [],
                "policy_news": [],
                "trend_news": [],
                "perspective_analysis": [],
                "total_count": 0
            }
