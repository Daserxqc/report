#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœç´¢MCPä¸åˆ†æMCPé›†æˆæµ‹è¯•
æµ‹è¯•æœç´¢ç»“æœä¸åˆ†æè¯„ä¼°ä¹‹é—´çš„æ•°æ®æ ¼å¼å…¼å®¹æ€§é—®é¢˜
"""

import sys
import os
import json
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "collectors"))
sys.path.insert(0, str(project_root / "search_mcp" / "src"))

def test_search_mcp_output_format():
    """æµ‹è¯•æœç´¢MCPçš„è¾“å‡ºæ ¼å¼"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•æœç´¢MCPè¾“å‡ºæ ¼å¼")
    print("="*60)
    
    try:
        # å¯¼å…¥main.pyä¸­çš„æœç´¢å‡½æ•°
        from main import comprehensive_search, parallel_search
        
        # æµ‹è¯•comprehensive_search
        print("\n1. æµ‹è¯•comprehensive_searchè¾“å‡ºæ ¼å¼:")
        search_result = comprehensive_search("äººå·¥æ™ºèƒ½", days=7, max_results=3)
        print(f"   è¿”å›ç±»å‹: {type(search_result)}")
        print(f"   è¿”å›å†…å®¹é•¿åº¦: {len(search_result) if search_result else 0}")
        print(f"   å‰200å­—ç¬¦: {search_result[:200] if search_result else 'None'}...")
        
        # æµ‹è¯•parallel_search
        print("\n2. æµ‹è¯•parallel_searchè¾“å‡ºæ ¼å¼:")
        parallel_result = parallel_search(["AIæŠ€æœ¯", "æœºå™¨å­¦ä¹ "], max_results=3, topic="äººå·¥æ™ºèƒ½")
        print(f"   è¿”å›ç±»å‹: {type(parallel_result)}")
        print(f"   è¿”å›å†…å®¹é•¿åº¦: {len(parallel_result) if parallel_result else 0}")
        print(f"   å‰200å­—ç¬¦: {parallel_result[:200] if parallel_result else 'None'}...")
        
        return search_result, parallel_result
        
    except Exception as e:
        print(f"âŒ æœç´¢MCPæµ‹è¯•å¤±è´¥: {e}")
        return None, None

def test_analysis_mcp_input_requirements():
    """æµ‹è¯•åˆ†æMCPçš„è¾“å…¥è¦æ±‚"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•åˆ†æMCPè¾“å…¥è¦æ±‚")
    print("="*60)
    
    try:
        from main import analysis_mcp
        
        # æµ‹è¯•1: ä½¿ç”¨æ­£ç¡®çš„List[Dict]æ ¼å¼
        print("\n1. æµ‹è¯•æ­£ç¡®çš„List[Dict]æ ¼å¼:")
        correct_data = [
            {
                "title": "äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
                "content": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ é¢†åŸŸå–å¾—äº†é‡å¤§çªç ´ã€‚",
                "url": "https://example.com/ai-trends",
                "source": "tech_news"
            },
            {
                "title": "AIåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
                "content": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ã€è¯ç‰©å‘ç°å’Œä¸ªæ€§åŒ–æ²»ç–—æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚",
                "url": "https://example.com/ai-medical",
                "source": "medical_journal"
            }
        ]
        
        result1 = analysis_mcp("quality", correct_data, "äººå·¥æ™ºèƒ½")
        print(f"   è¿”å›ç±»å‹: {type(result1)}")
        
        # å°è¯•è§£æJSONç»“æœ
        try:
            parsed_result = json.loads(result1)
            print(f"   è§£ææˆåŠŸï¼Œå¾—åˆ†: {parsed_result.get('score', 'N/A')}")
            print(f"   åˆ†æç±»å‹: {parsed_result.get('analysis_type', 'N/A')}")
        except:
            print(f"   JSONè§£æå¤±è´¥ï¼ŒåŸå§‹ç»“æœ: {result1[:200]}...")
        
        # æµ‹è¯•2: ä½¿ç”¨é”™è¯¯çš„å­—ç¬¦ä¸²æ ¼å¼
        print("\n2. æµ‹è¯•é”™è¯¯çš„å­—ç¬¦ä¸²æ ¼å¼:")
        wrong_data = "è¿™æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²æ ¼å¼çš„æœç´¢ç»“æœï¼ŒåŒ…å«äººå·¥æ™ºèƒ½ç›¸å…³ä¿¡æ¯..."
        
        result2 = analysis_mcp("quality", wrong_data, "äººå·¥æ™ºèƒ½")
        print(f"   è¿”å›ç±»å‹: {type(result2)}")
        
        try:
            parsed_result2 = json.loads(result2)
            print(f"   è§£ææˆåŠŸï¼Œå¾—åˆ†: {parsed_result2.get('score', 'N/A')}")
        except:
            print(f"   JSONè§£æå¤±è´¥ï¼ŒåŸå§‹ç»“æœ: {result2[:200]}...")
            
        return result1, result2
        
    except Exception as e:
        print(f"âŒ åˆ†æMCPæµ‹è¯•å¤±è´¥: {e}")
        return None, None

def convert_search_result_to_dict_format(search_result_str: str) -> List[Dict]:
    """å°†æœç´¢MCPçš„å­—ç¬¦ä¸²ç»“æœè½¬æ¢ä¸ºåˆ†æMCPæœŸæœ›çš„List[Dict]æ ¼å¼"""
    print("\n" + "="*60)
    print("ğŸ”„ è½¬æ¢æœç´¢ç»“æœæ ¼å¼")
    print("="*60)
    
    if not search_result_str or not isinstance(search_result_str, str):
        print("âŒ è¾“å…¥æ•°æ®æ— æ•ˆ")
        return []
    
    # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æœç´¢ç»“æœæ ¼å¼è¿›è¡Œè°ƒæ•´
    converted_data = []
    
    try:
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
        lines = search_result_str.split('\n')
        current_item = {}
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æµ‹æ ‡é¢˜è¡Œï¼ˆé€šå¸¸ä»¥æ•°å­—å¼€å¤´æˆ–åŒ…å«**ï¼‰
            if line.startswith(('1.', '2.', '3.', '4.', '5.')) or '**' in line:
                if current_item and current_item.get('title'):
                    converted_data.append(current_item)
                    current_item = {}
                
                # æå–æ ‡é¢˜
                title = line.replace('**', '').strip()
                if title.startswith(tuple('12345')):
                    title = title[2:].strip()  # ç§»é™¤åºå·
                current_item['title'] = title
                
            # æ£€æµ‹URLè¡Œ
            elif 'http' in line or 'æ¥æº:' in line:
                if 'æ¥æº:' in line:
                    url = line.replace('æ¥æº:', '').strip()
                else:
                    url = line.strip()
                current_item['url'] = url
                
            # æ£€æµ‹æœç´¢å¼•æ“è¡Œ
            elif 'æœç´¢å¼•æ“:' in line:
                source = line.replace('æœç´¢å¼•æ“:', '').strip()
                current_item['source'] = source
                
            # å…¶ä»–è¡Œä½œä¸ºå†…å®¹
            elif line and not line.startswith(('#', '=', '-')):
                if 'content' not in current_item:
                    current_item['content'] = line
                else:
                    current_item['content'] += ' ' + line
        
        # æ·»åŠ æœ€åä¸€ä¸ªé¡¹ç›®
        if current_item and current_item.get('title'):
            converted_data.append(current_item)
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªé€šç”¨é¡¹ç›®
        if not converted_data:
            converted_data = [{
                'title': 'æœç´¢ç»“æœ',
                'content': search_result_str[:500],  # å–å‰500å­—ç¬¦
                'url': 'unknown',
                'source': 'search_mcp'
            }]
            
        print(f"âœ… è½¬æ¢å®Œæˆï¼Œå…±æå– {len(converted_data)} ä¸ªé¡¹ç›®")
        for i, item in enumerate(converted_data, 1):
            print(f"   [{i}] æ ‡é¢˜: {item.get('title', 'N/A')[:50]}...")
            print(f"       å†…å®¹é•¿åº¦: {len(item.get('content', ''))}")
            
        return converted_data
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        # è¿”å›ä¸€ä¸ªåŸºæœ¬çš„æ ¼å¼
        return [{
            'title': 'æœç´¢ç»“æœ',
            'content': search_result_str[:500] if search_result_str else '',
            'url': 'unknown',
            'source': 'search_mcp'
        }]

def test_integrated_workflow():
    """æµ‹è¯•å®Œæ•´çš„æœç´¢->è½¬æ¢->åˆ†æå·¥ä½œæµ"""
    print("\n" + "="*60)
    print("ğŸš€ æµ‹è¯•å®Œæ•´å·¥ä½œæµ")
    print("="*60)
    
    try:
        from main import comprehensive_search, analysis_mcp
        
        # æ­¥éª¤1: æ‰§è¡Œæœç´¢
        print("\næ­¥éª¤1: æ‰§è¡Œæœç´¢")
        search_result = comprehensive_search("äººå·¥æ™ºèƒ½", days=7, max_results=3)
        print(f"æœç´¢å®Œæˆï¼Œç»“æœé•¿åº¦: {len(search_result) if search_result else 0}")
        
        if not search_result:
            print("âŒ æœç´¢æ— ç»“æœï¼Œæµ‹è¯•ç»ˆæ­¢")
            return False
        
        # æ­¥éª¤2: è½¬æ¢æ ¼å¼
        print("\næ­¥éª¤2: è½¬æ¢æ•°æ®æ ¼å¼")
        converted_data = convert_search_result_to_dict_format(search_result)
        print(f"è½¬æ¢å®Œæˆï¼Œæ•°æ®é¡¹æ•°: {len(converted_data)}")
        
        # æ­¥éª¤3: æ‰§è¡Œåˆ†æ
        print("\næ­¥éª¤3: æ‰§è¡Œè´¨é‡åˆ†æ")
        analysis_result = analysis_mcp("quality", converted_data, "äººå·¥æ™ºèƒ½")
        print(f"åˆ†æå®Œæˆï¼Œç»“æœç±»å‹: {type(analysis_result)}")
        
        # æ­¥éª¤4: è§£æåˆ†æç»“æœ
        print("\næ­¥éª¤4: è§£æåˆ†æç»“æœ")
        try:
            parsed_analysis = json.loads(analysis_result)
            score = parsed_analysis.get('score', 0)
            reasoning = parsed_analysis.get('reasoning', 'N/A')
            
            print(f"âœ… è´¨é‡è¯„åˆ†: {score}/10")
            print(f"âœ… è¯„ä¼°ç†ç”±: {reasoning[:200]}...")
            
            if score > 0:
                print("\nğŸ‰ é›†æˆæµ‹è¯•æˆåŠŸï¼æœç´¢ç»“æœæˆåŠŸè½¬æ¢å¹¶è·å¾—äº†è´¨é‡è¯„åˆ†")
                return True
            else:
                print("\nâš ï¸ é›†æˆæµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼Œä½†è´¨é‡è¯„åˆ†ä¸º0")
                return False
                
        except json.JSONDecodeError as e:
            print(f"âŒ åˆ†æç»“æœJSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹ç»“æœ: {analysis_result[:300]}...")
            return False
            
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æœç´¢MCPä¸åˆ†æMCPé›†æˆæµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•ç»“æœç»Ÿè®¡
    test_results = {
        'search_output_format': False,
        'analysis_input_requirements': False,
        'format_conversion': False,
        'integrated_workflow': False
    }
    
    # 1. æµ‹è¯•æœç´¢MCPè¾“å‡ºæ ¼å¼
    search_result, parallel_result = test_search_mcp_output_format()
    test_results['search_output_format'] = search_result is not None
    
    # 2. æµ‹è¯•åˆ†æMCPè¾“å…¥è¦æ±‚
    analysis_result1, analysis_result2 = test_analysis_mcp_input_requirements()
    test_results['analysis_input_requirements'] = analysis_result1 is not None
    
    # 3. æµ‹è¯•æ ¼å¼è½¬æ¢
    if search_result:
        converted_data = convert_search_result_to_dict_format(search_result)
        test_results['format_conversion'] = len(converted_data) > 0
    
    # 4. æµ‹è¯•å®Œæ•´å·¥ä½œæµ
    test_results['integrated_workflow'] = test_integrated_workflow()
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*80)
    
    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:30} {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed_tests}/{total_tests} é¡¹æµ‹è¯•é€šè¿‡")
    
    if test_results['integrated_workflow']:
        print("\nğŸ‰ é—®é¢˜å·²è§£å†³ï¼æœç´¢MCPå’Œåˆ†æMCPç°åœ¨å¯ä»¥æ­£å¸¸åä½œäº†")
    else:
        print("\nâš ï¸ ä»å­˜åœ¨é›†æˆé—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        
        # æä¾›è§£å†³æ–¹æ¡ˆå»ºè®®
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®:")
        print("1. ä¿®æ”¹æœç´¢MCPè¿”å›ç»“æ„åŒ–çš„List[Dict]æ•°æ®è€Œä¸æ˜¯å­—ç¬¦ä¸²")
        print("2. åœ¨è°ƒç”¨åˆ†æMCPä¹‹å‰æ·»åŠ æ•°æ®æ ¼å¼è½¬æ¢æ­¥éª¤")
        print("3. ç»Ÿä¸€æœç´¢å’Œåˆ†æMCPä¹‹é—´çš„æ•°æ®æ¥å£è§„èŒƒ")

if __name__ == "__main__":
    main()