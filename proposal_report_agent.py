"""
å¼€é¢˜æŠ¥å‘Šç”ŸæˆAgent
åŠŸèƒ½ï¼š
1. æ ¹æ®ç”¨æˆ·è¾“å…¥çš„é¢˜ç›®ç”Ÿæˆç›¸å…³ç ”ç©¶æ–¹å‘
2. ä¸ç”¨æˆ·äº¤äº’ç¡®è®¤ç ”ç©¶æ–¹å‘
3. ç”Ÿæˆå¼€é¢˜æŠ¥å‘Šå¤§çº²å¹¶ä¸ç”¨æˆ·ç¡®è®¤
4. è°ƒç”¨å¤šä¸ªAPIè¿›è¡Œå†…å®¹æ£€ç´¢å’Œæ±‡æ€»
5. ç”Ÿæˆè§„èŒƒçš„å¼€é¢˜æŠ¥å‘Š
"""

import os
import json
import sys
from datetime import datetime
from dotenv import load_dotenv
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from collectors.tavily_collector import TavilyCollector
from collectors.google_search_collector import GoogleSearchCollector
from collectors.brave_search_collector import BraveSearchCollector
from collectors.arxiv_collector import ArxivCollector
from collectors.llm_processor import LLMProcessor
from collectors.parallel_llm_processor import ParallelLLMProcessor

class ProposalReportAgent:
    """å¼€é¢˜æŠ¥å‘Šç”ŸæˆAgent"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„ç§æœç´¢æ”¶é›†å™¨
        self.collectors = {}
        self.llm_processor = None
        
        # åˆå§‹åŒ–LLMå¤„ç†å™¨
        try:
            self.llm_processor = LLMProcessor()
            print("âœ… LLMå¤„ç†å™¨å·²åˆå§‹åŒ–")
        except Exception as e:
            print(f"âŒ LLMå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return
        
        # åˆå§‹åŒ–æœç´¢æ”¶é›†å™¨
        self._init_collectors()
        
        # å¼€é¢˜æŠ¥å‘Šæ ‡å‡†å¤§çº²
        self.standard_outline = {
            "1": "ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰",
            "2": "å›½å†…å¤–ç ”ç©¶ç°çŠ¶",
            "3": "ç ”ç©¶ç›®æ ‡ä¸å†…å®¹",
            "4": "ç ”ç©¶æ–¹æ³•ä¸æŠ€æœ¯è·¯çº¿",
            "5": "é¢„æœŸæˆæœä¸åˆ›æ–°ç‚¹",
            "6": "ç ”ç©¶è¿›åº¦å®‰æ’",
            "7": "å‚è€ƒæ–‡çŒ®"
        }
    
    def _init_collectors(self):
        """åˆå§‹åŒ–å„ç§æœç´¢æ”¶é›†å™¨"""
        # åˆå§‹åŒ–Tavily
        try:
            self.tavily_collector = TavilyCollector()
            self.collectors['tavily'] = self.tavily_collector
            print("âœ… Tavilyæœç´¢å¼•æ“å·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸ Tavilyæœç´¢å¼•æ“ä¸å¯ç”¨: {str(e)}")
        
        # åˆå§‹åŒ–Googleæœç´¢
        try:
            self.google_collector = GoogleSearchCollector()
            if self.google_collector.has_api_key:
                self.collectors['google'] = self.google_collector
                print("âœ… Googleæœç´¢å¼•æ“å·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸ Googleæœç´¢å¼•æ“ä¸å¯ç”¨: {str(e)}")
        
        # åˆå§‹åŒ–Braveæœç´¢
        try:
            self.brave_collector = BraveSearchCollector()
            if self.brave_collector.has_api_key:
                self.collectors['brave'] = self.brave_collector
                print("âœ… Braveæœç´¢å¼•æ“å·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸ Braveæœç´¢å¼•æ“ä¸å¯ç”¨: {str(e)}")
        
        # åˆå§‹åŒ–ArXiv
        try:
            self.arxiv_collector = ArxivCollector()
            self.collectors['arxiv'] = self.arxiv_collector
            print("âœ… ArXivå­¦æœ¯æœç´¢å·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸ ArXivå­¦æœ¯æœç´¢ä¸å¯ç”¨: {str(e)}")
        
        print(f"ğŸ” å…±å¯ç”¨ {len(self.collectors)} ä¸ªæœç´¢å¼•æ“")
    
    def generate_research_directions(self, topic):
        """
        æ­¥éª¤1ï¼šæ ¹æ®ç”¨æˆ·é¢˜ç›®ç”Ÿæˆç›¸å…³ç ”ç©¶æ–¹å‘
        """
        print(f"ğŸ§  [ç ”ç©¶æ–¹å‘ç”Ÿæˆ] æ­£åœ¨ä¸ºé¢˜ç›® '{topic}' ç”Ÿæˆç›¸å…³ç ”ç©¶æ–¹å‘...")
        
        direction_prompt = f"""
        ç”¨æˆ·æä¾›çš„ç ”ç©¶é¢˜ç›®: "{topic}"
        
        è¯·ä½œä¸ºä¸€ä¸ªèµ„æ·±çš„å­¦æœ¯å¯¼å¸ˆï¼ŒåŸºäºè¯¥é¢˜ç›®ç”Ÿæˆ5ä¸ªç›¸å…³çš„ã€å…·ä½“çš„ç ”ç©¶æ–¹å‘ã€‚
        æ¯ä¸ªç ”ç©¶æ–¹å‘åº”è¯¥ï¼š
        1. ä¸åŸé¢˜ç›®ç´§å¯†ç›¸å…³ä½†æœ‰æ‰€ç»†åŒ–
        2. å…·æœ‰å­¦æœ¯ç ”ç©¶ä»·å€¼å’Œå¯è¡Œæ€§
        3. ç¬¦åˆå½“å‰å­¦æœ¯ç ”ç©¶çƒ­ç‚¹
        4. å¯ä»¥ä½œä¸ºå­¦ä½è®ºæ–‡çš„ç ”ç©¶æ–¹å‘
        5. è¡¨è¿°æ¸…æ™°ã€ä¸“ä¸š
        
        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
        {{
            "original_topic": "åŸå§‹é¢˜ç›®",
            "research_directions": [
                {{
                    "direction": "ç ”ç©¶æ–¹å‘1",
                    "description": "è¯¥æ–¹å‘çš„ç®€è¦æè¿°å’Œç ”ç©¶ä»·å€¼",
                    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"]
                }},
                {{
                    "direction": "ç ”ç©¶æ–¹å‘2",
                    "description": "è¯¥æ–¹å‘çš„ç®€è¦æè¿°å’Œç ”ç©¶ä»·å€¼",
                    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"]
                }}
            ]
        }}
        
        ç¡®ä¿ç”Ÿæˆ5ä¸ªä¸åŒçš„ç ”ç©¶æ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘éƒ½è¦æœ‰æ¸…æ™°çš„æè¿°å’Œç›¸å…³å…³é”®è¯ã€‚
        """
        
        try:
            response = self.llm_processor.call_llm_api(
                direction_prompt,
                "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å­¦æœ¯å¯¼å¸ˆï¼Œæ“…é•¿æŒ‡å¯¼å­¦ç”Ÿç¡®å®šç ”ç©¶æ–¹å‘ã€‚",
                max_tokens=2000
            )
            
            # è§£æJSONå“åº”
            direction_data = self._parse_json_response(response)
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(direction_data.get('research_directions', []))} ä¸ªç ”ç©¶æ–¹å‘")
            return direction_data
            
        except Exception as e:
            print(f"âŒ ç ”ç©¶æ–¹å‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._get_fallback_directions(topic)
    
    def _parse_json_response(self, response):
        """è§£æLLMçš„JSONå“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
        except Exception as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {str(e)}")
            raise
    
    def _get_fallback_directions(self, topic):
        """å¤‡ç”¨ç ”ç©¶æ–¹å‘ç”Ÿæˆ"""
        return {
            "original_topic": topic,
            "research_directions": [
                {
                    "direction": f"{topic}çš„ç†è®ºåŸºç¡€ç ”ç©¶",
                    "description": "æ·±å…¥æ¢è®¨è¯¥é¢†åŸŸçš„ç†è®ºåŸºç¡€å’Œæ ¸å¿ƒæ¦‚å¿µ",
                    "keywords": ["ç†è®ºåŸºç¡€", "æ ¸å¿ƒæ¦‚å¿µ", "åŸºç¡€ç ”ç©¶"]
                },
                {
                    "direction": f"{topic}çš„æŠ€æœ¯å®ç°ç ”ç©¶",
                    "description": "ç ”ç©¶è¯¥é¢†åŸŸçš„æŠ€æœ¯å®ç°æ–¹æ³•å’Œå…³é”®æŠ€æœ¯",
                    "keywords": ["æŠ€æœ¯å®ç°", "å…³é”®æŠ€æœ¯", "æ–¹æ³•ç ”ç©¶"]
                },
                {
                    "direction": f"{topic}çš„åº”ç”¨åœºæ™¯ç ”ç©¶",
                    "description": "æ¢ç´¢è¯¥é¢†åŸŸåœ¨å®é™…åº”ç”¨ä¸­çš„åœºæ™¯å’Œæ•ˆæœ",
                    "keywords": ["åº”ç”¨åœºæ™¯", "å®é™…åº”ç”¨", "æ•ˆæœè¯„ä¼°"]
                }
            ]
        }
    
    def confirm_research_direction(self, directions_data):
        """
        æ­¥éª¤2ï¼šä¸ç”¨æˆ·äº¤äº’ç¡®è®¤ç ”ç©¶æ–¹å‘
        """
        print(f"\nğŸ“‹ åŸºäºæ‚¨çš„é¢˜ç›® '{directions_data['original_topic']}' ç”Ÿæˆçš„ç ”ç©¶æ–¹å‘ï¼š")
        print("=" * 70)
        
        while True:
            # æ˜¾ç¤ºç ”ç©¶æ–¹å‘
            directions = directions_data['research_directions']
            for i, direction in enumerate(directions, 1):
                print(f"\n{i}. {direction['direction']}")
                print(f"   æè¿°ï¼š{direction['description']}")
                print(f"   å…³é”®è¯ï¼š{', '.join(direction['keywords'])}")
            
            print(f"\né€‰æ‹©é€‰é¡¹ï¼š")
            print("1-5: é€‰æ‹©å¯¹åº”çš„ç ”ç©¶æ–¹å‘")
            print("r: é‡æ–°ç”Ÿæˆç ”ç©¶æ–¹å‘")
            print("c: è‡ªå®šä¹‰ç ”ç©¶æ–¹å‘")
            
            choice = input("\nè¯·è¾“å…¥æ‚¨çš„é€‰æ‹©: ").strip().lower()
            
            if choice in ['1', '2', '3', '4', '5']:
                idx = int(choice) - 1
                if idx < len(directions):
                    selected_direction = directions[idx]
                    print(f"\nâœ… æ‚¨é€‰æ‹©äº†: {selected_direction['direction']}")
                    confirm = input("ç¡®è®¤æ­¤ç ”ç©¶æ–¹å‘å—ï¼Ÿ(y/n): ").strip().lower()
                    if confirm == 'y':
                        return selected_direction
                    else:
                        continue
                else:
                    print("âš ï¸ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            
            elif choice == 'r':
                # é‡æ–°ç”Ÿæˆç ”ç©¶æ–¹å‘
                print("\nğŸ”„ é‡æ–°ç”Ÿæˆç ”ç©¶æ–¹å‘...")
                new_directions = self.generate_research_directions(directions_data['original_topic'])
                directions_data = new_directions
                print(f"\nğŸ“‹ é‡æ–°ç”Ÿæˆçš„ç ”ç©¶æ–¹å‘ï¼š")
                print("=" * 70)
                
            elif choice == 'c':
                # è‡ªå®šä¹‰ç ”ç©¶æ–¹å‘
                custom_direction = input("\nè¯·è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰ç ”ç©¶æ–¹å‘: ").strip()
                if custom_direction:
                    custom_description = input("è¯·ç®€è¦æè¿°è¯¥ç ”ç©¶æ–¹å‘çš„ä»·å€¼å’Œæ„ä¹‰: ").strip()
                    custom_keywords = input("è¯·è¾“å…¥ç›¸å…³å…³é”®è¯ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰: ").strip().split(',')
                    
                    selected_direction = {
                        "direction": custom_direction,
                        "description": custom_description,
                        "keywords": [k.strip() for k in custom_keywords]
                    }
                    print(f"\nâœ… æ‚¨çš„è‡ªå®šä¹‰ç ”ç©¶æ–¹å‘: {selected_direction['direction']}")
                    return selected_direction
                else:
                    print("âš ï¸ ç ”ç©¶æ–¹å‘ä¸èƒ½ä¸ºç©º")
            
            else:
                print("âš ï¸ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def generate_proposal_outline(self, selected_direction):
        """
        æ­¥éª¤3ï¼šç”Ÿæˆå¼€é¢˜æŠ¥å‘Šå¤§çº²
        """
        print(f"\nğŸ“ [å¤§çº²ç”Ÿæˆ] æ­£åœ¨ä¸ºç ”ç©¶æ–¹å‘ '{selected_direction['direction']}' ç”Ÿæˆå¼€é¢˜æŠ¥å‘Šå¤§çº²...")
        
        outline_prompt = f"""
        ç ”ç©¶æ–¹å‘: "{selected_direction['direction']}"
        ç ”ç©¶æè¿°: "{selected_direction['description']}"
        å…³é”®è¯: {', '.join(selected_direction['keywords'])}
        
        è¯·ä½œä¸ºä¸€ä¸ªèµ„æ·±çš„å­¦æœ¯å¯¼å¸ˆï¼Œä¸ºè¯¥ç ”ç©¶æ–¹å‘ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„å¼€é¢˜æŠ¥å‘Šå¤§çº²ã€‚
        
        æ ‡å‡†å¼€é¢˜æŠ¥å‘Šåº”åŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š
        1. ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰
        2. å›½å†…å¤–ç ”ç©¶ç°çŠ¶
        3. ç ”ç©¶ç›®æ ‡ä¸å†…å®¹
        4. ç ”ç©¶æ–¹æ³•ä¸æŠ€æœ¯è·¯çº¿
        5. é¢„æœŸæˆæœä¸åˆ›æ–°ç‚¹
        6. ç ”ç©¶è¿›åº¦å®‰æ’
        7. å‚è€ƒæ–‡çŒ®
        
        è¯·ä¸ºæ¯ä¸ªéƒ¨åˆ†ç”Ÿæˆè¯¦ç»†çš„å­é¡¹ç›®ï¼Œç¡®ä¿ï¼š
        - æ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰3-5ä¸ªå…·ä½“çš„å­é¡¹ç›®
        - å­é¡¹ç›®è¦å…·ä½“ã€å¯æ‰§è¡Œ
        - ç¬¦åˆå­¦æœ¯ç ”ç©¶è§„èŒƒ
        - é’ˆå¯¹è¯¥ç ”ç©¶æ–¹å‘çš„ç‰¹ç‚¹
        
        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
        {{
            "research_direction": "ç ”ç©¶æ–¹å‘",
            "outline": {{
                "1": {{
                    "title": "ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰",
                    "sub_items": [
                        "å…·ä½“å­é¡¹ç›®1",
                        "å…·ä½“å­é¡¹ç›®2",
                        "å…·ä½“å­é¡¹ç›®3"
                    ]
                }},
                "2": {{
                    "title": "å›½å†…å¤–ç ”ç©¶ç°çŠ¶",
                    "sub_items": [
                        "å…·ä½“å­é¡¹ç›®1",
                        "å…·ä½“å­é¡¹ç›®2",
                        "å…·ä½“å­é¡¹ç›®3"
                    ]
                }}
            }}
        }}
        
        ç¡®ä¿ç”Ÿæˆå®Œæ•´çš„7ä¸ªéƒ¨åˆ†çš„å¤§çº²ã€‚
        """
        
        try:
            response = self.llm_processor.call_llm_api(
                outline_prompt,
                "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å­¦æœ¯å¯¼å¸ˆï¼Œæ“…é•¿æŒ‡å¯¼å­¦ç”Ÿåˆ¶å®šå¼€é¢˜æŠ¥å‘Šå¤§çº²ã€‚",
                max_tokens=3000
            )
            
            # è§£æJSONå“åº”
            outline_data = self._parse_json_response(response)
            print(f"âœ… æˆåŠŸç”Ÿæˆå¼€é¢˜æŠ¥å‘Šå¤§çº²")
            return outline_data
            
        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._get_fallback_outline(selected_direction)
    
    def _get_fallback_outline(self, selected_direction):
        """å¤‡ç”¨å¤§çº²ç”Ÿæˆ"""
        return {
            "research_direction": selected_direction['direction'],
            "outline": {
                "1": {
                    "title": "ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰",
                    "sub_items": [
                        "ç ”ç©¶é—®é¢˜çš„æå‡º",
                        "ç ”ç©¶æ„ä¹‰åˆ†æ",
                        "ç ”ç©¶ä»·å€¼é˜è¿°"
                    ]
                },
                "2": {
                    "title": "å›½å†…å¤–ç ”ç©¶ç°çŠ¶",
                    "sub_items": [
                        "å›½å¤–ç ”ç©¶ç°çŠ¶åˆ†æ",
                        "å›½å†…ç ”ç©¶ç°çŠ¶åˆ†æ",
                        "ç ”ç©¶ä¸è¶³ä¸å‘å±•è¶‹åŠ¿"
                    ]
                },
                "3": {
                    "title": "ç ”ç©¶ç›®æ ‡ä¸å†…å®¹",
                    "sub_items": [
                        "ç ”ç©¶ç›®æ ‡ç¡®å®š",
                        "ç ”ç©¶å†…å®¹è§„åˆ’",
                        "ç ”ç©¶èŒƒå›´ç•Œå®š"
                    ]
                },
                "4": {
                    "title": "ç ”ç©¶æ–¹æ³•ä¸æŠ€æœ¯è·¯çº¿",
                    "sub_items": [
                        "ç ”ç©¶æ–¹æ³•é€‰æ‹©",
                        "æŠ€æœ¯è·¯çº¿è®¾è®¡",
                        "å®æ–½æ–¹æ¡ˆåˆ¶å®š"
                    ]
                },
                "5": {
                    "title": "é¢„æœŸæˆæœä¸åˆ›æ–°ç‚¹",
                    "sub_items": [
                        "é¢„æœŸæˆæœæè¿°",
                        "åˆ›æ–°ç‚¹åˆ†æ",
                        "å­¦æœ¯è´¡çŒ®æ€»ç»“"
                    ]
                },
                "6": {
                    "title": "ç ”ç©¶è¿›åº¦å®‰æ’",
                    "sub_items": [
                        "ç ”ç©¶é˜¶æ®µåˆ’åˆ†",
                        "æ—¶é—´è¿›åº¦å®‰æ’",
                        "é‡Œç¨‹ç¢‘è®¾å®š"
                    ]
                },
                "7": {
                    "title": "å‚è€ƒæ–‡çŒ®",
                    "sub_items": [
                        "æ–‡çŒ®æ”¶é›†æ•´ç†",
                        "å¼•ç”¨æ ¼å¼è§„èŒƒ",
                        "å‚è€ƒæ–‡çŒ®åˆ—è¡¨"
                    ]
                }
            }
        }
    
    def confirm_outline(self, outline_data):
        """
        æ­¥éª¤4ï¼šä¸ç”¨æˆ·ç¡®è®¤å’Œä¿®æ”¹å¤§çº²
        """
        print(f"\nğŸ“‹ å¼€é¢˜æŠ¥å‘Šå¤§çº² - {outline_data['research_direction']}")
        print("=" * 70)
        
        while True:
            # æ˜¾ç¤ºå¤§çº²
            outline = outline_data['outline']
            for section_num, section_data in outline.items():
                print(f"\n{section_num}. {section_data['title']}")
                for i, sub_item in enumerate(section_data['sub_items'], 1):
                    print(f"   {section_num}.{i} {sub_item}")
            
            print(f"\né€‰æ‹©é€‰é¡¹ï¼š")
            print("y: ç¡®è®¤å¤§çº²ï¼Œå¼€å§‹ç”ŸæˆæŠ¥å‘Š")
            print("m: ä¿®æ”¹æŸä¸ªéƒ¨åˆ†")
            print("r: é‡æ–°ç”Ÿæˆæ•´ä¸ªå¤§çº²")
            
            choice = input("\nè¯·è¾“å…¥æ‚¨çš„é€‰æ‹©: ").strip().lower()
            
            if choice == 'y':
                print("\nâœ… å¤§çº²ç¡®è®¤å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆå¼€é¢˜æŠ¥å‘Š...")
                return outline_data
            
            elif choice == 'm':
                # ä¿®æ”¹æŸä¸ªéƒ¨åˆ†
                section_num = input("è¯·è¾“å…¥è¦ä¿®æ”¹çš„éƒ¨åˆ†ç¼–å· (1-7): ").strip()
                if section_num in outline:
                    print(f"\nå½“å‰éƒ¨åˆ†ï¼š{outline[section_num]['title']}")
                    for i, sub_item in enumerate(outline[section_num]['sub_items'], 1):
                        print(f"   {section_num}.{i} {sub_item}")
                    
                    new_items = []
                    print("\nè¯·è¾“å…¥æ–°çš„å­é¡¹ç›®ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼‰ï¼š")
                    while True:
                        item = input().strip()
                        if not item:
                            break
                        new_items.append(item)
                    
                    if new_items:
                        outline[section_num]['sub_items'] = new_items
                        print(f"âœ… éƒ¨åˆ† {section_num} ä¿®æ”¹å®Œæˆ")
                    else:
                        print("âš ï¸ æœªè¾“å…¥ä»»ä½•å†…å®¹ï¼Œä¿æŒåŸçŠ¶")
                else:
                    print("âš ï¸ æ— æ•ˆçš„éƒ¨åˆ†ç¼–å·")
            
            elif choice == 'r':
                # é‡æ–°ç”Ÿæˆå¤§çº²
                print("\nğŸ”„ é‡æ–°ç”Ÿæˆå¤§çº²...")
                # è¿™é‡Œéœ€è¦ä¼ é€’selected_directionï¼Œéœ€è¦åœ¨è°ƒç”¨æ—¶ä¿å­˜
                print("âš ï¸ é‡æ–°ç”ŸæˆåŠŸèƒ½éœ€è¦åœ¨ä¸»æµç¨‹ä¸­å®ç°")
            
            else:
                print("âš ï¸ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def search_academic_content(self, direction, outline_data):
        """
        æ­¥éª¤5ï¼šæœç´¢å­¦æœ¯å†…å®¹å’Œè®ºæ–‡
        """
        print(f"\nğŸ” [å†…å®¹æœç´¢] æ­£åœ¨æœç´¢ç›¸å…³å­¦æœ¯å†…å®¹...")
        
        # æ„å»ºæœç´¢å…³é”®è¯
        search_keywords = direction['keywords']
        direction_name = direction['direction']
        
        all_content = {}
        all_papers = []
        
        # 1. æœç´¢å­¦æœ¯è®ºæ–‡
        print("ğŸ“š æœç´¢å­¦æœ¯è®ºæ–‡...")
        papers = self._search_academic_papers(direction_name, search_keywords)
        all_papers.extend(papers)
        
        # 2. ä¸ºæ¯ä¸ªå¤§çº²éƒ¨åˆ†æœç´¢å†…å®¹
        outline = outline_data['outline']
        for section_num, section_data in outline.items():
            if section_num == '7':  # è·³è¿‡å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
                continue
            
            print(f"ğŸ” æœç´¢ '{section_data['title']}' ç›¸å…³å†…å®¹...")
            section_content = self._search_section_content(
                section_data['title'],
                direction_name,
                search_keywords
            )
            all_content[section_num] = section_content
        
        return all_content, all_papers
    
    def _search_academic_papers(self, direction_name, keywords):
        """æœç´¢å­¦æœ¯è®ºæ–‡"""
        papers = []
        
        # 1. ä»ArXivæœç´¢
        if 'arxiv' in self.collectors:
            try:
                arxiv_papers = self.arxiv_collector.get_papers_by_topic(
                    direction_name, keywords, days=365
                )
                papers.extend(arxiv_papers)
                print(f"   ArXiv: {len(arxiv_papers)} ç¯‡è®ºæ–‡")
            except Exception as e:
                print(f"   ArXivæœç´¢å¤±è´¥: {str(e)}")
        
        # 2. ä»å…¶ä»–æœç´¢å¼•æ“æœç´¢å­¦æœ¯å†…å®¹
        for search_term in keywords[:5]:  # é™åˆ¶æœç´¢æ•°é‡
            query = f"{direction_name} {search_term} academic paper research"
            
            # Tavilyæœç´¢
            if 'tavily' in self.collectors:
                try:
                    results = self.tavily_collector.search(query, max_results=5)
                    for result in results:
                        if self._is_academic_source(result.get('url', '')):
                            papers.append({
                                'title': result.get('title', ''),
                                'content': result.get('content', ''),
                                'url': result.get('url', ''),
                                'source': 'tavily',
                                'published': datetime.now().strftime('%Y-%m-%d')
                            })
                except Exception as e:
                    print(f"   Tavilyæœç´¢å¤±è´¥: {str(e)}")
            
            # Googleæœç´¢
            if 'google' in self.collectors:
                try:
                    results = self.google_collector.search(query, max_results=5)
                    for result in results:
                        if self._is_academic_source(result.get('url', '')):
                            papers.append({
                                'title': result.get('title', ''),
                                'content': result.get('snippet', ''),
                                'url': result.get('url', ''),
                                'source': 'google',
                                'published': datetime.now().strftime('%Y-%m-%d')
                            })
                except Exception as e:
                    print(f"   Googleæœç´¢å¤±è´¥: {str(e)}")
        
        # å»é‡
        unique_papers = []
        seen_urls = set()
        for paper in papers:
            url = paper.get('url', '')
            if url and url not in seen_urls:
                unique_papers.append(paper)
                seen_urls.add(url)
        
        print(f"ğŸ“š å…±æ‰¾åˆ° {len(unique_papers)} ç¯‡ç›¸å…³è®ºæ–‡")
        return unique_papers
    
    def _is_academic_source(self, url):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå­¦æœ¯æ¥æº"""
        academic_domains = [
            'arxiv.org', 'ieee.org', 'acm.org', 'springer.com',
            'elsevier.com', 'nature.com', 'science.org', 'wiley.com',
            'researchgate.net', 'scholar.google.com', 'dblp.org'
        ]
        return any(domain in url.lower() for domain in academic_domains)
    
    def _search_section_content(self, section_title, direction_name, keywords):
        """æœç´¢ç‰¹å®šéƒ¨åˆ†çš„å†…å®¹"""
        content = []
        
        # æ„å»ºé’ˆå¯¹æ€§æœç´¢æŸ¥è¯¢
        queries = [
            f"{direction_name} {section_title}",
            f"{direction_name} research {section_title.lower()}",
            f"{keywords[0]} {section_title}" if keywords else f"{direction_name} {section_title}"
        ]
        
        for query in queries[:2]:  # é™åˆ¶æœç´¢æ•°é‡
            # ä½¿ç”¨å„ç§æœç´¢å¼•æ“
            for collector_name, collector in self.collectors.items():
                if collector_name == 'arxiv':
                    continue  # ArXivå·²ç»åœ¨è®ºæ–‡æœç´¢ä¸­å¤„ç†
                
                try:
                    if collector_name == 'tavily':
                        results = collector.search(query, max_results=3)
                    elif collector_name == 'google':
                        results = collector.search(query, max_results=3)
                    elif collector_name == 'brave':
                        results = collector.search(query, count=3)
                    else:
                        continue
                    
                    for result in results:
                        content.append({
                            'title': result.get('title', ''),
                            'content': result.get('content', result.get('snippet', '')),
                            'url': result.get('url', ''),
                            'source': collector_name
                        })
                except Exception as e:
                    print(f"      {collector_name}æœç´¢å¤±è´¥: {str(e)}")
        
        return content
    
    def generate_report_content(self, direction, outline_data, search_content, papers):
        """
        æ­¥éª¤6ï¼šç”Ÿæˆå¼€é¢˜æŠ¥å‘Šå†…å®¹
        """
        print(f"\nğŸ“ [æŠ¥å‘Šç”Ÿæˆ] æ­£åœ¨ç”Ÿæˆå¼€é¢˜æŠ¥å‘Šå†…å®¹...")
        
        # åˆå§‹åŒ–å¹¶è¡Œå¤„ç†å™¨
        parallel_processor = ParallelLLMProcessor(
            self.llm_processor,
            config={
                'section_generator': {'max_workers': 4},
                'content_analyzer': {'max_workers': 3}
            }
        )
        
        # ç”Ÿæˆå„ä¸ªéƒ¨åˆ†çš„å†…å®¹
        report_sections = {}
        outline = outline_data['outline']
        
        for section_num, section_data in outline.items():
            if section_num == '7':  # å‚è€ƒæ–‡çŒ®å•ç‹¬å¤„ç†
                continue
            
            print(f"ğŸ“ ç”Ÿæˆ '{section_data['title']}' éƒ¨åˆ†...")
            
            # è·å–è¯¥éƒ¨åˆ†çš„æœç´¢å†…å®¹
            section_content = search_content.get(section_num, [])
            
            # ç”Ÿæˆè¯¥éƒ¨åˆ†çš„å†…å®¹
            section_text = self._generate_section_content(
                section_data['title'],
                section_data['sub_items'],
                section_content,
                papers,
                direction
            )
            
            report_sections[section_num] = {
                'title': section_data['title'],
                'content': section_text
            }
        
        # ç»„åˆå®Œæ•´æŠ¥å‘Š
        full_report = self._assemble_full_report(
            direction['direction'],
            report_sections,
            papers
        )
        
        return full_report
    
    def _generate_section_content(self, section_title, sub_items, content_data, papers, direction):
        """ç”Ÿæˆå•ä¸ªéƒ¨åˆ†çš„å†…å®¹"""
        # å‡†å¤‡å†…å®¹ææ–™
        content_materials = []
        for item in content_data:
            content_materials.append(f"æ ‡é¢˜: {item['title']}\nå†…å®¹: {item['content']}")
        
        # å‡†å¤‡è®ºæ–‡ææ–™
        paper_materials = []
        for paper in papers[:10]:  # é™åˆ¶è®ºæ–‡æ•°é‡
            paper_materials.append(f"è®ºæ–‡: {paper['title']}\næ‘˜è¦: {paper['content']}")
        
        section_prompt = f"""
        ç ”ç©¶æ–¹å‘: {direction['direction']}
        éƒ¨åˆ†æ ‡é¢˜: {section_title}
        å­é¡¹ç›®: {', '.join(sub_items)}
        
        å‚è€ƒå†…å®¹:
        {chr(10).join(content_materials[:5])}
        
        ç›¸å…³è®ºæ–‡:
        {chr(10).join(paper_materials[:5])}
        
        è¯·åŸºäºä»¥ä¸Šææ–™ï¼Œä¸ºå¼€é¢˜æŠ¥å‘Šçš„"{section_title}"éƒ¨åˆ†æ’°å†™è¯¦ç»†å†…å®¹ã€‚
        
        è¦æ±‚ï¼š
        1. å†…å®¹è¦å­¦æœ¯è§„èŒƒï¼Œç¬¦åˆå¼€é¢˜æŠ¥å‘Šè¦æ±‚
        2. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘ä¸¥å¯†
        3. é€‚å½“å¼•ç”¨ç›¸å…³æ–‡çŒ®ï¼ˆä½¿ç”¨[1]ã€[2]ç­‰æ ¼å¼ï¼‰
        4. æ¯ä¸ªå­é¡¹ç›®éƒ½è¦æœ‰ç›¸åº”å†…å®¹
        5. å­—æ•°æ§åˆ¶åœ¨800-1500å­—
        6. ä½¿ç”¨å­¦æœ¯å†™ä½œé£æ ¼
        
        è¯·ç›´æ¥è¿”å›è¯¥éƒ¨åˆ†çš„å†…å®¹ï¼Œä¸è¦æ·»åŠ å…¶ä»–è¯´æ˜ã€‚
        """
        
        try:
            section_content = self.llm_processor.call_llm_api(
                section_prompt,
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯å†™ä½œåŠ©æ‰‹ï¼Œæ“…é•¿æ’°å†™è§„èŒƒçš„å¼€é¢˜æŠ¥å‘Šã€‚",
                max_tokens=3000
            )
            return section_content.strip()
        except Exception as e:
            print(f"ç”Ÿæˆ'{section_title}'éƒ¨åˆ†å¤±è´¥: {str(e)}")
            return f"## {section_title}\n\næœ¬éƒ¨åˆ†å†…å®¹ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¡¥å……ã€‚"
    
    def _assemble_full_report(self, direction_name, report_sections, papers):
        """ç»„è£…å®Œæ•´æŠ¥å‘Š"""
        report = f"""# {direction_name} å¼€é¢˜æŠ¥å‘Š

## æ‘˜è¦

æœ¬ç ”ç©¶æ—¨åœ¨æ·±å…¥æ¢è®¨{direction_name}é¢†åŸŸçš„ç›¸å…³é—®é¢˜ï¼Œé€šè¿‡ç³»ç»Ÿçš„ç†è®ºåˆ†æå’Œå®è¯ç ”ç©¶ï¼Œä¸ºè¯¥é¢†åŸŸçš„å‘å±•æä¾›æ–°çš„è§è§£å’Œè§£å†³æ–¹æ¡ˆã€‚

"""
        
        # æ·»åŠ å„ä¸ªéƒ¨åˆ†
        for section_num in sorted(report_sections.keys()):
            section_data = report_sections[section_num]
            report += f"## {section_num}. {section_data['title']}\n\n"
            report += section_data['content']
            report += "\n\n"
        
        # æ·»åŠ å‚è€ƒæ–‡çŒ®
        report += "## 7. å‚è€ƒæ–‡çŒ®\n\n"
        for i, paper in enumerate(papers[:30], 1):
            title = paper.get('title', 'æ— æ ‡é¢˜')
            url = paper.get('url', '')
            authors = paper.get('authors', ['æœªçŸ¥ä½œè€…'])
            published = paper.get('published', 'æœªçŸ¥æ—¶é—´')
            
            if isinstance(authors, list):
                authors_str = ', '.join(authors)
            else:
                authors_str = str(authors)
            
            report += f"[{i}] {authors_str}. {title}. {published}. Available: {url}\n\n"
        
        return report
    
    def save_report(self, report_content, direction_name):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs('reports', exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        date_str = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"proposal_report_{direction_name.replace(' ', '_')}_{date_str}.md"
        filepath = os.path.join('reports', filename)
        
        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… å¼€é¢˜æŠ¥å‘Šå·²ä¿å­˜è‡³: {filepath}")
        return filepath
    
    def run(self, topic):
        """è¿è¡Œå®Œæ•´çš„å¼€é¢˜æŠ¥å‘Šç”Ÿæˆæµç¨‹"""
        print(f"\nğŸš€ å¼€é¢˜æŠ¥å‘Šç”ŸæˆAgentå¯åŠ¨")
        print(f"ğŸ“ ç”¨æˆ·é¢˜ç›®: '{topic}'")
        print("=" * 70)
        
        try:
            # æ­¥éª¤1: ç”Ÿæˆç ”ç©¶æ–¹å‘
            directions_data = self.generate_research_directions(topic)
            
            # æ­¥éª¤2: ç¡®è®¤ç ”ç©¶æ–¹å‘
            selected_direction = self.confirm_research_direction(directions_data)
            
            # æ­¥éª¤3: ç”Ÿæˆå¤§çº²
            outline_data = self.generate_proposal_outline(selected_direction)
            
            # æ­¥éª¤4: ç¡®è®¤å¤§çº²
            confirmed_outline = self.confirm_outline(outline_data)
            
            # æ­¥éª¤5: æœç´¢å†…å®¹
            search_content, papers = self.search_academic_content(selected_direction, confirmed_outline)
            
            # æ­¥éª¤6: ç”ŸæˆæŠ¥å‘Š
            report_content = self.generate_report_content(
                selected_direction, confirmed_outline, search_content, papers
            )
            
            # æ­¥éª¤7: ä¿å­˜æŠ¥å‘Š
            filepath = self.save_report(report_content, selected_direction['direction'])
            
            print(f"\nâœ… å¼€é¢˜æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {filepath}")
            
            return filepath
            
        except Exception as e:
            print(f"âŒ å¼€é¢˜æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    load_dotenv()
    
    print("ğŸ“ å¼€é¢˜æŠ¥å‘Šç”ŸæˆAgent")
    print("=" * 50)
    
    # åˆ›å»ºAgentå®ä¾‹
    agent = ProposalReportAgent()
    
    # è·å–ç”¨æˆ·è¾“å…¥
    topic = input("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶é¢˜ç›®: ").strip()
    
    if not topic:
        print("âŒ é¢˜ç›®ä¸èƒ½ä¸ºç©º")
        return
    
    # è¿è¡Œå¼€é¢˜æŠ¥å‘Šç”Ÿæˆæµç¨‹
    result = agent.run(topic)
    
    if result:
        print(f"\nğŸ‰ å¼€é¢˜æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {result}")
    else:
        print(f"\nâŒ å¼€é¢˜æŠ¥å‘Šç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main() 