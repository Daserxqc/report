# Search MCP HTTP API è°ƒç”¨ç¤ºä¾‹

## ğŸŒ HTTP API æœåŠ¡éƒ¨ç½²

### 1. æœ¬åœ°éƒ¨ç½²

```bash
# å¯åŠ¨HTTP APIæœåŠ¡
cd search_mcp
python main.py

# æœåŠ¡å°†è¿è¡Œåœ¨ http://localhost:8080
```

### 2. äº‘æœåŠ¡å™¨éƒ¨ç½²

#### ä½¿ç”¨Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . .

# å®‰è£…ä¾èµ–
RUN pip install -e .

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨æœåŠ¡
CMD ["python", "main.py"]
```

```bash
# æ„å»ºå’Œè¿è¡Œ
docker build -t search-mcp .
docker run -p 8080:8080 -e TAVILY_API_KEY="your_key" search-mcp
```

#### ä½¿ç”¨äº‘å¹³å°éƒ¨ç½²

**Railway éƒ¨ç½²:**
```bash
# å®‰è£…Railway CLI
npm install -g @railway/cli

# éƒ¨ç½²
railway login
railway init
railway up
```

**Heroku éƒ¨ç½²:**
```bash
# åˆ›å»ºProcfile
echo "web: python main.py" > Procfile

# éƒ¨ç½²
heroku create your-search-mcp
heroku config:set TAVILY_API_KEY="your_key"
git push heroku main
```

## ğŸ“¡ HTTP API è°ƒç”¨æ–¹å¼

### 1. Python è°ƒç”¨ç¤ºä¾‹

```python
import requests
import json

class SearchMCPClient:
    def __init__(self, base_url="http://your-server:8080"):
        self.base_url = base_url
    
    def parallel_search(self, queries, sources=None, max_results=5):
        """å¹¶è¡Œæœç´¢"""
        payload = {
            "queries": queries,
            "sources": sources,
            "max_results_per_query": max_results,
            "days_back": 7,
            "max_workers": 6
        }
        
        response = requests.post(
            f"{self.base_url}/search/parallel",
            json=payload,
            timeout=60
        )
        
        return response.json()
    
    def search_by_category(self, queries, category="web", max_results=5):
        """æŒ‰ç±»åˆ«æœç´¢"""
        payload = {
            "queries": queries,
            "category": category,
            "max_results_per_query": max_results,
            "days_back": 7
        }
        
        response = requests.post(
            f"{self.base_url}/search/category",
            json=payload,
            timeout=60
        )
        
        return response.json()
    
    def quick_search(self, query, category="web", max_results=5):
        """å¿«é€Ÿæœç´¢"""
        params = {
            "q": query,
            "category": category,
            "max_results": max_results
        }
        
        response = requests.get(
            f"{self.base_url}/search/quick",
            params=params,
            timeout=30
        )
        
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
client = SearchMCPClient("http://your-server:8080")

# å¹¶è¡Œæœç´¢
results = client.parallel_search(
    queries=["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
    sources=["tavily", "brave"],
    max_results=10
)

# å­¦æœ¯æœç´¢
academic_results = client.search_by_category(
    queries=["machine learning"],
    category="academic",
    max_results=15
)

# å¿«é€Ÿæœç´¢
quick_results = client.quick_search("AIå‘å±•è¶‹åŠ¿")
```

### 2. JavaScript/Node.js è°ƒç”¨ç¤ºä¾‹

```javascript
class SearchMCPClient {
    constructor(baseUrl = "http://your-server:8080") {
        this.baseUrl = baseUrl;
    }
    
    async parallelSearch(queries, sources = null, maxResults = 5) {
        const payload = {
            queries: queries,
            sources: sources,
            max_results_per_query: maxResults,
            days_back: 7,
            max_workers: 6
        };
        
        const response = await fetch(`${this.baseUrl}/search/parallel`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(payload)
        });
        
        return await response.json();
    }
    
    async searchByCategory(queries, category = "web", maxResults = 5) {
        const payload = {
            queries: queries,
            category: category,
            max_results_per_query: maxResults,
            days_back: 7
        };
        
        const response = await fetch(`${this.baseUrl}/search/category`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(payload)
        });
        
        return await response.json();
    }
    
    async quickSearch(query, category = "web", maxResults = 5) {
        const params = new URLSearchParams({
            q: query,
            category: category,
            max_results: maxResults
        });
        
        const response = await fetch(`${this.baseUrl}/search/quick?${params}`);
        return await response.json();
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const client = new SearchMCPClient("http://your-server:8080");

// å¹¶è¡Œæœç´¢
const results = await client.parallelSearch(
    ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
    ["tavily", "brave"],
    10
);

// å­¦æœ¯æœç´¢
const academicResults = await client.searchByCategory(
    ["machine learning"],
    "academic",
    15
);
```

### 3. curl è°ƒç”¨ç¤ºä¾‹

```bash
# å¹¶è¡Œæœç´¢
curl -X POST "http://your-server:8080/search/parallel" \
  -H "Content-Type: application/json" \
  -d '{
    "queries": ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
    "sources": ["tavily", "brave"],
    "max_results_per_query": 10,
    "days_back": 7,
    "max_workers": 6
  }'

# æŒ‰ç±»åˆ«æœç´¢
curl -X POST "http://your-server:8080/search/category" \
  -H "Content-Type: application/json" \
  -d '{
    "queries": ["machine learning"],
    "category": "academic",
    "max_results_per_query": 15,
    "days_back": 7
  }'

# å¿«é€Ÿæœç´¢
curl "http://your-server:8080/search/quick?q=AIå‘å±•è¶‹åŠ¿&category=web&max_results=5"

# å¥åº·æ£€æŸ¥
curl "http://your-server:8080/health"

# è·å–å¯ç”¨æ•°æ®æº
curl "http://your-server:8080/sources"
```

## ğŸ”§ å®¢æˆ·ç«¯SDKç¤ºä¾‹

### Python SDKåŒ…è£…

```python
# search_mcp_sdk.py
import requests
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

@dataclass
class SearchResult:
    title: str
    content: str
    url: str
    source: str
    source_type: str
    publish_date: Optional[str] = None

class SearchMCPSDK:
    """Search MCP Python SDK"""
    
    def __init__(self, base_url: str, timeout: int = 60):
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
    
    def search(self, 
               queries: List[str], 
               category: str = "web",
               max_results: int = 5) -> List[SearchResult]:
        """ç®€åŒ–çš„æœç´¢æ¥å£"""
        
        response = requests.post(
            f"{self.base_url}/search/category",
            json={
                "queries": queries,
                "category": category,
                "max_results_per_query": max_results
            },
            timeout=self.timeout
        )
        
        if response.status_code != 200:
            raise Exception(f"Search failed: {response.text}")
        
        data = response.json()
        if not data["success"]:
            raise Exception(f"Search failed: {data['message']}")
        
        # è½¬æ¢ä¸ºSearchResultå¯¹è±¡
        results = []
        for item in data["data"]:
            results.append(SearchResult(
                title=item["title"],
                content=item["content"],
                url=item["url"],
                source=item["source"],
                source_type=item["source_type"],
                publish_date=item.get("publish_date")
            ))
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
sdk = SearchMCPSDK("http://your-server:8080")
results = sdk.search(["äººå·¥æ™ºèƒ½"], category="web", max_results=10)

for result in results:
    print(f"æ ‡é¢˜: {result.title}")
    print(f"æ¥æº: {result.source}")
    print(f"é“¾æ¥: {result.url}")
    print("---")
```

## ğŸš€ éƒ¨ç½²å»ºè®®

### 1. ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# production_config.py
import os
from search_mcp.config import SearchConfig

def get_production_config():
    return SearchConfig(
        # APIå¯†é’¥ä»ç¯å¢ƒå˜é‡è¯»å–
        tavily_api_key=os.getenv("TAVILY_API_KEY"),
        brave_search_api_key=os.getenv("BRAVE_SEARCH_API_KEY"),
        
        # ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
        max_workers=8,
        request_timeout=30.0,
        enable_cache=True,
        cache_ttl=1800,  # 30åˆ†é’Ÿ
        
        # æ—¥å¿—é…ç½®
        log_level="INFO",
        enable_file_logging=True,
        log_file_path="/var/log/search-mcp/app.log"
    )
```

### 2. è´Ÿè½½å‡è¡¡é…ç½®

```nginx
# nginx.conf
upstream search_mcp {
    server 127.0.0.1:8080;
    server 127.0.0.1:8081;
    server 127.0.0.1:8082;
}

server {
    listen 80;
    server_name your-domain.com;
    
    location / {
        proxy_pass http://search_mcp;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 60s;
        proxy_read_timeout 60s;
    }
}
``` 