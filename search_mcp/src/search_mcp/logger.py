"""
Search MCP æ—¥å¿—é…ç½®

é…ç½®å’Œç®¡ç†æœç´¢æœåŠ¡çš„æ—¥å¿—è®°å½•
"""

import logging
import logging.handlers
import sys
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime


def setup_logger(name: str, 
                 level: str = "INFO",
                 log_format: Optional[str] = None,
                 log_file: Optional[str] = None,
                 max_file_size: int = 10 * 1024 * 1024,  # 10MB
                 backup_count: int = 5,
                 enable_console: bool = True) -> logging.Logger:
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨
    
    Args:
        name: æ—¥å¿—è®°å½•å™¨åç§°
        level: æ—¥å¿—çº§åˆ«
        log_format: æ—¥å¿—æ ¼å¼
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        max_file_size: æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        backup_count: å¤‡ä»½æ–‡ä»¶æ•°é‡
        enable_console: æ˜¯å¦å¯ç”¨æ§åˆ¶å°è¾“å‡º
        
    Returns:
        é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level.upper(), logging.INFO))
    
    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    logger.handlers.clear()
    
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    if log_format is None:
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    formatter = logging.Formatter(log_format)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    if enable_console:
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        console_handler.setLevel(getattr(logging, level.upper(), logging.INFO))
        logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨
    if log_file:
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨RotatingFileHandlerå®ç°æ—¥å¿—è½®è½¬
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=max_file_size,
            backupCount=backup_count,
            encoding='utf-8'
        )
        file_handler.setFormatter(formatter)
        file_handler.setLevel(getattr(logging, level.upper(), logging.INFO))
        logger.addHandler(file_handler)
    
    return logger


def setup_mcp_logger(config_dict: Dict[str, Any]) -> logging.Logger:
    """
    æ ¹æ®é…ç½®å­—å…¸è®¾ç½®MCPæ—¥å¿—è®°å½•å™¨
    
    Args:
        config_dict: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ—¥å¿—ç›¸å…³é…ç½®
        
    Returns:
        é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    log_level = config_dict.get('log_level', 'INFO')
    log_format = config_dict.get('log_format', 
                                 "%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    log_file = config_dict.get('log_file_path')
    enable_file_logging = config_dict.get('enable_file_logging', False)
    
    # å¦‚æœæ²¡æœ‰å¯ç”¨æ–‡ä»¶æ—¥å¿—ï¼Œåˆ™ä¸è®¾ç½®æ—¥å¿—æ–‡ä»¶
    if not enable_file_logging:
        log_file = None
    
    return setup_logger(
        name="search_mcp",
        level=log_level,
        log_format=log_format,
        log_file=log_file
    )


class SearchLogger:
    """æœç´¢æ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self, config_dict: Dict[str, Any]):
        self.config = config_dict
        self.logger = setup_mcp_logger(config_dict)
        self.search_logs = []  # å­˜å‚¨æœç´¢æ—¥å¿—
    
    def log_search_start(self, queries: list, sources: list, params: dict):
        """è®°å½•æœç´¢å¼€å§‹"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'event': 'search_start',
            'queries': queries,
            'sources': sources,
            'params': params
        }
        self.search_logs.append(log_entry)
        
        self.logger.info(f"ğŸš€ å¼€å§‹æœç´¢: {len(queries)}ä¸ªæŸ¥è¯¢, {len(sources)}ä¸ªæ•°æ®æº")
        self.logger.debug(f"æœç´¢å‚æ•°: {params}")
    
    def log_search_complete(self, results_count: int, execution_time: float, 
                           sources_used: list, errors: list = None):
        """è®°å½•æœç´¢å®Œæˆ"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'event': 'search_complete',
            'results_count': results_count,
            'execution_time': execution_time,
            'sources_used': sources_used,
            'errors': errors or []
        }
        self.search_logs.append(log_entry)
        
        self.logger.info(f"âœ… æœç´¢å®Œæˆ: {results_count}æ¡ç»“æœ, è€—æ—¶{execution_time:.2f}ç§’")
        
        if errors:
            self.logger.warning(f"âš ï¸ æœç´¢è¿‡ç¨‹ä¸­å‡ºç°{len(errors)}ä¸ªé”™è¯¯")
            for error in errors:
                self.logger.error(f"é”™è¯¯è¯¦æƒ…: {error}")
    
    def log_source_result(self, source: str, query: str, result_count: int, 
                         success: bool, error: str = None):
        """è®°å½•å•ä¸ªæ•°æ®æºçš„æœç´¢ç»“æœ"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'event': 'source_result',
            'source': source,
            'query': query,
            'result_count': result_count,
            'success': success,
            'error': error
        }
        self.search_logs.append(log_entry)
        
        if success:
            self.logger.debug(f"âœ… {source}({query}): {result_count}æ¡ç»“æœ")
        else:
            self.logger.error(f"âŒ {source}({query}): æœç´¢å¤±è´¥ - {error}")
    
    def log_collector_status(self, collectors_info: list):
        """è®°å½•æ”¶é›†å™¨çŠ¶æ€"""
        self.logger.info("ğŸ“Š æ”¶é›†å™¨çŠ¶æ€:")
        for info in collectors_info:
            self.logger.info(f"  {info.name}: {info.status}")
    
    def log_api_request(self, source: str, endpoint: str, params: dict, 
                       response_time: float, success: bool, error: str = None):
        """è®°å½•APIè¯·æ±‚"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'event': 'api_request',
            'source': source,
            'endpoint': endpoint,
            'params': params,
            'response_time': response_time,
            'success': success,
            'error': error
        }
        self.search_logs.append(log_entry)
        
        if success:
            self.logger.debug(f"ğŸŒ APIè¯·æ±‚æˆåŠŸ: {source} - {response_time:.2f}s")
        else:
            self.logger.error(f"ğŸŒ APIè¯·æ±‚å¤±è´¥: {source} - {error}")
    
    def log_rate_limit(self, source: str, retry_after: int = None):
        """è®°å½•é€Ÿç‡é™åˆ¶"""
        self.logger.warning(f"â±ï¸ {source} è§¦å‘é€Ÿç‡é™åˆ¶")
        if retry_after:
            self.logger.info(f"å°†åœ¨{retry_after}ç§’åé‡è¯•")
    
    def log_cache_hit(self, cache_key: str):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.logger.debug(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­: {cache_key}")
    
    def log_cache_miss(self, cache_key: str):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.logger.debug(f"ğŸ’¾ ç¼“å­˜æœªå‘½ä¸­: {cache_key}")
    
    def get_search_logs(self, limit: int = 100) -> list:
        """è·å–æœç´¢æ—¥å¿—"""
        return self.search_logs[-limit:]
    
    def clear_search_logs(self):
        """æ¸…é™¤æœç´¢æ—¥å¿—"""
        self.search_logs.clear()
        self.logger.info("ğŸ§¹ æœç´¢æ—¥å¿—å·²æ¸…é™¤")
    
    def export_logs(self, file_path: str, format: str = 'json'):
        """å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶"""
        import json
        from pathlib import Path
        
        log_path = Path(file_path)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        if format.lower() == 'json':
            with open(log_path, 'w', encoding='utf-8') as f:
                json.dump(self.search_logs, f, indent=2, ensure_ascii=False)
        else:
            # ç®€å•çš„æ–‡æœ¬æ ¼å¼
            with open(log_path, 'w', encoding='utf-8') as f:
                for log_entry in self.search_logs:
                    f.write(f"{log_entry['timestamp']} - {log_entry['event']}\n")
                    f.write(f"  {log_entry}\n\n")
        
        self.logger.info(f"ğŸ“„ æ—¥å¿—å·²å¯¼å‡ºåˆ°: {file_path}")


def create_search_logger(config_dict: Dict[str, Any]) -> SearchLogger:
    """åˆ›å»ºæœç´¢æ—¥å¿—ç®¡ç†å™¨çš„ä¾¿æ·å‡½æ•°"""
    return SearchLogger(config_dict)


# é»˜è®¤æ—¥å¿—é…ç½®
DEFAULT_LOG_CONFIG = {
    'log_level': 'INFO',
    'log_format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    'enable_file_logging': False,
    'log_file_path': None
} 