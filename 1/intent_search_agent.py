"""
æ„å›¾ç†è§£ä¸å†…å®¹æ£€ç´¢Agent
åŠŸèƒ½ï¼š
1. ç†è§£ç”¨æˆ·æŸ¥è¯¢æ„å›¾ï¼Œç”Ÿæˆç›¸å…³ä¸»é¢˜æ‰©å±•
2. è°ƒç”¨å¤šæ¸ é“æœç´¢å·¥å…·è¿›è¡Œå†…å®¹æ£€ç´¢
3. è¿”å›é«˜åº¦ç²¾ç®€çš„JSONæ ¼å¼ç»“æœï¼ˆ50-60å­—ï¼‰
"""

import os
import json
import sys
from datetime import datetime
from dotenv import load_dotenv
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from collectors.tavily_collector import TavilyCollector
from collectors.google_search_collector import GoogleSearchCollector
from collectors.brave_search_collector import BraveSearchCollector

# å…³é—­HTTPè¯·æ±‚æ—¥å¿—
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

class IntentSearchAgent:
    """æ„å›¾ç†è§£ä¸å†…å®¹æ£€ç´¢Agent"""
    
    def __init__(self):
        # åˆå§‹åŒ–æœç´¢æ”¶é›†å™¨
        self.collectors = {}
        
        # åªåˆå§‹åŒ–Googleæœç´¢ï¼ˆä¸“æ³¨äºäº‹å®æ€§ã€å®é™…æ€§å†…å®¹ï¼‰
        try:
            self.google_collector = GoogleSearchCollector()
            if self.google_collector.has_api_key:
                self.collectors['google'] = self.google_collector
                print("âœ… Googleæœç´¢å¼•æ“å·²å¯ç”¨ï¼ˆä¸“æ³¨äº‹å®æ€§å†…å®¹ï¼‰")
            else:
                print("âŒ Googleæœç´¢å¼•æ“APIå¯†é’¥æœªé…ç½®")
                return
        except Exception as e:
            print(f"âŒ Googleæœç´¢å¼•æ“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return
        
        # åˆå§‹åŒ–LLMå¤„ç†å™¨ï¼ˆä½¿ç”¨Googleæœç´¢çš„LLMå¤„ç†å™¨ï¼‰
        try:
            # å°è¯•ä»Googleæœç´¢è·å–LLMå¤„ç†å™¨
            self.llm_processor = self.google_collector._get_llm_processor()
            print("âœ… LLMå¤„ç†å™¨å·²å¯ç”¨")
        except Exception as e:
            print(f"âŒ LLMå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            # å¦‚æœGoogleæœç´¢æ²¡æœ‰LLMå¤„ç†å™¨ï¼Œå°è¯•Tavilyçš„
            try:
                from collectors.tavily_collector import TavilyCollector
                tavily_collector = TavilyCollector()
                self.llm_processor = tavily_collector._get_llm_processor()
                print("âœ… LLMå¤„ç†å™¨å·²å¯ç”¨ï¼ˆä½¿ç”¨Tavilyå¤‡ç”¨ï¼‰")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨LLMå¤„ç†å™¨ä¹Ÿåˆå§‹åŒ–å¤±è´¥: {str(e2)}")
                return
        
        print(f"ğŸ” æœç´¢å¼•æ“é…ç½®å®Œæˆï¼Œä¸“æ³¨äºäº‹å®æ€§ã€å®é™…æ€§å†…å®¹")
    
    def understand_intent(self, user_query):
        """
        æ­¥éª¤1ï¼šæ„å›¾ç†è§£ä¸ä¸»é¢˜æ‰©å±•
        ä½¿ç”¨LLMç†è§£ç”¨æˆ·æ„å›¾ï¼Œç”Ÿæˆç›¸å…³ä¸»é¢˜å’Œå…³é”®è¯
        """
        print(f"ğŸ§  [æ„å›¾ç†è§£] æ­£åœ¨åˆ†æç”¨æˆ·æŸ¥è¯¢: '{user_query}'")
        
        intent_prompt = f"""
        ç”¨æˆ·æŸ¥è¯¢: "{user_query}"
        
        è¯·ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æœç´¢åŠ©æ‰‹ï¼Œæ·±åº¦ç†è§£ç”¨æˆ·çš„æœç´¢æ„å›¾ï¼Œæä¾›å¹³è¡¡çš„æ¦‚å¿µæ€§å’Œå®ç”¨æ€§å†…å®¹ã€‚
        
        åˆ†æç­–ç•¥ï¼š
        1. é¦–å…ˆåˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼š
           - æ¦‚å¿µæ€§æŸ¥è¯¢ï¼ˆå¦‚"AI Agent"ã€"åŒºå—é“¾"ç­‰ï¼‰ï¼šä¼˜å…ˆæä¾›åŸºç¡€æ¦‚å¿µã€å®šä¹‰ã€åŸç†
           - å®ç”¨æ€§æŸ¥è¯¢ï¼ˆå¦‚"å¦‚ä½•å¼€å‘AI Agent"ã€"AI Agentæ•™ç¨‹"ï¼‰ï¼šä¼˜å…ˆæä¾›å·¥å…·ã€æ–¹æ³•ã€æ¡ˆä¾‹
        
        2. å¯¹äºæ¦‚å¿µæ€§æŸ¥è¯¢ï¼Œæœç´¢é‡ç‚¹ï¼š
           - åŸºæœ¬å®šä¹‰å’Œæ ¸å¿ƒæ¦‚å¿µ
           - å·¥ä½œåŸç†å’ŒæŠ€æœ¯æ¶æ„
           - ä¸»è¦ç‰¹å¾å’Œåˆ†ç±»
           - ç„¶åæ˜¯å®é™…åº”ç”¨å’Œå·¥å…·
        
        3. å¯¹äºå®ç”¨æ€§æŸ¥è¯¢ï¼Œæœç´¢é‡ç‚¹ï¼š
           - å…·ä½“å·¥å…·å’Œæ¡†æ¶
           - å®ç°æ–¹æ³•å’Œæœ€ä½³å®è·µ
           - å®é™…æ¡ˆä¾‹å’Œåº”ç”¨åœºæ™¯
           - é¿å…è¿‡åº¦å•†ä¸šåŒ–å†…å®¹
        
        4. æœç´¢å…³é”®è¯è¦æ±‚ï¼š
           - åŒ…å«"æ¦‚å¿µ"ã€"å®šä¹‰"ã€"åŸç†"ç­‰åŸºç¡€æ€§å…³é”®è¯
           - é¿å…è¿‡å¤šç‰¹å®šå…¬å¸åç§°
           - å¹³è¡¡ç†è®ºå’Œå®è·µå†…å®¹
        
        è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
        {{
            "query_type": "æ¦‚å¿µæ€§" æˆ– "å®ç”¨æ€§",
            "core_intent": "ç”¨æˆ·æ ¸å¿ƒæ„å›¾çš„ç®€è¦æè¿°",
            "expanded_topics": [
                {{
                    "topic": "ä¸»é¢˜åç§°",
                    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
                    "search_focus": "æ¦‚å¿µæ€§" æˆ– "å®ç”¨æ€§"
                }}
            ],
            "search_queries": ["æœç´¢æŸ¥è¯¢1", "æœç´¢æŸ¥è¯¢2", "æœç´¢æŸ¥è¯¢3"]
        }}
        
        ç¤ºä¾‹1 - æ¦‚å¿µæ€§æŸ¥è¯¢ï¼š
        ç”¨æˆ·æŸ¥è¯¢: "AI Agent"
        è¿”å›ï¼š
        {{
            "query_type": "æ¦‚å¿µæ€§",
            "core_intent": "äº†è§£AI Agentçš„åŸºæœ¬æ¦‚å¿µã€å·¥ä½œåŸç†å’Œä¸»è¦ç‰¹å¾",
            "expanded_topics": [
                {{
                    "topic": "AI AgentåŸºæœ¬æ¦‚å¿µ",
                    "keywords": ["AI Agentå®šä¹‰", "æ™ºèƒ½ä»£ç†", "è‡ªä¸»ä»£ç†"],
                    "search_focus": "æ¦‚å¿µæ€§"
                }},
                {{
                    "topic": "AI Agentå·¥ä½œåŸç†",
                    "keywords": ["æ„ŸçŸ¥", "å†³ç­–", "æ‰§è¡Œ", "å­¦ä¹ æœºåˆ¶"],
                    "search_focus": "æ¦‚å¿µæ€§"
                }},
                {{
                    "topic": "AI Agentå¼€å‘æ¡†æ¶",
                    "keywords": ["LangChain", "AutoGPT", "æ¡†æ¶å¯¹æ¯”"],
                    "search_focus": "å®ç”¨æ€§"
                }}
            ],
            "search_queries": ["AI Agentæ¦‚å¿µå®šä¹‰", "AI Agentå·¥ä½œåŸç†", "AI Agentå¼€å‘æ¡†æ¶"]
        }}
        
        ç¤ºä¾‹2 - å®ç”¨æ€§æŸ¥è¯¢ï¼š
        ç”¨æˆ·æŸ¥è¯¢: "å¦‚ä½•å¼€å‘AI Agent"
        è¿”å›ï¼š
        {{
            "query_type": "å®ç”¨æ€§",
            "core_intent": "å­¦ä¹ AI Agentçš„å…·ä½“å¼€å‘æ–¹æ³•å’Œå®ç°æŠ€æœ¯",
            "expanded_topics": [
                {{
                    "topic": "AI Agentå¼€å‘æ•™ç¨‹",
                    "keywords": ["å¼€å‘æŒ‡å—", "ä»£ç å®ç°", "å®æˆ˜æ•™ç¨‹"],
                    "search_focus": "å®ç”¨æ€§"
                }}
            ],
            "search_queries": ["AI Agentå¼€å‘æ•™ç¨‹", "AI Agentä»£ç å®ç°"]
        }}
        """
        
        try:
            response = self.llm_processor.call_llm_api(
                intent_prompt,
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢æ„å›¾åˆ†æå¸ˆï¼Œæ“…é•¿ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶ç”Ÿæˆå‡†ç¡®çš„æœç´¢ç­–ç•¥ã€‚",
                max_tokens=2000
            )
            
            # è§£æJSONå“åº”
            intent_data = self._parse_intent_response(response)
            print(f"âœ… [æ„å›¾ç†è§£å®Œæˆ] æ ¸å¿ƒæ„å›¾: {intent_data['core_intent']}")
            print(f"ğŸ“Š æ‰©å±•ä¸»é¢˜: {len(intent_data['expanded_topics'])}ä¸ª")
            return intent_data
            
        except Exception as e:
            print(f"âŒ [æ„å›¾ç†è§£å¤±è´¥] {str(e)}")
            # è¿”å›åŸºç¡€çš„æ„å›¾åˆ†æ
            return self._get_fallback_intent(user_query)
    
    def _parse_intent_response(self, response):
        """è§£æLLMçš„æ„å›¾ç†è§£å“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)
            else:
                raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
        except Exception as e:
            print(f"âš ï¸ [JSONè§£æå¤±è´¥] {str(e)}")
            raise
    
    def _get_fallback_intent(self, user_query):
        """å¤‡ç”¨æ„å›¾åˆ†æï¼Œå½“LLMä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        return {
            "core_intent": f"æœç´¢å…³äº'{user_query}'çš„ç›¸å…³ä¿¡æ¯",
            "expanded_topics": [
                {
                    "topic": f"{user_query}åŸºç¡€ä¿¡æ¯",
                    "keywords": [user_query, "åŸºæœ¬æ¦‚å¿µ", "å®šä¹‰"]
                },
                {
                    "topic": f"{user_query}æœ€æ–°åŠ¨æ€",
                    "keywords": [user_query, "æœ€æ–°", "åŠ¨æ€", "æ–°é—»"]
                }
            ],
            "search_queries": [f"{user_query}æœ€æ–°ä¿¡æ¯", f"{user_query}å‘å±•è¶‹åŠ¿"]
        }
    
    def parallel_content_search(self, intent_data, max_results=5):
        """
        æ­¥éª¤2ï¼šGoogleæœç´¢å†…å®¹æ£€ç´¢
        åŸºäºæ„å›¾åˆ†æç»“æœï¼Œä½¿ç”¨Googleæœç´¢è¿›è¡Œæ£€ç´¢ï¼Œæ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´ç­–ç•¥
        """
        query_type = intent_data.get('query_type', 'æ¦‚å¿µæ€§')
        print(f"ğŸ” [Googleæ£€ç´¢] å¼€å§‹æ‰§è¡Œ{query_type}å†…å®¹æ£€ç´¢...")
        
        # æ„å»ºæœç´¢æŸ¥è¯¢åˆ—è¡¨
        search_queries = intent_data.get('search_queries', [])
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹å’Œä¸»é¢˜é‡ç‚¹è°ƒæ•´æœç´¢ç­–ç•¥
        for topic_data in intent_data.get('expanded_topics', []):
            topic = topic_data.get('topic', '')
            keywords = topic_data.get('keywords', [])
            search_focus = topic_data.get('search_focus', 'æ¦‚å¿µæ€§')
            
            if topic:
                if search_focus == 'æ¦‚å¿µæ€§':
                    # æ¦‚å¿µæ€§æœç´¢ï¼šä¼˜å…ˆåŸºç¡€æ¦‚å¿µã€å®šä¹‰ã€åŸç†
                    search_queries.append(f"{topic} æ¦‚å¿µ")
                    search_queries.append(f"{topic} å®šä¹‰")
                    if 'åŸç†' in topic or 'å·¥ä½œåŸç†' in topic:
                        search_queries.append(f"{topic} è¯¦è§£")
                else:
                    # å®ç”¨æ€§æœç´¢ï¼šä¼˜å…ˆæ•™ç¨‹ã€å®è·µã€æ¡ˆä¾‹
                    search_queries.append(f"{topic} æ•™ç¨‹")
                    search_queries.append(f"{topic} å®è·µ")
                
                # æ·»åŠ å…³é”®è¯æœç´¢ï¼ˆé™åˆ¶æ•°é‡ï¼‰
                if keywords:
                    search_queries.append(' '.join(keywords[:2]))
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹é™åˆ¶æœç´¢æ•°é‡
        if query_type == 'æ¦‚å¿µæ€§':
            search_queries = search_queries[:5]  # æ¦‚å¿µæ€§æŸ¥è¯¢ï¼Œè¾ƒå°‘ä½†æ›´ç²¾å‡†
        else:
            search_queries = search_queries[:7]  # å®ç”¨æ€§æŸ¥è¯¢ï¼Œæ›´å¤šå®é™…å†…å®¹
        
        # å»é‡æœç´¢æŸ¥è¯¢
        search_queries = list(dict.fromkeys(search_queries))  # ä¿æŒé¡ºåºçš„å»é‡
        
        all_results = []
        
        # ä½¿ç”¨Googleæœç´¢
        google_collector = self.collectors.get('google')
        if google_collector:
            for query in search_queries:
                try:
                    results = google_collector.search(query, max_results=max_results)
                    if results:
                        all_results.extend(results)
                        print(f"  âœ… [Google] '{query[:40]}...' -> {len(results)}æ¡ç»“æœ")
                    else:
                        print(f"  âš ï¸ [Google] '{query[:40]}...' -> æ— ç»“æœ")
                except Exception as e:
                    print(f"  âŒ [Google] '{query[:40]}...' -> æœç´¢å¤±è´¥: {str(e)}")
        else:
            print("âŒ Googleæœç´¢ä¸å¯ç”¨")
            return []
        
        # å»é‡å¤„ç†
        unique_results = self._deduplicate_results(all_results)
        print(f"ğŸ“Š [æ£€ç´¢å®Œæˆ] æ€»è®¡è·å¾— {len(unique_results)} æ¡{query_type}Googleæœç´¢ç»“æœ")
        
        return unique_results
    
    def _execute_single_search(self, collector, collector_name, query, max_results):
        """æ‰§è¡Œå•ä¸ªæœç´¢ä»»åŠ¡"""
        try:
            if collector_name == 'tavily':
                return collector.search(query, max_results=max_results)
            elif collector_name == 'google':
                return collector.search(query, max_results=max_results)
            elif collector_name == 'brave':
                return collector.search(query, count=max_results)
            else:
                return []
        except Exception as e:
            print(f"    âš ï¸ [{collector_name}] æœç´¢å‡ºé”™: {str(e)}")
            return []
    
    def _deduplicate_results(self, results):
        """ç»“æœå»é‡"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            url = result.get('url', '')
            title = result.get('title', '')
            
            # åŸºäºURLå»é‡
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
            # å¦‚æœæ²¡æœ‰URLï¼ŒåŸºäºæ ‡é¢˜å»é‡
            elif not url and title:
                existing_titles = [r.get('title', '') for r in unique_results]
                if title not in existing_titles:
                    unique_results.append(result)
        
        return unique_results
    
    def generate_concise_summary(self, intent_data, search_results, summary_length):
        """
        æ­¥éª¤3ï¼šç”Ÿæˆè¯¦ç»†æ‘˜è¦
        åŸºäºæœç´¢ç»“æœç”ŸæˆæŒ‡å®šé•¿åº¦çš„è¯¦ç»†æ‘˜è¦ï¼Œæ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´é£æ ¼
        """
        query_type = intent_data.get('query_type', 'æ¦‚å¿µæ€§')
        print(f"ğŸ“ [è¯¦ç»†æ‘˜è¦] æ­£åœ¨ç”Ÿæˆ{query_type}æ‘˜è¦ (é•¿åº¦: {summary_length})...")
        
        # æ ¹æ®é•¿åº¦èŒƒå›´è®¾ç½®å‚æ•°
        length_config = self._get_length_config(summary_length)
        
        # å‡†å¤‡æ‘˜è¦æ•°æ®
        summary_data = {
            "query_type": query_type,
            "core_intent": intent_data.get('core_intent', ''),
            "top_results": search_results[:length_config['result_count']],
            "expanded_topics": [t.get('topic', '') for t in intent_data.get('expanded_topics', [])]
        }
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´æ‘˜è¦æç¤º
        if query_type == 'æ¦‚å¿µæ€§':
            summary_style = f"""
            æ¦‚å¿µæ€§æ‘˜è¦è¦æ±‚ï¼š
            1. é¦–å…ˆæ˜ç¡®å®šä¹‰æ ¸å¿ƒæ¦‚å¿µ
            2. è§£é‡ŠåŸºæœ¬å·¥ä½œåŸç†æˆ–æœºåˆ¶
            3. åˆ—ä¸¾ä¸»è¦ç‰¹å¾å’Œåˆ†ç±»
            4. ç®€è¦æåŠå®é™…åº”ç”¨åœºæ™¯
            5. é¿å…è¿‡å¤šå•†ä¸šåŒ–å†…å®¹å’Œå…¬å¸åç§°
            6. é‡ç‚¹åœ¨äºå¸®åŠ©ç”¨æˆ·ç†è§£"è¿™æ˜¯ä»€ä¹ˆ"å’Œ"å¦‚ä½•å·¥ä½œ"
            """
        else:
            summary_style = f"""
            å®ç”¨æ€§æ‘˜è¦è¦æ±‚ï¼š
            1. é‡ç‚¹ä»‹ç»å…·ä½“å·¥å…·å’Œæ–¹æ³•
            2. æä¾›å®é™…æ“ä½œæ­¥éª¤æˆ–æŒ‡å—
            3. åˆ—ä¸¾æœ€ä½³å®è·µå’Œåº”ç”¨æ¡ˆä¾‹
            4. åŒ…å«æŠ€æœ¯ç»†èŠ‚å’Œå®ç°è·¯å¾„
            5. çªå‡ºå¯æ“ä½œæ€§å’Œå®ç”¨ä»·å€¼
            6. é‡ç‚¹åœ¨äºå¸®åŠ©ç”¨æˆ·ç†è§£"æ€ä¹ˆåš"å’Œ"å¦‚ä½•å®ç°"
            """
        
        summary_prompt = f"""
        åŸºäºä»¥ä¸‹æœç´¢ç»“æœï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„{query_type}æ‘˜è¦ï¼š
        
        æŸ¥è¯¢ç±»å‹: {query_type}
        ç”¨æˆ·æ„å›¾: {summary_data['core_intent']}
        ç›¸å…³ä¸»é¢˜: {', '.join(summary_data['expanded_topics'])}
        
        {summary_style}
        
        æœç´¢ç»“æœ:
        {self._format_search_results_for_summary(summary_data['top_results'])}
        
        è¯·ç”Ÿæˆä¸€ä¸ª{summary_length}çš„è¯¦ç»†æ‘˜è¦ï¼Œè¦æ±‚ï¼š
        1. å­—æ•°ä¸¥æ ¼æ§åˆ¶åœ¨{summary_length}èŒƒå›´å†…ï¼Œè¿™æ˜¯æœ€é‡è¦çš„è¦æ±‚
        2. å¦‚æœæ˜¯"50å­—ä»¥å†…"ï¼Œè¯·ç¡®ä¿ä¸è¶…è¿‡50å­—
        3. å¦‚æœæ˜¯"50-100å­—"ï¼Œè¯·ç¡®ä¿åœ¨50-100å­—ä¹‹é—´
        4. å¦‚æœæ˜¯"100-300å­—"ï¼Œè¯·ç¡®ä¿åœ¨100-300å­—ä¹‹é—´
        5. å¦‚æœæ˜¯"300å­—ä»¥ä¸Š"ï¼Œè¯·ç¡®ä¿è¶…è¿‡300å­—ä½†ä¸è¶…è¿‡500å­—
        6. æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´å†…å®¹é‡ç‚¹
        7. å¿…é¡»æ˜¯å®Œæ•´çš„å¥å­ï¼Œä¸èƒ½æœ‰çœç•¥å·æˆ–æˆªæ–­
        8. è¯­è¨€å‡†ç¡®ä¸“ä¸šï¼Œé€»è¾‘æ¸…æ™°
        9. é¿å…è¿‡åº¦å•†ä¸šåŒ–å†…å®¹å’Œå…¬å¸å †ç Œ
        
        æ ¼å¼è¦æ±‚ï¼š
        - ä½¿ç”¨å®Œæ•´çš„å¥å­ç»“æ„
        - ä¸ä½¿ç”¨çœç•¥å·(...)
        - å¥å­è¦å®Œæ•´ï¼Œä¸èƒ½ä¸­é€”æˆªæ–­
        - ä¿¡æ¯å‡†ç¡®ï¼Œé€»è¾‘æ¸…æ™°
        - ä¸¥æ ¼éµå¾ªå­—æ•°é™åˆ¶
        
        è¯·åªè¿”å›æ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚ç”Ÿæˆå‰è¯·å…ˆç¡®è®¤å­—æ•°åœ¨è¦æ±‚èŒƒå›´å†…ã€‚
        """
        
        try:
            summary_text = self.llm_processor.call_llm_api(
                summary_prompt,
                f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{query_type}ä¿¡æ¯æ‘˜è¦å¸ˆï¼Œæ“…é•¿æ ¹æ®ä¸åŒæŸ¥è¯¢ç±»å‹å’Œé•¿åº¦è¦æ±‚ç”Ÿæˆåˆé€‚çš„æ‘˜è¦ã€‚",
                max_tokens=length_config['max_tokens']
            )
            
            # æ¸…ç†æ‘˜è¦æ–‡æœ¬
            summary_text = summary_text.strip()
            
            # ç§»é™¤å¯èƒ½çš„çœç•¥å·
            summary_text = summary_text.replace('...', '').replace('â€¦', '')
            
            # ç¡®ä¿å¥å­å®Œæ•´æ€§
            if not summary_text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
                # å¦‚æœæœ€åä¸€ä¸ªå­—ç¬¦ä¸æ˜¯æ ‡ç‚¹ç¬¦å·ï¼Œæ·»åŠ å¥å·
                summary_text += 'ã€‚'
            
            # æ ¹æ®é•¿åº¦èŒƒå›´æ£€æŸ¥å’Œè°ƒæ•´
            summary_text = self._adjust_summary_length(summary_text, length_config)
            
            print(f"âœ… [æ‘˜è¦å®Œæˆ] é•¿åº¦: {len(summary_text)}å­—")
            return summary_text
            
        except Exception as e:
            print(f"âŒ [æ‘˜è¦ç”Ÿæˆå¤±è´¥] {str(e)}")
            return self._get_fallback_summary(intent_data, search_results, summary_length)
    
    def _get_length_config(self, summary_length):
        """æ ¹æ®é•¿åº¦èŒƒå›´è¿”å›é…ç½®å‚æ•°"""
        configs = {
            "50å­—ä»¥å†…": {"max_tokens": 150, "max_chars": 50, "min_chars": 20, "result_count": 3},
            "50-100å­—": {"max_tokens": 250, "max_chars": 100, "min_chars": 50, "result_count": 5},
            "100-300å­—": {"max_tokens": 750, "max_chars": 300, "min_chars": 100, "result_count": 8},
            "300å­—ä»¥ä¸Š": {"max_tokens": 1000, "max_chars": 500, "min_chars": 300, "result_count": 15}
        }
        return configs.get(summary_length, configs["50-100å­—"])
    
    def _adjust_summary_length(self, summary_text, length_config):
        """æ ¹æ®é•¿åº¦é…ç½®è°ƒæ•´æ‘˜è¦é•¿åº¦"""
        current_length = len(summary_text)
        max_chars = length_config['max_chars']
        min_chars = length_config['min_chars']
        
        # å¦‚æœè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œéœ€è¦æˆªæ–­
        if current_length > max_chars:
            # ä¼˜å…ˆåœ¨å¥å·å¤„æˆªæ–­
            sentences = []
            temp_text = summary_text
            
            # æŒ‰å¥å·åˆ†å‰²
            sentence_endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']
            current_pos = 0
            
            while current_pos < len(temp_text):
                # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¥å·
                next_end = len(temp_text)
                end_char = ''
                for ending in sentence_endings:
                    pos = temp_text.find(ending, current_pos)
                    if pos != -1 and pos < next_end:
                        next_end = pos
                        end_char = ending
                
                if next_end == len(temp_text):
                    # æ²¡æœ‰æ‰¾åˆ°å¥å·ï¼Œå–å‰©ä½™éƒ¨åˆ†
                    sentences.append(temp_text[current_pos:])
                    break
                else:
                    # æ‰¾åˆ°å¥å·ï¼ŒåŒ…å«å¥å·
                    sentences.append(temp_text[current_pos:next_end + 1])
                    current_pos = next_end + 1
            
            # é‡æ–°ç»„åˆå¥å­ï¼Œç¡®ä¿ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
            result = ''
            for sentence in sentences:
                if len(result + sentence) <= max_chars:
                    result += sentence
                else:
                    break
            
            # å¦‚æœç»“æœå¤ªçŸ­ï¼Œè‡³å°‘ä¿è¯æœ‰ä¸€ä¸ªå®Œæ•´å¥å­
            if len(result) < min_chars and sentences:
                result = sentences[0]
                # å¦‚æœç¬¬ä¸€ä¸ªå¥å­ä»ç„¶å¤ªé•¿ï¼Œå¼ºåˆ¶æˆªæ–­
                if len(result) > max_chars:
                    result = result[:max_chars-1] + 'ã€‚'
            
            summary_text = result
        
        # ç¡®ä¿æ‘˜è¦ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾
        if summary_text and not summary_text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
            summary_text += 'ã€‚'
        
        return summary_text
    
    def _format_search_results_for_summary(self, results):
        """æ ¼å¼åŒ–æœç´¢ç»“æœç”¨äºæ‘˜è¦ç”Ÿæˆï¼Œæä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯"""
        formatted = []
        for i, result in enumerate(results[:5], 1):  # ä½¿ç”¨å‰5ä¸ªç»“æœ
            title = result.get('title', 'æ— æ ‡é¢˜')
            snippet = result.get('snippet', result.get('content', ''))
            url = result.get('url', '')
            
            # æ¸…ç†snippet
            if snippet:
                snippet = snippet.replace('...', '').replace('â€¦', '').strip()
                # å¢åŠ snippeté•¿åº¦é™åˆ¶
                snippet = snippet[:200] + "" if len(snippet) > 200 else snippet
            
            # æ„å»ºæ ¼å¼åŒ–ç»“æœ
            formatted_result = f"{i}. æ ‡é¢˜: {title}"
            if snippet:
                formatted_result += f"\n   å†…å®¹: {snippet}"
            if url:
                formatted_result += f"\n   æ¥æº: {url}"
            
            formatted.append(formatted_result)
        
        return '\n\n'.join(formatted)
    
    def _get_fallback_summary(self, intent_data, search_results, summary_length):
        """å¤‡ç”¨æ‘˜è¦ç”Ÿæˆï¼Œç”Ÿæˆæ›´å®Œæ•´çš„æ‘˜è¦"""
        core_intent = intent_data.get('core_intent', '')
        topics = intent_data.get('expanded_topics', [])
        topic_names = [t.get('topic', '') for t in topics[:3]]
        
        # æ ¹æ®é•¿åº¦èŒƒå›´è·å–é…ç½®
        length_config = self._get_length_config(summary_length)
        
        if search_results:
            # ä½¿ç”¨æœç´¢ç»“æœç”Ÿæˆæ‘˜è¦
            first_result = search_results[0]
            title = first_result.get('title', '')
            snippet = first_result.get('snippet', first_result.get('content', ''))
            
            # æ„å»ºè¯¦ç»†æ‘˜è¦
            summary_parts = []
            
            if title:
                summary_parts.append(f"æ ¹æ®æœç´¢ç»“æœï¼Œ{title}")
            
            if snippet:
                # æå–snippetçš„å…³é”®ä¿¡æ¯
                snippet_clean = snippet.replace('...', '').replace('â€¦', '').strip()
                if len(snippet_clean) > 60:
                    snippet_clean = snippet_clean[:60]
                summary_parts.append(snippet_clean)
            
            if topic_names:
                summary_parts.append(f"ä¸»è¦æ¶‰åŠ{', '.join(topic_names)}ç­‰ç›¸å…³é¢†åŸŸ")
            
            if len(search_results) > 1:
                summary_parts.append(f"å…±æ‰¾åˆ°{len(search_results)}ä¸ªç›¸å…³èµ„æº")
            
            # æ ¹æ®é•¿åº¦èŒƒå›´è°ƒæ•´å†…å®¹è¯¦ç»†ç¨‹åº¦
            if length_config['max_chars'] >= 200:
                # é•¿æ‘˜è¦ï¼šæ·»åŠ æ›´å¤šç»†èŠ‚
                if len(search_results) > 2:
                    second_result = search_results[1]
                    second_title = second_result.get('title', '')
                    if second_title:
                        summary_parts.append(f"å¦å¤–ï¼Œ{second_title}")
            
            summary = 'ï¼Œ'.join(summary_parts)
            
            # ç¡®ä¿æ‘˜è¦å®Œæ•´
            if not summary.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
                summary += 'ã€‚'
        else:
            summary = f"å…³äº{core_intent}çš„ä¿¡æ¯æš‚æ—¶æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
            if topic_names:
                summary += f"å»ºè®®æœç´¢{', '.join(topic_names)}ç­‰ç›¸å…³ä¸»é¢˜ã€‚"
        
        # ä½¿ç”¨é•¿åº¦é…ç½®è°ƒæ•´æ‘˜è¦
        summary = self._adjust_summary_length(summary, length_config)
        
        return summary
    
    def search_and_summarize(self, user_query, summary_length="50-100å­—"):
        """
        ä¸»è¦æ¥å£ï¼šæ‰§è¡Œå®Œæ•´çš„æ„å›¾ç†è§£ä¸å†…å®¹æ£€ç´¢æµç¨‹
        è¿”å›JSONæ ¼å¼çš„ç»“æœ
        """
        print(f"\nğŸš€ å¯åŠ¨æ„å›¾ç†è§£ä¸å†…å®¹æ£€ç´¢Agent")
        print(f"ğŸ¯ ç”¨æˆ·æŸ¥è¯¢: '{user_query}'")
        print("=" * 50)
        
        # è®°å½•æœç´¢å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        
        try:
            # æ­¥éª¤1ï¼šæ„å›¾ç†è§£
            intent_data = self.understand_intent(user_query)
            
            # æ­¥éª¤2ï¼šGoogleæœç´¢å†…å®¹æ£€ç´¢
            search_results = self.parallel_content_search(intent_data, max_results=5)
            
            # æ­¥éª¤3ï¼šç”Ÿæˆè¯¦ç»†æ‘˜è¦
            summary_text = self.generate_concise_summary(intent_data, search_results, summary_length)
            
            # è®°å½•æœç´¢ç»“æŸæ—¶é—´
            end_time = datetime.now()
            search_duration = (end_time - start_time).total_seconds()
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "user_query": user_query,
                "core_intent": intent_data.get('core_intent', ''),
                "expanded_topics": [t.get('topic', '') for t in intent_data.get('expanded_topics', [])],
                "summary": summary_text,
                "result_count": len(search_results),
                "search_start_time": start_time.isoformat(),
                "search_end_time": end_time.isoformat(),
                "search_duration_seconds": round(search_duration, 2),
                "summary_length": summary_length
            }
            
            print("\n" + "=" * 50)
            print("ğŸ“Š æ£€ç´¢ç»“æœ:")
            print(f"ğŸ§  æ ¸å¿ƒæ„å›¾: {result['core_intent']}")
            print(f"ğŸ” æ‰©å±•ä¸»é¢˜: {', '.join(result['expanded_topics'])}")
            print(f"ğŸ“ è¯¦ç»†æ‘˜è¦: {result['summary']}")
            print(f"ğŸ“ˆ ç»“æœæ•°é‡: {result['result_count']}")
            print(f"â±ï¸ æœç´¢è€—æ—¶: {search_duration:.2f}ç§’")
            print("=" * 50)
            
            return result
            
        except Exception as e:
            end_time = datetime.now()
            search_duration = (end_time - start_time).total_seconds()
            
            print(f"âŒ [æµç¨‹æ‰§è¡Œå¤±è´¥] {str(e)}")
            return {
                "user_query": user_query,
                "core_intent": f"æœç´¢å…³äº'{user_query}'çš„ä¿¡æ¯",
                "expanded_topics": [],
                "summary": f"æœç´¢'{user_query}'æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "result_count": 0,
                "search_start_time": start_time.isoformat(),
                "search_end_time": end_time.isoformat(),
                "search_duration_seconds": round(search_duration, 2),
                "error": str(e),
                "summary_length": summary_length
            }

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•å’Œå‘½ä»¤è¡Œè°ƒç”¨"""
    load_dotenv()
    
    # åˆ›å»ºAgentå®ä¾‹
    agent = IntentSearchAgent()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        # ä»å‘½ä»¤è¡Œå‚æ•°è·å–æŸ¥è¯¢
        user_query = ' '.join(sys.argv[1:])
        print(f"ğŸ¯ æ‰§è¡Œæœç´¢æŸ¥è¯¢: '{user_query}'")
        
        # ä½¿ç”¨é»˜è®¤é•¿åº¦èŒƒå›´
        result = agent.search_and_summarize(user_query, summary_length="100-300å­—")
        
        # è¾“å‡ºJSONç»“æœ
        print(f"\nğŸ“„ JSONç»“æœ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    else:
        # äº¤äº’å¼æ¨¡å¼ - æ‰§è¡Œä¸€æ¬¡åé€€å‡º
        print("ğŸ§ª æ„å›¾ç†è§£ä¸å†…å®¹æ£€ç´¢Agent")
        print("=" * 50)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("1. ç›´æ¥è¾“å…¥æŸ¥è¯¢å†…å®¹")
        print("2. è¾“å…¥ 'test' è¿è¡Œæµ‹è¯•ç”¨ä¾‹")
        print("3. è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("=" * 50)
        
        try:
            user_input = input("\nğŸ” è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢ (æˆ– 'test'/'quit'): ").strip()
            
            if not user_input:
                print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢å†…å®¹")
                return
            
            if user_input.lower() in ['quit', 'exit']:
                print("ğŸ‘‹ å†è§ï¼")
                return
            
            if user_input.lower() == 'test':
                # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
                test_queries = [
                    "AI Agent",
                    "AI Agentå¼€å‘æ¡†æ¶",
                    "LangChainæ•™ç¨‹"
                ]
                
                print("ğŸ§ª å¼€å§‹è¿è¡Œå®ç”¨æ€§æœç´¢æµ‹è¯•ç”¨ä¾‹...")
                
                for query in test_queries:
                    print(f"\n{'='*60}")
                    print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
                    print('='*60)
                    
                    result = agent.search_and_summarize(query, summary_length="50-100å­—")
                    
                    # è¾“å‡ºJSONç»“æœ
                    print(f"\nğŸ“„ JSONç»“æœ:")
                    print(json.dumps(result, ensure_ascii=False, indent=2))
                    
                    print(f"\nâ¸ï¸ æš‚åœ3ç§’...")
                    import time
                    time.sleep(3)
                
                print("\nâœ… æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œå®Œæˆ")
                
            else:
                # è®©ç”¨æˆ·é€‰æ‹©æ‘˜è¦é•¿åº¦
                print("\nğŸ“ è¯·é€‰æ‹©æ‘˜è¦é•¿åº¦èŒƒå›´:")
                print("1. 50å­—ä»¥å†… (ç®€æ´æ¦‚è¿°)")
                print("2. 50-100å­— (æ ‡å‡†æ‘˜è¦)")
                print("3. 100-300å­— (è¯¦ç»†æ‘˜è¦) [é»˜è®¤]")
                print("4. 300å­—ä»¥ä¸Š (æ·±åº¦æ‘˜è¦)")
                
                length_choice = input("\nè¯·é€‰æ‹© (1-4, ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
                
                # æ˜ å°„ç”¨æˆ·é€‰æ‹©åˆ°é•¿åº¦èŒƒå›´
                length_options = {
                    '1': "50å­—ä»¥å†…",
                    '2': "50-100å­—",
                    '3': "100-300å­—",
                    '4': "300å­—ä»¥ä¸Š"
                }
                
                if length_choice in length_options:
                    summary_length = length_options[length_choice]
                elif length_choice == '':
                    summary_length = "100-300å­—"  # é»˜è®¤é•¿åº¦
                else:
                    print("âš ï¸ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤é•¿åº¦: 100-300å­—")
                    summary_length = "100-300å­—"
                
                print(f"âœ… å·²é€‰æ‹©æ‘˜è¦é•¿åº¦: {summary_length}")
                
                # æ‰§è¡Œç”¨æˆ·æŸ¥è¯¢
                print(f"\n{'='*60}")
                print(f"æ‰§è¡ŒæŸ¥è¯¢: {user_input}")
                print(f"æ‘˜è¦é•¿åº¦: {summary_length}")
                print('='*60)
                
                result = agent.search_and_summarize(user_input, summary_length=summary_length)
                
                # è¾“å‡ºJSONç»“æœ
                print(f"\nğŸ“„ JSONç»“æœ:")
                print(json.dumps(result, ensure_ascii=False, indent=2))
                
            # æ‰§è¡Œå®Œæˆåé€€å‡º
            print("\nâœ… æ£€ç´¢å®Œæˆï¼Œç¨‹åºé€€å‡º")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main() 