"""
è§‚ç‚¹å¯¹æ¯”åˆ†æå™¨ - å¹¶è¡Œå¤„ç†ç‰ˆæœ¬
ä¸“é—¨è´Ÿè´£ä¸åŒè§‚ç‚¹çš„å¯¹æ¯”åˆ†æï¼Œæ”¯æŒå¹¶è¡Œå¤„ç†
"""

import time
from typing import List, Dict, Any, Optional
import threading

class PerspectiveAnalyzer:
    """è§‚ç‚¹å¯¹æ¯”åˆ†æå™¨ - å¹¶è¡Œç‰ˆæœ¬"""
    
    def __init__(self, llm_processor, max_workers: int = 2):
        """
        åˆå§‹åŒ–è§‚ç‚¹å¯¹æ¯”åˆ†æå™¨
        
        Args:
            llm_processor: LLMå¤„ç†å™¨å®ä¾‹
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
        """
        self.llm_processor = llm_processor
        self.max_workers = max_workers
        self.analysis_lock = threading.Lock()
        
    def analyze_perspective_parallel(self, topic: str, perspective_data: List[Dict]) -> str:
        """
        å¹¶è¡Œåˆ†æè§‚ç‚¹å¯¹æ¯”
        
        Args:
            topic: è¡Œä¸šä¸»é¢˜
            perspective_data: è§‚ç‚¹å¯¹æ¯”æ•°æ®åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„è§‚ç‚¹å¯¹æ¯”åˆ†ææŠ¥å‘Š
        """
        if not perspective_data:
            return ""  # æ²¡æœ‰è§‚ç‚¹æ•°æ®æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
        
        start_time = time.time()
        print(f"ğŸ” [è§‚ç‚¹å¯¹æ¯”åˆ†æ] å¼€å§‹å¹¶è¡Œåˆ†æ{len(perspective_data)}æ¡ä¸åŒè§‚ç‚¹ä¿¡æ¯...")
        
        try:
            # æ„å»ºè§‚ç‚¹åˆ†ææç¤º
            all_perspectives_text = "\n\n".join([
                f"æ ‡é¢˜: {item.get('title', 'æ— æ ‡é¢˜')}\nå†…å®¹: {item.get('content', 'æ— å†…å®¹')[:500]}...\næ¥æº: {item.get('source', 'æœªçŸ¥')}"
                for item in perspective_data
            ])
            
            enhanced_prompt = f"""
            ä½œä¸º{topic}è¡Œä¸šçš„å®¢è§‚åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹ä¸åŒè§‚ç‚¹å’Œäº‰è®®æ€§ä¿¡æ¯è¿›è¡Œå¹³è¡¡åˆ†æï¼š
            
            {all_perspectives_text}
            
            ğŸ¯ **è§‚ç‚¹å¯¹æ¯”åˆ†ææ¡†æ¶**:
            1. **æ­£é¢è§‚ç‚¹æ€»ç»“**: æ”¯æŒæ€§ã€ä¹è§‚æ€§çš„è§‚ç‚¹æœ‰å“ªäº›ï¼Ÿ
            2. **è´¨ç–‘å£°éŸ³æ±‡æ€»**: æ‰¹è¯„ã€è´¨ç–‘ã€æ‹…å¿§çš„è§‚ç‚¹æœ‰å“ªäº›ï¼Ÿ
            3. **äº‰è®®ç„¦ç‚¹è¯†åˆ«**: ä¸»è¦çš„åˆ†æ­§ç‚¹åœ¨å“ªé‡Œï¼Ÿ
            4. **ä¸åŒç«‹åœºåˆ†æ**: 
               - ä¼ä¸švsç›‘ç®¡æ–¹
               - æŠ•èµ„è€…vsæ¶ˆè´¹è€…
               - å›½å†…vså›½é™…è§†è§’
               - å­¦æœ¯ç•Œvsäº§ä¸šç•Œ
            5. **å®¢è§‚è¯„ä¼°**: åŸºäºç°æœ‰è¯æ®ï¼Œå“ªäº›è§‚ç‚¹æ›´æœ‰è¯´æœåŠ›ï¼Ÿ
            6. **å¹³è¡¡å»ºè®®**: å¦‚ä½•åœ¨ä¸åŒè§‚ç‚¹é—´æ‰¾åˆ°å¹³è¡¡ï¼Ÿ
            
            ğŸ¤” **åˆ†æå¸ˆæ€è€ƒè¿‡ç¨‹**:
            - é¿å…åå‘ä»»ä½•ä¸€æ–¹ï¼Œä¿æŒä¸­ç«‹å®¢è§‚
            - åˆ†ææ¯ç§è§‚ç‚¹èƒŒåçš„åˆ©ç›Šè€ƒé‡å’Œé€»è¾‘åŸºç¡€
            - è¯†åˆ«å¯èƒ½çš„ä¿¡æ¯åå·®å’Œå±€é™æ€§
            - æä¾›å»ºè®¾æ€§çš„ç»¼åˆåˆ¤æ–­
            
            è¯·æä¾›å®¢è§‚ã€å¹³è¡¡çš„è§‚ç‚¹å¯¹æ¯”åˆ†æï¼Œå­—æ•°æ§åˆ¶åœ¨1500-2000å­—ã€‚
            
            ğŸ“ **å¯¹æ¯”åˆ†æè¦æ±‚**:
            - æ¯ä¸ªé‡è¦è§‚ç‚¹éƒ½è¦å®¢è§‚å‘ˆç°ï¼Œä¸åä¸å€š
            - åˆ†æè§‚ç‚¹èƒŒåçš„æ·±å±‚åŸå› å’ŒåŠ¨æœº
            - è¯†åˆ«ä¸åŒè§‚ç‚¹çš„åˆç†æ€§å’Œå±€é™æ€§
            - æä¾›åŸºäºäº‹å®çš„å¹³è¡¡åˆ¤æ–­
            - é¿å…ç»å¯¹åŒ–è¡¨è¿°ï¼Œæ‰¿è®¤å¤æ‚æ€§å’Œä¸ç¡®å®šæ€§
            - ä¸ºè¯»è€…æä¾›å¤šå…ƒåŒ–æ€è€ƒè§’åº¦
            """
            
            system_msg = f"""ä½ æ˜¯{topic}è¡Œä¸šçš„èµ„æ·±å®¢è§‚åˆ†æå¸ˆï¼Œå…·å¤‡ï¼š
            1. ä¸­ç«‹å®¢è§‚çš„åˆ†ææ€åº¦
            2. å¤šç»´åº¦çš„æ€è€ƒèƒ½åŠ›  
            3. å¹³è¡¡ä¸åŒè§‚ç‚¹çš„æŠ€å·§
            4. æ·±åº¦çš„è¡Œä¸šæ´å¯ŸåŠ›
            è¯·å±•ç°å‡ºä¸“ä¸šçš„å®¢è§‚åˆ†æèƒ½åŠ›ã€‚"""
            
            if not self.llm_processor:
                return f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\næš‚æ— {topic}è¡Œä¸šçš„ä¸åŒè§‚ç‚¹å¯¹æ¯”åˆ†æã€‚\n\n"
            
            analysis = self.llm_processor.call_llm_api(enhanced_prompt, system_msg, max_tokens=8000)
            
            # æ·»åŠ åˆ†ææ¥æº
            sources = []
            for item in perspective_data:
                if item.get('url', '#') != '#':
                    sources.append(f"- [{item.get('title', 'æœªçŸ¥æ ‡é¢˜')}]({item.get('url')}) - {item.get('source', 'æœªçŸ¥æ¥æº')}")
            
            if sources:
                analysis += "\n\n**è§‚ç‚¹æ¥æº:**\n" + "\n".join(sources)
            
            elapsed_time = time.time() - start_time
            print(f"âœ… [è§‚ç‚¹å¯¹æ¯”åˆ†æ] å¹¶è¡Œåˆ†æå®Œæˆï¼Œè€—æ—¶ {elapsed_time:.1f}ç§’")
            
            return f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\n{analysis}\n\n"
            
        except Exception as e:
            print(f"âŒ [é”™è¯¯] å¹¶è¡Œè§‚ç‚¹å¯¹æ¯”åˆ†ææ—¶å‡ºé”™: {str(e)}")
            return f"## âš–ï¸ å¤šå…ƒè§‚ç‚¹å¯¹æ¯”åˆ†æ\n\næš‚æ— {topic}è¡Œä¸šçš„ä¸åŒè§‚ç‚¹å¯¹æ¯”åˆ†æã€‚\n\n"
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "analyzer_type": "PerspectiveAnalyzer",
            "max_workers": self.max_workers,
            "parallel_tasks": ["perspective_analysis"],
            "estimated_speedup": "1x (single LLM call optimized)"
        } 