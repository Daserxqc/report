"""
é‡å¤§æ–°é—»åˆ†æå™¨ - å¹¶è¡Œå¤„ç†ç‰ˆæœ¬
ä¸“é—¨è´Ÿè´£é‡å¤§æ–°é—»çš„æ·±åº¦åˆ†æï¼Œæ”¯æŒå¹¶è¡Œå¤„ç†
"""

import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class BreakingNewsAnalyzer:
    """é‡å¤§æ–°é—»åˆ†æå™¨ - å¹¶è¡Œç‰ˆæœ¬"""
    
    def __init__(self, llm_processor, max_workers: int = 2):
        """
        åˆå§‹åŒ–é‡å¤§æ–°é—»åˆ†æå™¨
        
        Args:
            llm_processor: LLMå¤„ç†å™¨å®ä¾‹
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
        """
        self.llm_processor = llm_processor
        self.max_workers = max_workers
        self.analysis_lock = threading.Lock()
        
    def analyze_breaking_news_parallel(self, topic: str, breaking_news: List[Dict], days: int = 7) -> str:
        """
        å¹¶è¡Œåˆ†æé‡å¤§æ–°é—»
        
        Args:
            topic: è¡Œä¸šä¸»é¢˜
            breaking_news: é‡å¤§æ–°é—»åˆ—è¡¨
            days: æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„é‡å¤§æ–°é—»åˆ†ææŠ¥å‘Š
        """
        if not breaking_news:
            return f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ\n\nğŸ“Š **åˆ†æè¯´æ˜**: åœ¨å½“å‰æ—¶é—´çª—å£å†…ï¼Œæš‚æœªå‘ç°{topic}è¡Œä¸šçš„é‡å¤§çªå‘äº‹ä»¶ã€‚\n\n"
        
        start_time = time.time()
        print(f"ğŸ” [é‡å¤§æ–°é—»åˆ†æ] å¼€å§‹å¹¶è¡Œåˆ†æ{len(breaking_news)}æ¡é‡å¤§äº‹ä»¶...")
        
        try:
            # æ­¥éª¤1ï¼šå¹¶è¡Œç”Ÿæˆäº‹ä»¶æ‘˜è¦å’Œæ·±åº¦åˆ†æ
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # ä»»åŠ¡1ï¼šç”Ÿæˆé‡å¤§äº‹ä»¶æ‘˜è¦
                summary_future = executor.submit(
                    self._generate_major_events_summary,
                    topic, breaking_news, days
                )
                
                # ä»»åŠ¡2ï¼šç”Ÿæˆæ·±åº¦åˆ†æ
                analysis_future = executor.submit(
                    self._generate_depth_analysis,
                    topic, breaking_news, days
                )
                
                # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
                summary_section = summary_future.result()
                analysis_section = analysis_future.result()
            
            # æ­¥éª¤2ï¼šæ•´åˆç»“æœ
            sources = self._extract_sources(breaking_news)
            
            final_content = f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ\n\n{summary_section}\n\n### ğŸ“Š ç»¼åˆåˆ†æä¸å½±å“è¯„ä¼°\n\n{analysis_section}"
            
            if sources:
                final_content += f"\n\n**ä¿¡æ¯æ¥æº:**\n{sources}"
            
            final_content += "\n\n"
            
            elapsed_time = time.time() - start_time
            print(f"âœ… [é‡å¤§æ–°é—»åˆ†æ] å¹¶è¡Œåˆ†æå®Œæˆï¼Œè€—æ—¶ {elapsed_time:.1f}ç§’")
            
            return final_content
            
        except Exception as e:
            print(f"âŒ [é”™è¯¯] å¹¶è¡Œé‡å¤§æ–°é—»åˆ†ææ—¶å‡ºé”™: {str(e)}")
            return f"## ğŸš¨ è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†æ\n\nâŒ åˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\n"
    
    def _generate_major_events_summary(self, topic: str, breaking_news: List[Dict], days: int) -> str:
        """ç”Ÿæˆé‡å¤§äº‹ä»¶æ‘˜è¦ï¼ˆç¬¬ä¸€ä¸ªå¹¶è¡Œä»»åŠ¡ï¼‰"""
        print(f"  ğŸ“‹ [ä»»åŠ¡1] æ­£åœ¨ç­›é€‰å’Œæ€»ç»“æœ€é‡è¦çš„{min(7, len(breaking_news))}ä¸ªé‡å¤§äº‹ä»¶...")
        
        # ä¸¥æ ¼çš„æ—¶é—´è¿‡æ»¤
        time_filtered_news = self._filter_by_time(breaking_news, days)
        
        if not time_filtered_news:
            return f"### ä¸€ã€é‡å¤§æ–°é—»æ‘˜è¦ä¸å…³é”®ç»†èŠ‚\n\nâš ï¸ **æ—¶é—´è¿‡æ»¤ç»“æœ**: åœ¨æœ€è¿‘{days}å¤©å†…æš‚æ— ç¬¦åˆè¦æ±‚çš„é‡å¤§äº‹ä»¶ï¼Œå¯èƒ½éœ€è¦æ”¾å®½æ—¶é—´èŒƒå›´æˆ–æ£€æŸ¥æ•°æ®æºã€‚"
        
        # é€‰æ‹©æœ€é‡è¦çš„5-7ä¸ªäº‹ä»¶
        selected_news = time_filtered_news[:min(7, len(time_filtered_news))]
        
        all_news_text = "\n\n".join([
            f"äº‹ä»¶{i+1}:\næ ‡é¢˜: {item.get('title', 'æ— æ ‡é¢˜')}\næ—¶é—´: {item.get('date', 'æœ€è¿‘')}\nå†…å®¹: {item.get('content', 'æ— å†…å®¹')[:400]}...\næ¥æº: {item.get('source', 'æœªçŸ¥æ¥æº')}\nç½‘å€: {item.get('url', '#')}"
            for i, item in enumerate(selected_news)
        ])
        
        summary_prompt = f"""
        ä½œä¸º{topic}è¡Œä¸šçš„èµ„æ·±åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹æœ€æ–°é‡å¤§äº‹ä»¶è¿›è¡Œæ™ºèƒ½ç­›é€‰ã€å»é‡å’Œæ•´ç†ã€‚

        æœ€æ–°äº‹ä»¶ä¿¡æ¯ï¼š
        {all_news_text}

        ğŸ” **æ™ºèƒ½ç­›é€‰ä»»åŠ¡**ï¼š
        1. **å»é‡è¯†åˆ«**ï¼šä»”ç»†åˆ†ææ‰€æœ‰äº‹ä»¶ï¼Œè¯†åˆ«å†…å®¹ç›¸ä¼¼æˆ–é‡å¤çš„äº‹ä»¶ï¼ˆå¦‚åŒä¸€äº‹ä»¶çš„ä¸åŒæŠ¥é“ï¼‰
        2. **é‡è¦æ€§è¯„ä¼°**ï¼šè¯„ä¼°æ¯ä¸ªäº‹ä»¶å¯¹{topic}è¡Œä¸šçš„å½±å“ç¨‹åº¦å’Œé‡è¦æ€§
        3. **æ—¶æ•ˆæ€§åˆ¤æ–­**ï¼šä¼˜å…ˆé€‰æ‹©æœ€æ–°ã€æœ€å…·æ—¶æ•ˆæ€§çš„äº‹ä»¶
        4. **å¤šæ ·æ€§ä¿è¯**ï¼šç¡®ä¿é€‰å‡ºçš„äº‹ä»¶æ¶µç›–ä¸åŒæ–¹é¢ï¼ˆæŠ€æœ¯ã€æ”¿ç­–ã€å¸‚åœºã€æŠ•èµ„ç­‰ï¼‰

        ğŸ“‹ **è¾“å‡ºè¦æ±‚** - è¯·ä»æ‰€æœ‰äº‹ä»¶ä¸­ç­›é€‰å‡ºæœ€é‡è¦çš„3-5ä¸ªä¸é‡å¤äº‹ä»¶ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

        1. [äº‹ä»¶æ ‡é¢˜] (æ¥æºç½‘ç«™åŸŸå)
           â—‹ äº‹ä»¶ï¼š[ç”¨1-2å¥è¯ç®€æ´æè¿°äº‹ä»¶æ ¸å¿ƒå†…å®¹]
           â—‹ å…³é”®ç‚¹ï¼š[åˆ—å‡º2-3ä¸ªæœ€é‡è¦çš„å…³é”®ä¿¡æ¯ç‚¹]

        2. [äº‹ä»¶æ ‡é¢˜] (æ¥æºç½‘ç«™åŸŸå)
           â—‹ äº‹ä»¶ï¼š[ç”¨1-2å¥è¯ç®€æ´æè¿°äº‹ä»¶æ ¸å¿ƒå†…å®¹]  
           â—‹ å…³é”®ç‚¹ï¼š[åˆ—å‡º2-3ä¸ªæœ€é‡è¦çš„å…³é”®ä¿¡æ¯ç‚¹]

        [ç»§ç»­ç›¸åŒæ ¼å¼...]

        ğŸ¯ **ç­›é€‰æ ‡å‡†**ï¼š
        - **å»é‡ä¼˜å…ˆ**ï¼šå¦‚æœå¤šä¸ªäº‹ä»¶è®²è¿°åŒä¸€ä»¶äº‹ï¼Œåªé€‰æ‹©ä¿¡æ¯æœ€å…¨é¢ã€æ¥æºæœ€æƒå¨çš„ä¸€ä¸ª
        - **å½±å“åŠ›ä¼˜å…ˆ**ï¼šä¼˜å…ˆé€‰æ‹©å¯¹{topic}è¡Œä¸šå½±å“æœ€å¤§çš„äº‹ä»¶
        - **æ—¶æ•ˆæ€§ä¼˜å…ˆ**ï¼šä¼˜å…ˆé€‰æ‹©æœ€æ–°å‘ç”Ÿçš„äº‹ä»¶
        - **å¤šæ ·æ€§ä¿è¯**ï¼šé¿å…æ‰€æœ‰äº‹ä»¶éƒ½é›†ä¸­åœ¨åŒä¸€ä¸ªå­é¢†åŸŸ
        - **ä¿¡æ¯å®Œæ•´æ€§**ï¼šä¼˜å…ˆé€‰æ‹©ä¿¡æ¯è¯¦ç»†ã€å…·ä½“çš„äº‹ä»¶

        âš ï¸ **é‡è¦æé†’**ï¼š
        - å¦‚æœå‘ç°å¤šä¸ªäº‹ä»¶æ˜¯å…³äºåŒä¸€ä»¶äº‹çš„ä¸åŒæŠ¥é“ï¼Œè¯·åˆå¹¶ä¿¡æ¯å¹¶åªè¾“å‡ºä¸€ä¸ªäº‹ä»¶
        - ä¸¥æ ¼æŒ‰ç…§é‡è¦æ€§æ’åºï¼Œæœ€é‡è¦çš„äº‹ä»¶æ’åœ¨å‰é¢
        - æ¯ä¸ªäº‹ä»¶çš„æè¿°æ§åˆ¶åœ¨100-150å­—ä»¥å†…
        - æ¥æºç½‘ç«™åªå†™åŸŸåï¼Œä¸è¦å®Œæ•´URL
        - ä¸è¦æ·»åŠ é¢å¤–çš„æ ‡é¢˜æˆ–è¯´æ˜æ–‡å­—
        """
        
        system_msg = f"""ä½ æ˜¯{topic}è¡Œä¸šçš„ä¸“ä¸šä¿¡æ¯æ•´ç†ä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚ä¿¡æ¯æç‚¼æˆç®€æ´å®ç”¨çš„æ‘˜è¦æ ¼å¼ã€‚è¯·ç¡®ä¿è¾“å‡ºæ ¼å¼å‡†ç¡®ï¼Œå†…å®¹ç®€æ´æœ‰ç”¨ã€‚"""
        
        try:
            if not self.llm_processor:
                return self._generate_fallback_summary_simple(topic, selected_news)
            
            summary_analysis = self.llm_processor.call_llm_api(summary_prompt, system_msg, max_tokens=6000)
            return f"### ä¸€ã€é‡å¤§æ–°é—»æ‘˜è¦ä¸å…³é”®ç»†èŠ‚\n\n{summary_analysis}"
            
        except Exception as e:
            print(f"    âŒ [ä»»åŠ¡1] ç”Ÿæˆé‡å¤§äº‹ä»¶æ‘˜è¦æ—¶å‡ºé”™: {str(e)}")
            return self._generate_fallback_summary_simple(topic, selected_news)
    
    def _generate_depth_analysis(self, topic: str, breaking_news: List[Dict], days: int) -> str:
        """ç”Ÿæˆæ·±åº¦åˆ†æï¼ˆç¬¬äºŒä¸ªå¹¶è¡Œä»»åŠ¡ï¼‰"""
        print(f"  ğŸ”¬ [ä»»åŠ¡2] æ­£åœ¨è¿›è¡Œæ·±åº¦å½±å“åˆ†æ...")
        
        all_news_text = "\n\n".join([
            f"æ ‡é¢˜: {item.get('title', 'æ— æ ‡é¢˜')}\nå†…å®¹: {item.get('content', 'æ— å†…å®¹')[:500]}...\næ¥æº: {item.get('source', 'æœªçŸ¥')}"
            for item in breaking_news
        ])
        
        enhanced_prompt = f"""
        ä½œä¸º{topic}è¡Œä¸šçš„é¦–å¸­åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹é‡å¤§äº‹ä»¶è¿›è¡Œæ·±åº¦åˆ†æï¼š
        
        {all_news_text}
        
        åˆ†ææ¡†æ¶ï¼š
        1. **äº‹ä»¶é‡è¦æ€§è¯„ä¼°**: æŒ‰å½±å“ç¨‹åº¦å¯¹äº‹ä»¶è¿›è¡Œæ’åºå’Œåˆ†ç±»
        2. **å¤šç»´åº¦å½±å“åˆ†æ**: åˆ†æå¯¹æŠ€æœ¯ã€å¸‚åœºã€æ”¿ç­–ã€ç«äº‰æ ¼å±€çš„å½±å“
        3. **å…³è”æ€§åˆ†æ**: è¯†åˆ«äº‹ä»¶ä¹‹é—´çš„å†…åœ¨è”ç³»å’Œå› æœå…³ç³»
        4. **è¶‹åŠ¿æŒ‡å‘æ€§**: è¿™äº›äº‹ä»¶åæ˜ äº†ä»€ä¹ˆè¶‹åŠ¿ä¿¡å·ï¼Ÿ
        5. **é£é™©ä¸æœºé‡**: ä¸ºè¡Œä¸šå‚ä¸è€…å¸¦æ¥çš„æœºé‡å’ŒæŒ‘æˆ˜
        
        ğŸ¤” **åˆ†æå¸ˆæ€è€ƒè¿‡ç¨‹**:
        - é¦–å…ˆæ¢³ç†äº‹ä»¶çš„æ—¶é—´çº¿å’Œé€»è¾‘å…³ç³»
        - ç„¶åè¯„ä¼°æ¯ä¸ªäº‹ä»¶çš„çŸ­æœŸå’Œé•¿æœŸå½±å“
        - æœ€åç»¼åˆåˆ¤æ–­å¯¹è¡Œä¸šå‘å±•çš„æŒ‡å‘æ„ä¹‰
        
        è¯·ä¿æŒåˆ†æçš„å®¢è§‚æ€§å’Œå‰ç»æ€§ï¼Œè¦æ±‚æ·±åº¦åˆ†æï¼Œå­—æ•°æ§åˆ¶åœ¨2000-2500å­—ã€‚
         
         ğŸ“ **æ·±åº¦åˆ†æè¦æ±‚**:
         - æ¯ä¸ªé‡å¤§äº‹ä»¶éƒ½è¦ä»å¤šä¸ªè§’åº¦æ·±å…¥å‰–æ
         - æä¾›è¯¦ç»†çš„èƒŒæ™¯ä¿¡æ¯å’Œå‘å±•è„‰ç»œ
         - åˆ†æäº‹ä»¶å¯¹äº§ä¸šé“¾å„ç¯èŠ‚çš„å…·ä½“å½±å“
         - è¯„ä¼°çŸ­æœŸã€ä¸­æœŸã€é•¿æœŸçš„å½±å“ç¨‹åº¦
         - è¯†åˆ«äº‹ä»¶èƒŒåçš„æ·±å±‚æ¬¡åŸå› å’Œè§„å¾‹
         - æä¾›å…·ä½“çš„åº”å¯¹ç­–ç•¥å’Œå‘å±•å»ºè®®
         - é¢„æµ‹åç»­å¯èƒ½çš„è¿é”ååº”å’Œå‘å±•è¶‹åŠ¿
        """
        
        system_msg = f"""ä½ æ˜¯{topic}è¡Œä¸šçš„èµ„æ·±é¦–å¸­åˆ†æå¸ˆï¼Œå…·å¤‡ï¼š
        1. æ•é”çš„è¡Œä¸šæ´å¯ŸåŠ›
        2. ç³»ç»Ÿæ€§çš„åˆ†ææ€ç»´
        3. å‰ç»æ€§çš„åˆ¤æ–­èƒ½åŠ›
        4. å®¢è§‚ç†æ€§çš„åˆ†ææ€åº¦
        è¯·å±•ç°å‡ºä¸“ä¸šåˆ†æå¸ˆçš„æ€è€ƒæ·±åº¦ã€‚"""
        
        try:
            if not self.llm_processor:
                return f"{topic}è¡Œä¸šé‡å¤§äº‹ä»¶éœ€è¦æ·±åº¦åˆ†æï¼Œä½†LLMå¤„ç†å™¨æš‚æ—¶ä¸å¯ç”¨ã€‚"
            
            analysis = self.llm_processor.call_llm_api(enhanced_prompt, system_msg, max_tokens=8000)
            return analysis
            
        except Exception as e:
            print(f"    âŒ [ä»»åŠ¡2] ç”Ÿæˆæ·±åº¦åˆ†ææ—¶å‡ºé”™: {str(e)}")
            return f"{topic}è¡Œä¸šé‡å¤§äº‹ä»¶æ·±åº¦åˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚"
    
    def _filter_by_time(self, breaking_news: List[Dict], days: int) -> List[Dict]:
        """æŒ‰æ—¶é—´è¿‡æ»¤æ–°é—»"""
        from datetime import datetime, timedelta
        
        today = datetime.now()
        cutoff_date = today - timedelta(days=days)
        current_year = today.year
        
        time_filtered_news = []
        
        for item in breaking_news:
            should_include = False
            title = item.get('title', '')
            content = item.get('content', '')
            source = item.get('source', '')
            news_date = item.get('date', '') or item.get('published_date', '')
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„æ—§å¹´ä»½æ ‡è¯†
            text_content = f"{title} {content} {source}".lower()
            old_year_patterns = ['2024å¹´', '2023å¹´', '2022å¹´', '2021å¹´', '2020å¹´']
            has_old_year = any(pattern in text_content for pattern in old_year_patterns)
            
            if has_old_year:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å½“å‰å¹´ä»½æˆ–æœ€æ–°æ—¶é—´è¯æ±‡
            current_time_patterns = [
                f'{current_year}å¹´', f'{current_year}', 'latest', 'recent', 
                'æœ€æ–°', 'æœ€è¿‘', 'breaking', 'åˆšåˆš', 'ä»Šæ—¥', 'ä»Šå¤©',
                today.strftime('%Yå¹´%mæœˆ'), today.strftime('%mæœˆ')
            ]
            
            has_recent_indicators = any(pattern in text_content for pattern in current_time_patterns)
            
            # å¦‚æœæœ‰æ˜ç¡®çš„å‘å¸ƒæ—¥æœŸï¼Œæ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
            if news_date and news_date != "æœªçŸ¥æ—¥æœŸ":
                try:
                    # å°è¯•è§£ææ—¥æœŸ
                    parsed_date = None
                    try:
                        from dateutil import parser
                        parsed_date = parser.parse(str(news_date))
                    except ImportError:
                        # å¦‚æœæ²¡æœ‰dateutilï¼Œä½¿ç”¨åŸºç¡€è§£æ
                        if isinstance(news_date, str):
                            # å°è¯•åŸºç¡€çš„ISOæ—¥æœŸæ ¼å¼
                            for fmt in ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y/%m/%d']:
                                try:
                                    parsed_date = datetime.strptime(news_date, fmt)
                                    break
                                except ValueError:
                                    continue
                    
                    if parsed_date and parsed_date >= cutoff_date:
                        should_include = True
                    elif parsed_date:
                        continue
                    else:
                        raise ValueError("æ— æ³•è§£ææ—¥æœŸ")
                except:
                    # æ—¥æœŸè§£æå¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åˆ¤æ–­
                    if has_recent_indicators:
                        should_include = True
                    else:
                        continue
            else:
                # æ²¡æœ‰å‘å¸ƒæ—¥æœŸï¼Œå®Œå…¨ä¾é å†…å®¹å…³é”®è¯
                if has_recent_indicators:
                    should_include = True
                else:
                    continue
            
            if should_include:
                time_filtered_news.append(item)
        
        return time_filtered_news
    
    def _generate_fallback_summary_simple(self, topic: str, selected_news: List[Dict]) -> str:
        """å¤‡ç”¨çš„ç®€æ´æ ¼å¼äº‹ä»¶æ‘˜è¦ç”Ÿæˆæ–¹æ³•"""
        if not selected_news:
            return "### ä¸€ã€é‡å¤§æ–°é—»æ‘˜è¦ä¸å…³é”®ç»†èŠ‚\n\nğŸ“Š **å½“å‰çŠ¶å†µ**: åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æš‚æ— é‡å¤§äº‹ä»¶ã€‚"
        
        summary_text = "### ä¸€ã€é‡å¤§æ–°é—»æ‘˜è¦ä¸å…³é”®ç»†èŠ‚\n\n"
        
        for i, event in enumerate(selected_news, 1):
            title = event.get('title', 'æœªçŸ¥äº‹ä»¶')
            source = event.get('source', 'æœªçŸ¥æ¥æº')
            content = event.get('content', 'æ— è¯¦ç»†å†…å®¹')[:150]
            
            # æå–åŸŸå
            source_domain = source
            if 'http' in source.lower():
                try:
                    from urllib.parse import urlparse
                    parsed = urlparse(source)
                    source_domain = parsed.netloc or source
                except:
                    source_domain = source
            
            summary_text += f"{i}. {title} ({source_domain})\n"
            summary_text += f"   â—‹ äº‹ä»¶ï¼š{content}...\n"
            summary_text += f"   â—‹ å…³é”®ç‚¹ï¼š{topic}è¡Œä¸šç›¸å…³é‡è¦åŠ¨æ€ï¼Œéœ€è¦æŒç»­å…³æ³¨ã€‚\n\n"
        
        return summary_text
    
    def _extract_sources(self, breaking_news: List[Dict]) -> str:
        """æå–æ–°é—»æ¥æºä¿¡æ¯"""
        sources = []
        for item in breaking_news:
            if item.get('url', '#') != '#':
                sources.append(f"- [{item.get('title', 'æœªçŸ¥æ ‡é¢˜')}]({item.get('url')}) - {item.get('source', 'æœªçŸ¥æ¥æº')}")
        
        return "\n".join(sources) if sources else ""
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "analyzer_type": "BreakingNewsAnalyzer",
            "max_workers": self.max_workers,
            "parallel_tasks": ["event_summary", "depth_analysis"],
            "estimated_speedup": "2x faster than sequential"
        } 