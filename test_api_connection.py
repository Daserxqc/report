#!/usr/bin/env python3
"""
APIè¿æ¥æµ‹è¯•è„šæœ¬
ç”¨äºè¯Šæ–­å¤§æ¨¡å‹APIè¿æ¥é—®é¢˜
"""

import os
import time
import json
import requests
import ssl
from datetime import datetime
from dotenv import load_dotenv
import config

def test_ssl_connection():
    """æµ‹è¯•SSLè¿æ¥"""
    print("ğŸ” æµ‹è¯•SSLè¿æ¥...")
    try:
        import ssl
        print(f"âœ… SSLç‰ˆæœ¬: {ssl.OPENSSL_VERSION}")
        
        # æµ‹è¯•SSLè¯ä¹¦
        context = ssl.create_default_context()
        print("âœ… SSLä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ SSLè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_network_connectivity():
    """æµ‹è¯•ç½‘ç»œè¿é€šæ€§"""
    print("\nğŸŒ æµ‹è¯•ç½‘ç»œè¿é€šæ€§...")
    
    test_urls = [
        "https://www.baidu.com",
        "https://www.google.com", 
        "https://dashscope.aliyuncs.com",
        "https://api.openai.com"
    ]
    
    results = {}
    for url in test_urls:
        try:
            response = requests.get(url, timeout=10)
            results[url] = {
                "status": "success",
                "status_code": response.status_code,
                "response_time": response.elapsed.total_seconds()
            }
            print(f"âœ… {url}: {response.status_code} ({response.elapsed.total_seconds():.2f}s)")
        except Exception as e:
            results[url] = {
                "status": "failed",
                "error": str(e)
            }
            print(f"âŒ {url}: {str(e)}")
    
    return results

def test_dashscope_api():
    """æµ‹è¯•DashScope APIè¿æ¥"""
    print("\nğŸš€ æµ‹è¯•DashScope API...")
    
    api_key = config.OPENAI_API_KEY
    base_url = config.OPENAI_BASE_URL
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return False
    
    print(f"ğŸ”‘ APIå¯†é’¥: {api_key[:10]}...")
    print(f"ğŸŒ Base URL: {base_url}")
    
    # æµ‹è¯•ç®€å•çš„APIè°ƒç”¨
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # æ„å»ºæµ‹è¯•æ•°æ®
    test_data = {
        "model": "deepseek-v3",
        "messages": [
            {"role": "user", "content": "Hello, please respond with 'API test successful'"}
        ],
        "temperature": 0.1,
        "max_tokens": 50
    }
    
    endpoint = f"{base_url}/chat/completions"
    
    try:
        print(f"ğŸ“¡ å‘é€è¯·æ±‚åˆ°: {endpoint}")
        start_time = time.time()
        
        response = requests.post(
            endpoint, 
            headers=headers, 
            json=test_data, 
            timeout=30,
            verify=True
        )
        
        response_time = time.time() - start_time
        print(f"â±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        print(f"ğŸ“Š çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                print(f"âœ… APIè°ƒç”¨æˆåŠŸ!")
                print(f"ğŸ“ å“åº”å†…å®¹: {content}")
                
                # æ£€æŸ¥ç”¨é‡ä¿¡æ¯
                if "usage" in result:
                    usage = result["usage"]
                    print(f"ğŸ“ˆ Tokenä½¿ç”¨: {usage}")
                
                return True
            else:
                print(f"âŒ APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
                return False
        else:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"ğŸ“„ é”™è¯¯å“åº”: {response.text}")
            return False
            
    except requests.exceptions.SSLError as e:
        print(f"âŒ SSLé”™è¯¯: {str(e)}")
        return False
    except requests.exceptions.ConnectionError as e:
        print(f"âŒ è¿æ¥é”™è¯¯: {str(e)}")
        return False
    except requests.exceptions.Timeout as e:
        print(f"âŒ è¶…æ—¶é”™è¯¯: {str(e)}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–é”™è¯¯: {str(e)}")
        return False

def test_openai_library():
    """æµ‹è¯•OpenAIåº“è°ƒç”¨"""
    print("\nğŸ“š æµ‹è¯•OpenAIåº“è°ƒç”¨...")
    
    try:
        from openai import OpenAI
        
        client = OpenAI(
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL
        )
        
        print("âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç®€å•è°ƒç”¨
        start_time = time.time()
        response = client.chat.completions.create(
            model="deepseek-v3",
            messages=[
                {"role": "user", "content": "Hello, please respond with 'OpenAI library test successful'"}
            ],
            temperature=0.1,
            max_tokens=50
        )
        
        response_time = time.time() - start_time
        print(f"â±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        
        if response.choices and len(response.choices) > 0:
            content = response.choices[0].message.content
            print(f"âœ… OpenAIåº“è°ƒç”¨æˆåŠŸ!")
            print(f"ğŸ“ å“åº”å†…å®¹: {content}")
            
            # æ£€æŸ¥ç”¨é‡ä¿¡æ¯
            if hasattr(response, 'usage') and response.usage:
                usage = response.usage
                print(f"ğŸ“ˆ Tokenä½¿ç”¨: {usage}")
            
            return True
        else:
            print("âŒ OpenAIåº“å“åº”æ ¼å¼å¼‚å¸¸")
            return False
            
    except ImportError:
        print("âŒ OpenAIåº“æœªå®‰è£…")
        return False
    except Exception as e:
        print(f"âŒ OpenAIåº“è°ƒç”¨å¤±è´¥: {str(e)}")
        return False

def test_llm_processor():
    """æµ‹è¯•LLMå¤„ç†å™¨"""
    print("\nğŸ”§ æµ‹è¯•LLMå¤„ç†å™¨...")
    
    try:
        from collectors.llm_processor import LLMProcessor
        
        processor = LLMProcessor()
        print("âœ… LLMå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç®€å•è°ƒç”¨
        start_time = time.time()
        result = processor.call_llm_api(
            prompt="Hello, please respond with 'LLM processor test successful'",
            system_message="You are a helpful assistant.",
            temperature=0.1,
            max_tokens=50
        )
        
        response_time = time.time() - start_time
        print(f"â±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        print(f"âœ… LLMå¤„ç†å™¨è°ƒç”¨æˆåŠŸ!")
        print(f"ğŸ“ å“åº”å†…å®¹: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLMå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        print(f"ğŸ“„ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def test_json_api():
    """æµ‹è¯•JSON APIè°ƒç”¨"""
    print("\nğŸ“‹ æµ‹è¯•JSON APIè°ƒç”¨...")
    
    try:
        from collectors.llm_processor import LLMProcessor
        
        processor = LLMProcessor()
        
        # æµ‹è¯•JSONæ ¼å¼è°ƒç”¨
        start_time = time.time()
        result = processor.call_llm_api_json(
            prompt="è¯·è¿”å›ä¸€ä¸ªç®€å•çš„JSONå¯¹è±¡ï¼ŒåŒ…å«å­—æ®µ'test'å’Œå€¼'success'",
            system_message="ä½ æ˜¯ä¸€ä¸ªAPIç¨‹åºï¼Œåªè¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®ã€‚",
            temperature=0.1,
            max_tokens=100
        )
        
        response_time = time.time() - start_time
        print(f"â±ï¸ å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        print(f"âœ… JSON APIè°ƒç”¨æˆåŠŸ!")
        print(f"ğŸ“ å“åº”å†…å®¹: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ JSON APIæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        print(f"ğŸ“„ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def generate_test_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š APIè¿æ¥æµ‹è¯•æŠ¥å‘Š")
    print("="*60)
    
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"ğŸ• æµ‹è¯•æ—¶é—´: {current_time}")
    
    total_tests = len(results)
    passed_tests = sum(1 for result in results.values() if result)
    
    print(f"ğŸ“ˆ æµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
    
    print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_data = {
        "test_time": current_time,
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "results": results
    }
    
    report_file = f"api_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return report_file

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ APIè¿æ¥è¯Šæ–­æµ‹è¯•å¼€å§‹")
    print("="*60)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = {}
    
    # 1. SSLè¿æ¥æµ‹è¯•
    test_results["SSLè¿æ¥"] = test_ssl_connection()
    
    # 2. ç½‘ç»œè¿é€šæ€§æµ‹è¯•
    network_results = test_network_connectivity()
    test_results["ç½‘ç»œè¿é€šæ€§"] = all(
        result["status"] == "success" 
        for result in network_results.values()
    )
    
    # 3. DashScope APIæµ‹è¯•
    test_results["DashScope API"] = test_dashscope_api()
    
    # 4. OpenAIåº“æµ‹è¯•
    test_results["OpenAIåº“"] = test_openai_library()
    
    # 5. LLMå¤„ç†å™¨æµ‹è¯•
    test_results["LLMå¤„ç†å™¨"] = test_llm_processor()
    
    # 6. JSON APIæµ‹è¯•
    test_results["JSON API"] = test_json_api()
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    report_file = generate_test_report(test_results)
    
    print("\nğŸ¯ æµ‹è¯•å®Œæˆ!")
    
    # ç»™å‡ºå»ºè®®
    if not test_results["LLMå¤„ç†å™¨"]:
        print("\nğŸ’¡ å»ºè®®:")
        if not test_results["ç½‘ç»œè¿é€šæ€§"]:
            print("  - æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®")
        if not test_results["SSLè¿æ¥"]:
            print("  - æ£€æŸ¥SSLè¯ä¹¦å’Œç³»ç»Ÿæ—¶é—´")
        if not test_results["DashScope API"]:
            print("  - æ£€æŸ¥APIå¯†é’¥å’Œbase_urlé…ç½®")
        print("  - å°è¯•ä½¿ç”¨å¤‡ç”¨ç½‘ç»œç¯å¢ƒ")
        print("  - è”ç³»APIæœåŠ¡æä¾›å•†")

if __name__ == "__main__":
    main()

