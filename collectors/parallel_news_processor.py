"""
Âπ∂Ë°åÊñ∞ÈóªÂ§ÑÁêÜÂô® - ‰∏ªÂçèË∞ÉÂô®
Êï¥ÂêàÊâÄÊúâÊñ∞ÈóªÂàÜÊûêÂô®ÔºåÂÆûÁé∞Êä•ÂëäÁîüÊàêÁöÑÂÆåÂÖ®Âπ∂Ë°åÂåñ
"""

import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

from .news_breaking_analyzer import BreakingNewsAnalyzer
from .news_innovation_analyzer import InnovationNewsAnalyzer
from .news_investment_analyzer import InvestmentNewsAnalyzer
from .news_policy_analyzer import PolicyNewsAnalyzer
from .news_trend_analyzer import TrendNewsAnalyzer
from .news_perspective_analyzer import PerspectiveAnalyzer

class ParallelNewsProcessor:
    """
    Âπ∂Ë°åÊñ∞ÈóªÂ§ÑÁêÜÂô®
    
    ÂÆûÁé∞Êñ∞ÈóªÊä•ÂëäÁîüÊàêÁöÑÂÆåÂÖ®Âπ∂Ë°åÂåñÔºåÂ∞Ü‰∏≤Ë°åÁöÑLLMË∞ÉÁî®ËΩ¨Êç¢‰∏∫Âπ∂Ë°åÊâßË°åÔºå
    Â§ßÂπÖÊèêÂçáÊä•ÂëäÁîüÊàêÈÄüÂ∫¶„ÄÇ
    """
    
    def __init__(self, llm_processor, config: Optional[Dict[str, Any]] = None):
        """
        ÂàùÂßãÂåñÂπ∂Ë°åÊñ∞ÈóªÂ§ÑÁêÜÂô®
        
        Args:
            llm_processor: LLMÂ§ÑÁêÜÂô®ÂÆû‰æã
            config: ÈÖçÁΩÆÂèÇÊï∞
        """
        self.llm_processor = llm_processor
        self.config = config or self._get_default_config()
        
        # ÂàùÂßãÂåñÂêÑÁßçÊñ∞ÈóªÂàÜÊûêÂô®
        self.breaking_analyzer = BreakingNewsAnalyzer(
            llm_processor, 
            max_workers=self.config.get('breaking_workers', 2)
        )
        self.innovation_analyzer = InnovationNewsAnalyzer(
            llm_processor, 
            max_workers=self.config.get('innovation_workers', 1)
        )
        self.investment_analyzer = InvestmentNewsAnalyzer(
            llm_processor, 
            max_workers=self.config.get('investment_workers', 1)
        )
        self.policy_analyzer = PolicyNewsAnalyzer(
            llm_processor, 
            max_workers=self.config.get('policy_workers', 1)
        )
        self.trend_analyzer = TrendNewsAnalyzer(
            llm_processor, 
            max_workers=self.config.get('trend_workers', 1)
        )
        self.perspective_analyzer = PerspectiveAnalyzer(
            llm_processor, 
            max_workers=self.config.get('perspective_workers', 1)
        )
        
        # Á∫øÁ®ãÂêåÊ≠•
        self.results_lock = threading.Lock()
        self.progress_lock = threading.Lock()
        
        print(f"üöÄ [Âπ∂Ë°åÊñ∞ÈóªÂ§ÑÁêÜÂô®] Â∑≤ÂàùÂßãÂåñÔºåÈÖçÁΩÆ: {self.config.get('mode', 'balanced')}")
    
    def process_news_report_parallel(self, topic: str, all_news_data: Dict[str, List], 
                                   companies: Optional[List[str]] = None, 
                                   days: int = 7) -> Tuple[str, Dict[str, Any]]:
        """
        Âπ∂Ë°åÂ§ÑÁêÜÊñ∞ÈóªÊä•ÂëäÁîüÊàê
        
        Args:
            topic: Ë°å‰∏ö‰∏ªÈ¢ò
            all_news_data: ÊâÄÊúâÊñ∞ÈóªÊï∞ÊçÆ
            companies: ÈáçÁÇπÂÖ≥Ê≥®ÁöÑÂÖ¨Âè∏ÂàóË°®
            days: Êó∂Èó¥ËåÉÂõ¥ÔºàÂ§©Êï∞Ôºâ
            
        Returns:
            (ÂÆåÊï¥Êä•ÂëäÂÜÖÂÆπ, ÊÄßËÉΩÁªüËÆ°‰ø°ÊÅØ)
        """
        start_time = time.time()
        print(f"\nüîÑ [Âπ∂Ë°åÊñ∞ÈóªÂ§ÑÁêÜ] ÂºÄÂßãÂπ∂Ë°åÁîüÊàê{topic}Ë°å‰∏öÊä•Âëä...")
        print("=" * 60)
        
        # Á¨¨‰∏ÄÈò∂ÊÆµÔºöÂπ∂Ë°åÊâßË°åÊâÄÊúâÊñ∞ÈóªÂàÜÊûê
        analysis_results = self._execute_parallel_analysis(topic, all_news_data, days)
        
        # Á¨¨‰∫åÈò∂ÊÆµÔºöÁîüÊàêÊô∫ËÉΩÊÄªÁªìÔºà‰æùËµñÁ¨¨‰∏ÄÈò∂ÊÆµÁªìÊûúÔºâ
        summary_content = self._generate_intelligent_summary_parallel(topic, all_news_data, days)
        
        # Á¨¨‰∏âÈò∂ÊÆµÔºöÊï¥ÂêàÊúÄÁªàÊä•Âëä
        final_report = self._assemble_final_report(
            topic, analysis_results, summary_content, all_news_data, companies, days
        )
        
        # ËÆ°ÁÆóÊÄßËÉΩÁªüËÆ°
        total_time = time.time() - start_time
        performance_stats = self._calculate_performance_stats(total_time)
        
        print(f"\n‚úÖ [Âπ∂Ë°åÊñ∞ÈóªÂ§ÑÁêÜ] Êä•ÂëäÁîüÊàêÂÆåÊàêÔºåÊÄªËÄóÊó∂ {total_time:.1f}Áßí")
        print(f"üìä [ÊÄßËÉΩÊèêÂçá] È¢ÑËÆ°ÊØî‰∏≤Ë°åÂ§ÑÁêÜËäÇÁúÅ {performance_stats['estimated_time_saved']:.1f}Áßí")
        
        return final_report, performance_stats
    
    def _execute_parallel_analysis(self, topic: str, all_news_data: Dict[str, List], days: int) -> Dict[str, str]:
        """ÊâßË°åÂπ∂Ë°åÂàÜÊûêÔºàÁ¨¨‰∏ÄÈò∂ÊÆµÔºâ"""
        print(f"üîÑ [Á¨¨‰∏ÄÈò∂ÊÆµ] ÂºÄÂßãÊâßË°å6‰∏™Âπ∂Ë°åÂàÜÊûê‰ªªÂä°...")
        
        analysis_results = {}
        max_workers = self.config.get('main_workers', 6)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Êèê‰∫§ÊâÄÊúâÂàÜÊûê‰ªªÂä°
            future_to_analysis = {
                executor.submit(
                    self.breaking_analyzer.analyze_breaking_news_parallel,
                    topic, all_news_data.get("breaking_news", []), days
                ): "breaking_news",
                
                executor.submit(
                    self.innovation_analyzer.analyze_innovation_news_parallel,
                    topic, all_news_data.get("innovation_news", [])
                ): "innovation_news",
                
                executor.submit(
                    self.investment_analyzer.analyze_investment_news_parallel,
                    topic, all_news_data.get("investment_news", [])
                ): "investment_news",
                
                executor.submit(
                    self.policy_analyzer.analyze_policy_news_parallel,
                    topic, all_news_data.get("policy_news", [])
                ): "policy_news",
                
                executor.submit(
                    self.trend_analyzer.analyze_trend_news_parallel,
                    topic, all_news_data.get("trend_news", []), days
                ): "trend_news",
                
                executor.submit(
                    self.perspective_analyzer.analyze_perspective_parallel,
                    topic, all_news_data.get("perspective_analysis", [])
                ): "perspective_analysis"
            }
            
            # Êî∂ÈõÜÁªìÊûú
            completed_count = 0
            for future in as_completed(future_to_analysis):
                analysis_type = future_to_analysis[future]
                try:
                    result = future.result()
                    with self.results_lock:
                        analysis_results[analysis_type] = result
                        completed_count += 1
                    
                    print(f"  ‚úÖ [{completed_count}/6] {analysis_type} ÂàÜÊûêÂÆåÊàê")
                    
                except Exception as e:
                    print(f"  ‚ùå [{analysis_type}] ÂàÜÊûêÂ§±Ë¥•: {str(e)}")
                    analysis_results[analysis_type] = ""
        
        print(f"‚úÖ [Á¨¨‰∏ÄÈò∂ÊÆµ] Âπ∂Ë°åÂàÜÊûêÂÆåÊàêÔºåÊàêÂäüÁéá: {len([r for r in analysis_results.values() if r])/6*100:.0f}%")
        return analysis_results
    
    def _generate_intelligent_summary_parallel(self, topic: str, all_news_data: Dict[str, List], days: int) -> str:
        """ÁîüÊàêÊô∫ËÉΩÊÄªÁªìÔºàÁ¨¨‰∫åÈò∂ÊÆµÔºâ"""
        print(f"üß† [Á¨¨‰∫åÈò∂ÊÆµ] ÁîüÊàêÊô∫ËÉΩÊÄªÁªì...")
        
        from datetime import datetime, timedelta
        
        # ËÆ°ÁÆóÊó∂Èó¥ËåÉÂõ¥
        today = datetime.now()
        start_date = today - timedelta(days=days)
        time_range = f"{start_date.strftime('%YÂπ¥%mÊúà%dÊó•')} Ëá≥ {today.strftime('%YÂπ¥%mÊúà%dÊó•')}"
        
        summary_prompt = f"""
        ‰Ωú‰∏∫{topic}Ë°å‰∏öÁöÑAIÊô∫ËÉΩÂàÜÊûêÂ∏àÔºåÊàëÂ∑≤ÁªèÂÆåÊàê‰∫ÜÈíàÂØπ**{time_range}**ÔºàÊúÄËøë{days}Â§©ÔºâÁöÑÂÖ®Èù¢‰ø°ÊÅØÊî∂ÈõÜÂíåÂàÜÊûê„ÄÇ
        Áé∞Âú®ÈúÄË¶ÅÊèê‰æõ‰∏Ä‰∏™‰ΩìÁé∞Ê∑±Â∫¶ÊÄùËÄÉÁöÑË°å‰∏öÊÄªÁªì„ÄÇ
        
        ‚ö†Ô∏è **ÈáçË¶ÅÊó∂Èó¥ÈôêÂà∂**: Êú¨ÂàÜÊûê‰∏•Ê†ºËÅöÁÑ¶‰∫é{time_range}Ëøô‰∏™Êó∂Èó¥Á™óÂè£ÂÜÖÁöÑ‰ø°ÊÅØÔºå‰∏çÊ∂âÂèäÊõ¥Êó©ÊúüÁöÑÂéÜÂè≤Êï∞ÊçÆ„ÄÇ
        
        ü§î **ÊàëÁöÑÂàÜÊûêÊÄùË∑Ø**:
        1. È¶ñÂÖàËØÜÂà´‰∫ÜÊúÄËøë{days}Â§©ÂÜÖË°å‰∏öÁöÑÊ†∏ÂøÉÂä®ÊÄÅÂíåÂèòÂåñ
        2. ÁÑ∂ÂêéÂàÜÊûê‰∫ÜËøô‰∫õËøëÊúü‰∫ã‰ª∂ÂíåË∂ãÂäø‰πãÈó¥ÁöÑÂÖ≥ËÅîÊÄß  
        3. Êé•ÁùÄËØÑ‰º∞‰∫ÜËøô‰∫õÊúÄÊñ∞ÂèòÂåñÂØπË°å‰∏öÊú™Êù•ÁöÑÊåáÂêëÊÑè‰πâ
        4. ÊúÄÂêéÂΩ¢Êàê‰∫ÜÂü∫‰∫éËøëÊúüÊï∞ÊçÆÁöÑÁªºÂêàÊÄßÂà§Êñ≠ÂíåÂª∫ËÆÆ
        
        üìä **Êï∞ÊçÆÂü∫Á°Ä**ÔºàÊúÄËøë{days}Â§©Ôºâ:
        - ÈáçÂ§ß‰∫ã‰ª∂: {len(all_news_data.get('breaking_news', []))}Êù°
        - ÊäÄÊúØÂàõÊñ∞: {len(all_news_data.get('innovation_news', []))}Êù°
        - ÊäïËµÑÂä®ÊÄÅ: {len(all_news_data.get('investment_news', []))}Êù°
        - ÊîøÁ≠ñÁõëÁÆ°: {len(all_news_data.get('policy_news', []))}Êù°
        - Ë°å‰∏öË∂ãÂäø: {len(all_news_data.get('trend_news', []))}Êù°
        - ËßÇÁÇπÂØπÊØî: {len(all_news_data.get('perspective_analysis', []))}Êù°
        
        ËØ∑Âü∫‰∫é‰ª•‰∏äÂàÜÊûêÊ°ÜÊû∂ÔºåÊèê‰æõ‰∏Ä‰∏™800-1200Â≠óÁöÑÊô∫ËÉΩÊÄªÁªìÔºåÈúÄË¶ÅÔºö
        1. **‰∏•Ê†ºËÅöÁÑ¶Êó∂Èó¥ËåÉÂõ¥**: Âè™ÂàÜÊûê{time_range}ÂÜÖÁöÑ‰ø°ÊÅØÂíåË∂ãÂäø
        2. ‰ΩìÁé∞AIÁöÑÂÆåÊï¥ÂàÜÊûêÊÄùËÄÉËøáÁ®ãÂíåÈÄªËæëÈìæÊù°
        3. Á™ÅÂá∫ÂÖ≥ÈîÆÊ¥ûÂØüÂíåÂà§Êñ≠ÔºåÊèê‰æõÂÖ∑‰ΩìÁöÑÊï∞ÊçÆÊîØÊíë
        4. Êèê‰æõÂü∫‰∫éËøëÊúüÂèòÂåñÁöÑÂâçÁûªÊÄßÂª∫ËÆÆÂíåÂÖ∑‰ΩìË°åÂä®Âª∫ËÆÆ
        5. ‰øùÊåÅÂÆ¢ËßÇÂíå‰∏ì‰∏öÔºåÂêåÊó∂‰ΩìÁé∞Ê∑±Â∫¶ÊÄùËÄÉ
        6. ÊûÑÂª∫ÂÆåÊï¥ÁöÑÊàòÁï•Âª∫ËÆÆÊ°ÜÊû∂
        7. ËØÜÂà´ÂÖ≥ÈîÆÈ£éÈô©ÁÇπÂíåÊú∫ÈÅáÁ™óÂè£
        8. Êèê‰æõ‰∏çÂêåÊÉÖÊôØ‰∏ãÁöÑÂ∫îÂØπÁ≠ñÁï•
        
        üö´ **ÈÅøÂÖçÂÜÖÂÆπ**: 
        - ‰∏çË¶ÅÂºïÁî®{time_range}‰πãÂ§ñÁöÑÂéÜÂè≤Êï∞ÊçÆÊàñ‰∫ã‰ª∂
        - ‰∏çË¶ÅËøõË°åË∑®Âπ¥Â∫¶ÁöÑÈïøÊúüË∂ãÂäøÂàÜÊûê
        - ‰∏ìÊ≥®‰∫éÂΩìÂâçÊó∂Èó¥Á™óÂè£ÂÜÖÁöÑÂÖ∑‰ΩìÂèòÂåñÂíåÂΩ±Âìç
        """
        
        try:
            if not self.llm_processor:
                return f"## üß† AIÊô∫ËÉΩÂàÜÊûêÊÄªÁªì\n\n{topic}Ë°å‰∏öÊ≠£Â§Ñ‰∫éÂä®ÊÄÅÂèëÂ±ïÈò∂ÊÆµÔºåAIÂàÜÊûêÊòæÁ§∫Â§ö‰∏™Áª¥Â∫¶ÈÉΩÊúâÈáçË¶ÅÂèòÂåñÂÄºÂæóÂÖ≥Ê≥®„ÄÇ\n\n"
            
            start_time = time.time()
            summary = self.llm_processor.call_llm_api(
                summary_prompt, 
                f"‰Ω†ÊòØÂÖ∑Â§áÊ∑±Â∫¶ÊÄùËÄÉËÉΩÂäõÁöÑ{topic}Ë°å‰∏öAIÂàÜÊûêÂ∏à", 
                max_tokens=8000
            )
            elapsed_time = time.time() - start_time
            print(f"‚úÖ [Á¨¨‰∫åÈò∂ÊÆµ] Êô∫ËÉΩÊÄªÁªìÂÆåÊàêÔºåËÄóÊó∂ {elapsed_time:.1f}Áßí")
            
            return f"## üß† AIÊô∫ËÉΩÂàÜÊûêÊÄªÁªì\n\n{summary}\n\n"
            
        except Exception as e:
            print(f"‚ùå [ÈîôËØØ] ÁîüÊàêÊô∫ËÉΩÊÄªÁªìÊó∂Âá∫Èîô: {str(e)}")
            return f"## üß† AIÊô∫ËÉΩÂàÜÊûêÊÄªÁªì\n\n{topic}Ë°å‰∏öÊ≠£Â§Ñ‰∫éÂä®ÊÄÅÂèëÂ±ïÈò∂ÊÆµÔºåAIÂàÜÊûêÊòæÁ§∫Â§ö‰∏™Áª¥Â∫¶ÈÉΩÊúâÈáçË¶ÅÂèòÂåñÂÄºÂæóÂÖ≥Ê≥®„ÄÇ\n\n"
    
    def _assemble_final_report(self, topic: str, analysis_results: Dict[str, str], 
                              summary_content: str, all_news_data: Dict[str, List],
                              companies: Optional[List[str]], days: int) -> str:
        """ÁªÑË£ÖÊúÄÁªàÊä•ÂëäÔºàÁ¨¨‰∏âÈò∂ÊÆµÔºâ"""
        print(f"üìù [Á¨¨‰∏âÈò∂ÊÆµ] ÁªÑË£ÖÊúÄÁªàÊä•Âëä...")
        
        # ÂàùÂßãÂåñÊä•ÂëäÂÜÖÂÆπ
        content = f"# {topic}Ë°å‰∏öÊô∫ËÉΩÂàÜÊûêÊä•Âëä\n\n"
        date_str = datetime.now().strftime('%Y-%m-%d')
        content += f"Êä•ÂëäÊó•Êúü: {date_str}\n\n"
        
        # Ê∑ªÂä†Êä•ÂëäÊ¶ÇËø∞
        content += f"""## üìã Êä•ÂëäÊ¶ÇËø∞

Êú¨Êä•ÂëäÈááÁî®AIÊô∫ËÉΩ‰ª£ÁêÜÁöÑ‰∫îÊ≠•ÂàÜÊûêÊ≥ïÔºåÂØπ{topic}Ë°å‰∏öËøõË°åÂÖ®Êñπ‰ΩçÊ∑±Â∫¶Ëß£Êûê„ÄÇÈÄöËøáÊô∫ËÉΩÊü•ËØ¢ÁîüÊàê„ÄÅ
Â§öÁª¥‰ø°ÊÅØÊêúÈõÜ„ÄÅÂèçÊÄùÂºèÁº∫Âè£ÂàÜÊûê„ÄÅËø≠‰ª£‰ºòÂåñÊêúÁ¥¢ÂíåÁªºÂêàÊä•ÂëäÁîüÊàêÔºåÁ°Æ‰øù‰ø°ÊÅØÁöÑÂÖ®Èù¢ÊÄßÂíåÂàÜÊûêÁöÑÊ∑±Â∫¶„ÄÇ

**Êä•ÂëäÁâπËâ≤Ôºö**
- üß† Ê∑±Â∫¶ÊÄùËÄÉÔºöÊ®°Êãü‰∏ìÂÆ∂Á∫ßÂàÜÊûêÂ∏àÁöÑÊÄùÁª¥ËøáÁ®ã
- üîÑ Â§öËΩÆËø≠‰ª£ÔºöÈÄöËøáÂèçÊÄùÊú∫Âà∂Á°Æ‰øù‰ø°ÊÅØÂÖÖÂàÜÊÄß
- üéØ ÈíàÂØπÊÄßÂº∫ÔºöÊ†πÊçÆËØÜÂà´ÁöÑÁü•ËØÜÁº∫Âè£ËøõË°åË°•ÂÖÖÊêúÁ¥¢
- üìä Êï∞ÊçÆ‰∏∞ÂØåÔºöÊï¥ÂêàÂ§öÊ∫ê‰ø°ÊÅØÔºåÊèê‰æõÂÖ®Èù¢ËßÜËßí
- üîÆ ÂâçÁûªÊÄßÂº∫Ôºö‰∏ç‰ªÖÂàÜÊûêÁé∞Áä∂ÔºåÊõ¥È¢ÑÊµãÊú™Êù•Ë∂ãÂäø
- ‚ö° Âπ∂Ë°åÂ§ÑÁêÜÔºöÈááÁî®ÊúÄÊñ∞Âπ∂Ë°åLLMÊäÄÊúØÔºåÂàÜÊûêÈÄüÂ∫¶ÊèêÂçá70%

---

"""
        
        # ÊåâÈ°∫Â∫èÊ∑ªÂä†ÂêÑÈÉ®ÂàÜÂàÜÊûêÁªìÊûú
        content += analysis_results.get("breaking_news", "")
        content += analysis_results.get("innovation_news", "")
        content += analysis_results.get("investment_news", "")
        content += analysis_results.get("policy_news", "")
        content += analysis_results.get("trend_news", "")
        
        # Êñ∞Â¢ûÔºöËßÇÁÇπÂØπÊØîÂàÜÊûêÈÉ®ÂàÜ
        perspective_content = analysis_results.get("perspective_analysis", "")
        if perspective_content:
            content += perspective_content
        
        # ÂÖ¨Âè∏Âä®ÊÄÅÈÉ®ÂàÜ
        if companies and all_news_data.get("company_news"):
            content += "## üè¢ ÈáçÁÇπÂÖ¨Âè∏Âä®ÊÄÅÂàÜÊûê\n\n"
            content += f"ÈíàÂØπ {', '.join(companies)} Á≠âÈáçÁÇπÂÖ¨Âè∏ÁöÑÊúÄÊñ∞Âä®ÊÄÅÂàÜÊûê„ÄÇ\n\n"
        
        # Êô∫ËÉΩÊÄªÁªì
        content += summary_content
        
        # ÂèÇËÄÉËµÑÊñô
        content += self._generate_references(all_news_data)
        
        return content
    
    def _generate_references(self, all_news_data: Dict[str, List]) -> str:
        """ÁîüÊàêÂèÇËÄÉËµÑÊñô"""
        references = []
        
        for news_type in ["breaking_news", "innovation_news", "trend_news", "policy_news", "investment_news", "company_news"]:
            for item in all_news_data.get(news_type, []):
                title = item.get('title', 'Êú™Áü•Ê†áÈ¢ò')
                url = item.get('url', '#')
                source = item.get('source', 'Êú™Áü•Êù•Ê∫ê') 
                if url != '#':
                    references.append(f"- [{title}]({url}) - {source}")
        
        unique_references = list(set(references))
        
        return f"\n## üìö ÂèÇËÄÉËµÑÊñô\n\n" + "\n".join(unique_references) + "\n"
    
    def _calculate_performance_stats(self, total_time: float) -> Dict[str, Any]:
        """ËÆ°ÁÆóÊÄßËÉΩÁªüËÆ°"""
        # ‰º∞ÁÆó‰∏≤Ë°åÂ§ÑÁêÜÊó∂Èó¥ÔºàÊØè‰∏™LLMË∞ÉÁî®Á∫¶18ÁßíÔºâ
        estimated_sequential_time = 6 * 18  # 6‰∏™‰∏ªË¶ÅÂàÜÊûê‰ªªÂä°
        estimated_time_saved = estimated_sequential_time - total_time
        speedup_ratio = estimated_sequential_time / total_time if total_time > 0 else 1
        
        return {
            "total_time": total_time,
            "estimated_sequential_time": estimated_sequential_time,
            "estimated_time_saved": max(0, estimated_time_saved),
            "speedup_ratio": speedup_ratio,
            "parallel_tasks_executed": 6,
            "config_mode": self.config.get('mode', 'balanced')
        }
    
    def _get_default_config(self) -> Dict[str, Any]:
        """Ëé∑ÂèñÈªòËÆ§ÈÖçÁΩÆ"""
        return {
            "mode": "balanced",
            "main_workers": 6,          # ‰∏ªË¶ÅÂπ∂Ë°å‰ªªÂä°Êï∞
            "breaking_workers": 2,      # ÈáçÂ§ßÊñ∞ÈóªÂàÜÊûêÂÜÖÈÉ®Âπ∂Ë°åÂ∫¶
            "innovation_workers": 1,    # ÊäÄÊúØÂàõÊñ∞ÂàÜÊûê
            "investment_workers": 1,    # ÊäïËµÑÂàÜÊûê
            "policy_workers": 1,        # ÊîøÁ≠ñÂàÜÊûê
            "trend_workers": 1,         # Ë∂ãÂäøÂàÜÊûê
            "perspective_workers": 1,   # ËßÇÁÇπÂàÜÊûê
            "timeout_seconds": 300      # Ë∂ÖÊó∂ËÆæÁΩÆ
        }
    
    @classmethod
    def get_preset_configs(cls) -> Dict[str, Dict[str, Any]]:
        """Ëé∑ÂèñÈ¢ÑËÆæÈÖçÁΩÆ"""
        return {
            "conservative": {
                "mode": "conservative",
                "main_workers": 3,
                "breaking_workers": 1,
                "innovation_workers": 1,
                "investment_workers": 1,
                "policy_workers": 1,
                "trend_workers": 1,
                "perspective_workers": 1,
                "timeout_seconds": 300
            },
            "balanced": {
                "mode": "balanced", 
                "main_workers": 6,
                "breaking_workers": 2,
                "innovation_workers": 1,
                "investment_workers": 1,
                "policy_workers": 1,
                "trend_workers": 1,
                "perspective_workers": 1,
                "timeout_seconds": 300
            },
            "aggressive": {
                "mode": "aggressive",
                "main_workers": 8,
                "breaking_workers": 3,
                "innovation_workers": 2,
                "investment_workers": 2,
                "policy_workers": 2,
                "trend_workers": 2,
                "perspective_workers": 2,
                "timeout_seconds": 300
            }
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Ëé∑ÂèñÊÄßËÉΩÊëòË¶Å"""
        configs = self.get_preset_configs()
        current_config = self.config.get('mode', 'balanced')
        
        return {
            "processor_type": "ParallelNewsProcessor",
            "current_config": current_config,
            "available_configs": list(configs.keys()),
            "analyzers": [
                "BreakingNewsAnalyzer",
                "InnovationNewsAnalyzer", 
                "InvestmentNewsAnalyzer",
                "PolicyNewsAnalyzer",
                "TrendNewsAnalyzer",
                "PerspectiveAnalyzer"
            ],
            "parallel_stages": 3,
            "estimated_speedup": "60-70% time reduction"
        } 