import json
from typing import List, Dict, Optional
from dataclasses import dataclass
from collectors.llm_processor import LLMProcessor


@dataclass
class QueryContext:
    """æŸ¥è¯¢ä¸Šä¸‹æ–‡æ•°æ®ç»“æ„"""
    topic: str
    strategy: str  # 'initial', 'iterative', 'targeted'
    context: str = ""
    existing_data: List[Dict] = None
    target_audience: str = "é€šç”¨"
    report_type: str = "ç»¼åˆæŠ¥å‘Š"
    
    def __post_init__(self):
        if self.existing_data is None:
            self.existing_data = []


class QueryGenerationMcp:
    """
    æŸ¥è¯¢ç”ŸæˆMCP (Model Context Protocol)
    
    ç”¨é€”ï¼šåŸºäºä¸Šä¸‹æ–‡èƒ½ç”Ÿæˆé«˜æ•ˆçš„æœç´¢æŸ¥è¯¢ã€‚
    
    èŒè´£ï¼š
    - ä¸ºåˆå§‹æœç´¢ç”Ÿæˆå¹¿æ³›çš„æŸ¥è¯¢
    - æ ¹æ®å·²æœ‰ä¿¡æ¯ç”Ÿæˆè¿­ä»£å¼ã€è¡¥å……æ€§çš„æŸ¥è¯¢
    - æ ¹æ®ç« èŠ‚æ ‡é¢˜ç”Ÿæˆé«˜åº¦é’ˆå¯¹æ€§çš„æŸ¥è¯¢
    
    è¾“å…¥ï¼štopic: str, strategy: str (e.g., 'initial', 'iterative', 'targeted'), context: str = ""
    è¾“å‡ºï¼šlist[str]
    
    å®ç°è¦ç‚¹ï¼šæ ¸å¿ƒæ˜¯ç²¾å¿ƒè®¾è®¡çš„Promptï¼Œå¼•å¯¼LLMè¿›è¡Œæ€ç»´é“¾æ¨ç†ã€‚ä¾‹å¦‚ï¼Œ'iterative'ç­–ç•¥çš„
             Promptï¼š"...åŸºäºä»¥ä¸‹å·²çŸ¥ä¿¡æ¯: [context]ã€‚è¯·ç”Ÿæˆ3ä¸ªå…¨æ–°çš„æŸ¥è¯¢ï¼Œä»¥æ¢ç´¢æˆ‘ä»¬å°šæœªäº†è§£çš„æ–¹é¢ã€‚"
    """
    
    def __init__(self):
        """åˆå§‹åŒ–QueryGenerationMcp"""
        try:
            self.llm_processor = LLMProcessor()
            self.has_llm = True
            print("âœ… QueryGenerationMcpåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ LLMå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.has_llm = False
        
        # é¢„å®šä¹‰çš„æŸ¥è¯¢ç­–ç•¥æ¨¡æ¿
        self.strategy_templates = self._load_strategy_templates()
    
    def _load_strategy_templates(self) -> Dict[str, str]:
        """åŠ è½½ä¸åŒç­–ç•¥çš„Promptæ¨¡æ¿"""
        return {
            "initial": """
ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯ç ”ç©¶å‘˜ï¼Œè¯·ä¸ºä¸»é¢˜"{topic}"ç”Ÿæˆåˆå§‹æœç´¢æŸ¥è¯¢ã€‚

æŠ¥å‘Šç±»å‹ï¼š{report_type}
ç›®æ ‡å—ä¼—ï¼š{target_audience}

ä»»åŠ¡è¦æ±‚ï¼š
1. ç”Ÿæˆ5-8ä¸ªå¤šæ ·åŒ–çš„æœç´¢æŸ¥è¯¢
2. è¦†ç›–ä¸»é¢˜çš„æ ¸å¿ƒæ¦‚å¿µã€æœ€æ–°å‘å±•ã€åº”ç”¨åœºæ™¯ã€æŒ‘æˆ˜é—®é¢˜
3. æŸ¥è¯¢åº”è¯¥å…·ä½“ä¸”å¯æœç´¢ï¼Œé¿å…è¿‡äºå®½æ³›
4. åŒ…å«ä¸­è‹±æ–‡å…³é”®è¯ç»„åˆï¼Œæé«˜æœç´¢è¦†ç›–é¢

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
```json
{{
    "queries": [
        "æŸ¥è¯¢1",
        "æŸ¥è¯¢2",
        "..."
    ],
    "reasoning": "ç”Ÿæˆè¿™äº›æŸ¥è¯¢çš„ç†ç”±å’Œç­–ç•¥è¯´æ˜"
}}
```
""",
            
            "iterative": """
åŸºäºä»¥ä¸‹å·²çŸ¥ä¿¡æ¯å’Œæœç´¢ç»“æœï¼Œä¸ºä¸»é¢˜"{topic}"ç”Ÿæˆè¡¥å……æ€§æŸ¥è¯¢ã€‚

å·²çŸ¥ä¿¡æ¯æ‘˜è¦ï¼š
{context}

ç°æœ‰æ•°æ®ç±»å‹ï¼š{existing_data_summary}

ä»»åŠ¡è¦æ±‚ï¼š
1. åˆ†æå·²æœ‰ä¿¡æ¯çš„è¦†ç›–é¢å’Œç¼ºå£
2. ç”Ÿæˆ3-5ä¸ªå…¨æ–°çš„ã€è¡¥å……æ€§çš„æŸ¥è¯¢
3. é‡ç‚¹å…³æ³¨å°šæœªå……åˆ†æ¢ç´¢çš„æ–¹é¢
4. é¿å…ä¸å·²æœ‰æŸ¥è¯¢é‡å¤

æ€ç»´é“¾æ¨ç†ï¼š
1. å·²æœ‰ä¿¡æ¯è¦†ç›–äº†å“ªäº›æ–¹é¢ï¼Ÿ
2. è¿˜ç¼ºå°‘å“ªäº›å…³é”®ä¿¡æ¯ï¼Ÿ
3. å“ªäº›è§’åº¦éœ€è¦æ›´æ·±å…¥çš„æ¢ç´¢ï¼Ÿ
4. å¦‚ä½•è®¾è®¡æŸ¥è¯¢æ¥å¡«è¡¥è¿™äº›ç©ºç™½ï¼Ÿ

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
```json
{{
    "gaps_identified": ["å‘ç°çš„ä¿¡æ¯ç¼ºå£1", "ç¼ºå£2", "..."],
    "queries": [
        "è¡¥å……æŸ¥è¯¢1",
        "è¡¥å……æŸ¥è¯¢2",
        "..."
    ],
    "reasoning": "åŸºäºç¼ºå£åˆ†æç”ŸæˆæŸ¥è¯¢çš„ç†ç”±"
}}
```
""",
            
            "targeted": """
ä¸ºæŠ¥å‘Šç« èŠ‚"{section_title}"ç”Ÿæˆé«˜åº¦é’ˆå¯¹æ€§çš„æœç´¢æŸ¥è¯¢ã€‚

ä¸»é¢˜ï¼š{topic}
ç« èŠ‚ä¿¡æ¯ï¼š{section_context}
æŠ¥å‘Šæ•´ä½“èƒŒæ™¯ï¼š{context}

ä»»åŠ¡è¦æ±‚ï¼š
1. ç”Ÿæˆ3-4ä¸ªä¸“é—¨é’ˆå¯¹è¯¥ç« èŠ‚çš„ç²¾å‡†æŸ¥è¯¢
2. æŸ¥è¯¢åº”è¯¥èƒ½è·å–è¯¥ç« èŠ‚æ‰€éœ€çš„å…·ä½“ä¿¡æ¯
3. è€ƒè™‘ç« èŠ‚åœ¨æ•´ä¸ªæŠ¥å‘Šä¸­çš„ä½œç”¨å’Œä½ç½®
4. ç¡®ä¿æŸ¥è¯¢çš„ä¸“ä¸šæ€§å’Œé’ˆå¯¹æ€§

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
```json
{{
    "section_focus": "è¯¥ç« èŠ‚çš„æ ¸å¿ƒå…³æ³¨ç‚¹",
    "queries": [
        "é’ˆå¯¹æ€§æŸ¥è¯¢1",
        "é’ˆå¯¹æ€§æŸ¥è¯¢2",
        "..."
    ],
    "expected_content": "æœŸæœ›é€šè¿‡è¿™äº›æŸ¥è¯¢è·å¾—çš„ä¿¡æ¯ç±»å‹"
}}
```
""",
            
            "academic": """
ä¸ºå­¦æœ¯ç ”ç©¶ä¸»é¢˜"{topic}"ç”Ÿæˆå­¦æœ¯å¯¼å‘çš„æœç´¢æŸ¥è¯¢ã€‚

ç ”ç©¶èƒŒæ™¯ï¼š{context}
ç ”ç©¶æ·±åº¦è¦æ±‚ï¼š{academic_level}

ä»»åŠ¡è¦æ±‚ï¼š
1. ç”Ÿæˆ4-6ä¸ªå­¦æœ¯æ€§æœç´¢æŸ¥è¯¢
2. åŒ…å«ä¸“ä¸šæœ¯è¯­å’Œæ¦‚å¿µ
3. è¦†ç›–ç†è®ºåŸºç¡€ã€ç ”ç©¶æ–¹æ³•ã€æœ€æ–°è¿›å±•
4. é€‚åˆåœ¨å­¦æœ¯æ•°æ®åº“ä¸­æœç´¢

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
```json
{{
    "academic_areas": ["ç†è®ºåŸºç¡€", "ç ”ç©¶æ–¹æ³•", "åº”ç”¨å®ä¾‹", "..."],
    "queries": [
        "å­¦æœ¯æŸ¥è¯¢1",
        "å­¦æœ¯æŸ¥è¯¢2", 
        "..."
    ],
    "keywords": ["å…³é”®å­¦æœ¯æœ¯è¯­1", "æœ¯è¯­2", "..."]
}}
```
""",
            
            "news": """
ä¸ºæ–°é—»è¯é¢˜"{topic}"ç”Ÿæˆæ—¶æ•ˆæ€§æœç´¢æŸ¥è¯¢ã€‚

æ—¶é—´èŒƒå›´ï¼š{time_range}
å…³æ³¨ç„¦ç‚¹ï¼š{news_focus}
èƒŒæ™¯ä¿¡æ¯ï¼š{context}

ä»»åŠ¡è¦æ±‚ï¼š
1. ç”Ÿæˆ4-5ä¸ªæ–°é—»å¯¼å‘çš„æœç´¢æŸ¥è¯¢
2. å…³æ³¨æœ€æ–°åŠ¨æ€ã€çªå‘äº‹ä»¶ã€è¶‹åŠ¿å˜åŒ–
3. åŒ…å«æ—¶é—´æ•æ„Ÿçš„å…³é”®è¯
4. é€‚åˆåœ¨æ–°é—»å¹³å°æœç´¢

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
```json
{{
    "news_angles": ["çªå‘äº‹ä»¶", "æ”¿ç­–å˜åŒ–", "å¸‚åœºåŠ¨æ€", "..."],
    "queries": [
        "æ–°é—»æŸ¥è¯¢1",
        "æ–°é—»æŸ¥è¯¢2",
        "..."
    ],
    "urgency_level": "ä¿¡æ¯æ—¶æ•ˆæ€§è¯„ä¼°"
}}
```
"""
        }
    
    def generate_queries(self, 
                        topic: str, 
                        strategy: str = "initial",
                        context: str = "",
                        **kwargs) -> List[str]:
        """
        ç”Ÿæˆæœç´¢æŸ¥è¯¢
        
        Args:
            topic: ä¸»é¢˜
            strategy: ç­–ç•¥ ('initial', 'iterative', 'targeted', 'academic', 'news')
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            List[str]: ç”Ÿæˆçš„æŸ¥è¯¢åˆ—è¡¨
        """
        if not self.has_llm:
            return self._fallback_query_generation(topic, strategy, context)
        
        try:
            # æ„å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
            query_context = QueryContext(
                topic=topic,
                strategy=strategy,
                context=context,
                **kwargs
            )
            
            # ç”ŸæˆæŸ¥è¯¢
            queries = self._generate_queries_with_llm(query_context)
            
            print(f"âœ… ä½¿ç”¨{strategy}ç­–ç•¥ä¸º'{topic}'ç”Ÿæˆäº†{len(queries)}ä¸ªæŸ¥è¯¢")
            return queries
            
        except Exception as e:
            print(f"âŒ LLMæŸ¥è¯¢ç”Ÿæˆå¤±è´¥: {str(e)}")
            return self._fallback_query_generation(topic, strategy, context)
    
    def _generate_queries_with_llm(self, query_context: QueryContext) -> List[str]:
        """ä½¿ç”¨LLMç”ŸæˆæŸ¥è¯¢"""
        template = self.strategy_templates.get(query_context.strategy, self.strategy_templates["initial"])
        
        # å‡†å¤‡æ¨¡æ¿å‚æ•°
        template_params = {
            "topic": query_context.topic,
            "context": query_context.context,
            "report_type": query_context.report_type,
            "target_audience": query_context.target_audience,
            "existing_data_summary": self._summarize_existing_data(query_context.existing_data)
        }
        
        # æ·»åŠ ç­–ç•¥ç‰¹å®šå‚æ•°
        if query_context.strategy == "targeted":
            template_params.update({
                "section_title": query_context.context.split("|")[0] if "|" in query_context.context else "æœªæŒ‡å®šç« èŠ‚",
                "section_context": query_context.context.split("|")[1] if "|" in query_context.context else query_context.context
            })
        elif query_context.strategy == "academic":
            template_params["academic_level"] = "ç ”ç©¶ç”Ÿ/ä¸“ä¸šç ”ç©¶äººå‘˜çº§åˆ«"
        elif query_context.strategy == "news":
            template_params.update({
                "time_range": "æœ€è¿‘30å¤©",
                "news_focus": "è¡Œä¸šåŠ¨æ€å’Œæ”¿ç­–å˜åŒ–"
            })
        
        # æ ¼å¼åŒ–prompt
        prompt = template.format(**template_params)
        
        # è°ƒç”¨LLM
        response = self.llm_processor.process_request(prompt)
        
        # è§£æå“åº”
        queries = self._parse_llm_response(response, query_context.strategy)
        
        # éªŒè¯å’Œè¿‡æ»¤æŸ¥è¯¢
        return self._validate_queries(queries, query_context.topic)
    
    def _parse_llm_response(self, response: str, strategy: str) -> List[str]:
        """è§£æLLMå“åº”æå–æŸ¥è¯¢"""
        try:
            # å°è¯•è§£æJSONæ ¼å¼
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                json_str = response[json_start:json_end].strip()
            else:
                # æŸ¥æ‰¾JSONå¯¹è±¡
                start_idx = response.find("{")
                end_idx = response.rfind("}") + 1
                if start_idx != -1 and end_idx != 0:
                    json_str = response[start_idx:end_idx]
                else:
                    raise ValueError("æ— æ³•æ‰¾åˆ°JSONæ ¼å¼")
            
            parsed_data = json.loads(json_str)
            queries = parsed_data.get("queries", [])
            
            if queries:
                # è®°å½•æ¨ç†è¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                if "reasoning" in parsed_data:
                    print(f"ğŸ’¡ æŸ¥è¯¢ç”Ÿæˆæ¨ç†: {parsed_data['reasoning']}")
                return queries
            else:
                raise ValueError("è§£æç»“æœä¸­æ²¡æœ‰querieså­—æ®µ")
                
        except Exception as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {str(e)}")
            return self._extract_queries_from_text(response)
    
    def _extract_queries_from_text(self, response: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–æŸ¥è¯¢ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        queries = []
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            # æŸ¥æ‰¾ç±»ä¼¼æŸ¥è¯¢çš„è¡Œ
            if (any(marker in line.lower() for marker in ['æŸ¥è¯¢', 'query', 'æœç´¢', 'search']) or 
                line.startswith('"') or 
                line.startswith('- ') or 
                line.startswith('* ') or
                line.startswith(tuple('123456789'))):
                
                # æ¸…ç†å’Œæå–æŸ¥è¯¢
                query = line
                for prefix in ['"', '- ', '* ', '1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']:
                    if query.startswith(prefix):
                        query = query[len(prefix):].strip()
                
                if query.endswith('"'):
                    query = query[:-1]
                
                if len(query) > 5 and len(query) < 200:  # åˆç†çš„æŸ¥è¯¢é•¿åº¦
                    queries.append(query)
        
        return queries[:8]  # æœ€å¤šè¿”å›8ä¸ªæŸ¥è¯¢
    
    def _validate_queries(self, queries: List[str], topic: str) -> List[str]:
        """éªŒè¯å’Œä¼˜åŒ–æŸ¥è¯¢"""
        validated_queries = []
        
        for query in queries:
            query = query.strip()
            
            # åŸºæœ¬éªŒè¯
            if not query or len(query) < 3 or len(query) > 200:
                continue
            
            # å»é™¤é‡å¤
            if query not in validated_queries:
                validated_queries.append(query)
        
        # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›æŸ¥è¯¢
        if not validated_queries:
            validated_queries = self._fallback_query_generation(topic, "initial", "")
        
        return validated_queries
    
    def _summarize_existing_data(self, existing_data: List[Dict]) -> str:
        """æ€»ç»“å·²æœ‰æ•°æ®"""
        if not existing_data:
            return "æ— å·²æœ‰æ•°æ®"
        
        data_types = set()
        source_types = set()
        
        for item in existing_data:
            if isinstance(item, dict):
                if 'source_type' in item:
                    source_types.add(item['source_type'])
                if 'title' in item:
                    data_types.add("æ ‡é¢˜ä¿¡æ¯")
                if 'content' in item:
                    data_types.add("å†…å®¹æ‘˜è¦")
        
        summary = f"å·²æœ‰{len(existing_data)}æ¡æ•°æ®ï¼Œ"
        if source_types:
            summary += f"æ¥æºç±»å‹: {', '.join(source_types)}ï¼Œ"
        if data_types:
            summary += f"æ•°æ®ç±»å‹: {', '.join(data_types)}"
        
        return summary
    
    def _fallback_query_generation(self, topic: str, strategy: str, context: str) -> List[str]:
        """å¤‡ç”¨æŸ¥è¯¢ç”Ÿæˆæ–¹æ³•"""
        base_queries = [
            f"{topic} æœ€æ–°å‘å±•",
            f"{topic} æŠ€æœ¯åŸç†",
            f"{topic} åº”ç”¨æ¡ˆä¾‹",
            f"{topic} å¸‚åœºè¶‹åŠ¿",
            f"{topic} æŒ‘æˆ˜é—®é¢˜"
        ]
        
        if strategy == "academic":
            academic_queries = [
                f"{topic} research papers",
                f"{topic} å­¦æœ¯ç ”ç©¶",
                f"{topic} ç†è®ºåŸºç¡€",
                f"{topic} methodology"
            ]
            return academic_queries
            
        elif strategy == "news":
            news_queries = [
                f"{topic} æœ€æ–°æ¶ˆæ¯",
                f"{topic} è¡Œä¸šåŠ¨æ€",
                f"{topic} æ”¿ç­–å˜åŒ–",
                f"{topic} breaking news"
            ]
            return news_queries
            
        elif strategy == "iterative" and context:
            # åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆè¡¥å……æŸ¥è¯¢
            if "æŠ€æœ¯" in context:
                return [f"{topic} å•†ä¸šåº”ç”¨", f"{topic} å¸‚åœºåˆ†æ", f"{topic} ç”¨æˆ·ä½“éªŒ"]
            elif "å¸‚åœº" in context:
                return [f"{topic} æŠ€æœ¯è¯¦è§£", f"{topic} äº§å“è¯„æµ‹", f"{topic} ä¸“å®¶è§‚ç‚¹"]
        
        return base_queries
    
    def generate_multi_strategy_queries(self, 
                                      topic: str,
                                      strategies: List[str] = None,
                                      context: str = "",
                                      **kwargs) -> Dict[str, List[str]]:
        """
        ä½¿ç”¨å¤šç§ç­–ç•¥ç”ŸæˆæŸ¥è¯¢
        
        Args:
            topic: ä¸»é¢˜
            strategies: ç­–ç•¥åˆ—è¡¨
            context: ä¸Šä¸‹æ–‡
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            Dict[str, List[str]]: å„ç­–ç•¥å¯¹åº”çš„æŸ¥è¯¢åˆ—è¡¨
        """
        if strategies is None:
            strategies = ["initial", "academic", "news"]
        
        all_queries = {}
        
        for strategy in strategies:
            try:
                queries = self.generate_queries(topic, strategy, context, **kwargs)
                all_queries[strategy] = queries
                print(f"  ğŸ“‹ {strategy}ç­–ç•¥: {len(queries)}ä¸ªæŸ¥è¯¢")
            except Exception as e:
                print(f"  âŒ {strategy}ç­–ç•¥å¤±è´¥: {str(e)}")
                all_queries[strategy] = []
        
        return all_queries
    
    def refine_queries_based_on_results(self, 
                                      original_queries: List[str],
                                      search_results: List[Dict],
                                      topic: str) -> List[str]:
        """
        åŸºäºæœç´¢ç»“æœä¼˜åŒ–æŸ¥è¯¢
        
        Args:
            original_queries: åŸå§‹æŸ¥è¯¢
            search_results: æœç´¢ç»“æœ
            topic: ä¸»é¢˜
            
        Returns:
            List[str]: ä¼˜åŒ–åçš„æŸ¥è¯¢
        """
        if not self.has_llm or not search_results:
            return original_queries
        
        # åˆ†ææœç´¢ç»“æœè´¨é‡
        results_summary = self._analyze_search_results(search_results)
        
        # ç”Ÿæˆä¼˜åŒ–æŸ¥è¯¢
        context = f"åŸå§‹æŸ¥è¯¢: {original_queries}\næœç´¢ç»“æœåˆ†æ: {results_summary}"
        
        refined_queries = self.generate_queries(
            topic=topic,
            strategy="iterative", 
            context=context
        )
        
        return refined_queries
    
    def _analyze_search_results(self, search_results: List[Dict]) -> str:
        """åˆ†ææœç´¢ç»“æœè´¨é‡"""
        if not search_results:
            return "æ— æœç´¢ç»“æœ"
        
        total_results = len(search_results)
        source_types = {}
        
        for result in search_results:
            source_type = result.get('source_type', 'unknown')
            source_types[source_type] = source_types.get(source_type, 0) + 1
        
        analysis = f"å…±{total_results}æ¡ç»“æœï¼Œ"
        analysis += f"æ¥æºåˆ†å¸ƒ: {dict(source_types)}"
        
        return analysis 